{"componentChunkName":"component---src-templates-author-tsx","path":"/author/kevincrawley/","result":{"data":{"ghostAuthor":{"slug":"kevincrawley","name":"Kevin Crawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","cover_image":"https://containous.ghost.io/content/images/2020/04/IMG_0248.jpg","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","location":"Nashville, TN","website":"https://containo.us","twitter":"@notsureifkevin","facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5fce60e016db8f0039b4334b","title":"From Zero to Hero: Getting Started with k0s and Traefik","slug":"from-zero-to-hero-getting-started-with-k0s-and-traefik","featured":true,"feature_image":"https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik-2.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/e5e000f515b518b83b527146af938a46/f3583/Getting-Started-with-k0s-and-Traefik-2.png","srcSet":"/static/e5e000f515b518b83b527146af938a46/630fb/Getting-Started-with-k0s-and-Traefik-2.png 300w,\n/static/e5e000f515b518b83b527146af938a46/2a4de/Getting-Started-with-k0s-and-Traefik-2.png 600w,\n/static/e5e000f515b518b83b527146af938a46/f3583/Getting-Started-with-k0s-and-Traefik-2.png 1200w,\n/static/e5e000f515b518b83b527146af938a46/bbee5/Getting-Started-with-k0s-and-Traefik-2.png 1800w,\n/static/e5e000f515b518b83b527146af938a46/0ef64/Getting-Started-with-k0s-and-Traefik-2.png 2400w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"K0s is a new Kubernetes distribution from Mirantis. It's similar to Rancher Labs' K3s, yet it ships only the bare minimum of extensions. K0s is a new Kubernetes distribution from Mirantis. This post covers how to configure k0s to include Traefik and begin routing your applications with CRDs.","custom_excerpt":"K0s is a new Kubernetes distribution from Mirantis. It's similar to Rancher Labs' K3s, yet it ships only the bare minimum of extensions. K0s is a new Kubernetes distribution from Mirantis. This post covers how to configure k0s to include Traefik and begin routing your applications with CRDs.","visibility":"public","created_at_pretty":"07 December, 2020","published_at_pretty":"December 8, 2020","updated_at_pretty":"09 December, 2020","created_at":"2020-12-07T17:05:36.000+00:00","published_at":"2020-12-08T16:10:36.000+00:00","updated_at":"2020-12-09T14:14:33.000+00:00","meta_title":"From Zero to Hero: Getting Started with k0s and Traefik","meta_description":"K0s is a new Kubernetes distribution from Mirantis. This post covers how to configure k0s to include Traefik and begin routing your applications with CRDs.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik---Twitter.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#homepage-featured-post-1","slug":"hash-homepage-featured-post-1","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"K0s [https://k0sproject.io/] is a new Kubernetes distribution from Mirantis.\nIt's similar to Rancher Labs' K3s, yet it ships with only the bare minimum of\nextensions. This allows flexibility for users who want to customize it to their\nneeds by defining their own ingress, storage, and other controllers in the CRD\nmanifest, configuring the cluster during bootstrap.\n\nIn the examples below, I’ll guide you through how to accomplish getting a\nfunctioning Kubernetes cluster by:\n\n 1. Installing k0s on a clean Linux VM\n 2. Configuring Traefik and MetalLB as an extension\n 3. Starting k0s\n 4. Deploying the Traefik Dashboard IngressRoute and an example service\n\nStep 1\nBefore we start, you should plan to do this on a clean install of Linux,\nprobably in a VM. You will be running k0s as a server/worker, and the worker\ninstalls components into the /var/lib filesystem as root (so root access is a\nrequirement). My understanding is there are plans to allow non-root workers in\nthe future. Hopefully, in addition to non-root, the k0s binary will allow worker\ninstallations in a configurable location.\n\n> Note: Cleanly shutting down and wiping the cluster is not a feature yet in the\nk0s binary. For now, rebooting the system and wiping /var/lib/k0s is the easiest\noption.\nOnce you have a clean Linux VM (I’m using Ubuntu 20.04.1), you’ll want to\ninstall the Helm and kubectl binaries.\n\ncurl -O https://get.helm.sh/helm-v3.4.1-linux-amd64.tar.gz\ntar xvzf helm-v3.4.1-linux-amd64.tar.gz\nsudo mv linux-amd64/helm /usr/local/bin\n\ncurl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin\n\nOnce those are installed, install the k0s binary, create the working directory\nfor k0s, and create a default config.\n\n> Note: The installer and running k0s itself both require root\n# make sure you're running as root\ncurl -sSLf get.k0s.sh | sh\n# create the working directory and set the permissions\nmkdir -p /var/lib/k0s && chmod 755 /var/lib/k0s\n# create the default config\nk0s default-config > /var/lib/k0s/k0s.yaml\n\nStep 2\nIn this step, you’ll configure Traefik and MetalLB\n[https://metallb.universe.tf/] as extensions that will be installed during the\ncluster's bootstrap. Traefik will function as an ingress controller and MetalLB\nwill allow you to access services from a logical IP address deployed as a \nservice load balancer\n[https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer].\nYou will want to have a small range of IP addresses that are addressable on your\nnetwork, preferably outside the range of your DHCP server.\n\nModify the newly created k0s.yaml file in /var/lib/k0s/k0s.yaml:\n\napiVersion: k0s.k0sproject.io/v1beta1\nkind: Cluster\nmetadata:\n  name: k0s\n...\nextensions:\n  helm:\n    repositories:\n    - name: traefik\n      url: https://helm.traefik.io/traefik\n    - name: bitnami\n      url: https://charts.bitnami.com/bitnami\n    charts:\n    - name: traefik\n      chartname: traefik/traefik\n      version: \"9.11.0\"\n      namespace: default\n    - name: metallb\n      chartname: bitnami/metallb\n      version: \"1.0.1\"\n      namespace: default\n      values: |2\n        configInline:\n          address-pools:\n          - name: generic-cluster-pool\n            protocol: layer2\n            addresses:\n            - 172.16.100.215-172.16.100.220\n\nAgain, be sure to provide a range of IPs for MetalLB that are addressable on\nyour network if you want to access the LoadBalancer and Ingress services from\noutside this machine.\n\nStep 3\nNow it's time to run k0s and let it automatically set up the server and worker,\nand deploy and configure Traefik and MetalLB:\n\ncd /var/lib/k0s\nk0s server --enable-worker </dev/null &>/dev/null &\n\nAfter a minute or two, you should be able to access the cluster using the\ncertificate generated by k0s, located in /var/lib/k0s/pki/admin.conf, and see\nthat MetalLB was deployed along with the Traefik Ingress Controller.\n\nroot@k0s-host ➜ export KUBECONFIG=/var/lib/k0s/pki/admin.conf\nroot@k0s-host ➜ kubectl get all\nNAME                                                 READY   STATUS    RESTARTS   AGE\npod/metallb-1607085578-controller-864c9757f6-bpx6r   1/1     Running   0          81s\npod/metallb-1607085578-speaker-245c2                 1/1     Running   0          60s\npod/traefik-1607085579-77bbc57699-b2f2t              1/1     Running   0          81s\n\nNAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/kubernetes           ClusterIP      10.96.0.1        <none>           443/TCP                      96s\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s\n\nNAME                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/metallb-1607085578-speaker   1         1         1       1            1           kubernetes.io/os=linux   87s\n\nNAME                                            READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/metallb-1607085578-controller   1/1     1            1           87s\ndeployment.apps/traefik-1607085579              1/1     1            1           84s\n\nNAME                                                       DESIRED   CURRENT   READY   AGE\nreplicaset.apps/metallb-1607085578-controller-864c9757f6   1         1         1       81s\nreplicaset.apps/traefik-1607085579-77bbc57699              1         1         1       81s\n\nTake note of the IP address assigned to the Traefik Load Balancer here:\n\nNAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s\n\nYou will need the EXTERNAL-IP (in this case, 172.16.100.215) later, when\naccessing Ingress resources on your cluster.\n\nStep 4\n * Deploy the Traefik dashboard\n * Deploy the sample “whoami” service\n\nNow that you have a functional and addressable load balancer on your cluster,\nyou can easily deploy the Traefik dashboard and access it from anywhere on your\nlocal network (provided that you configured MetalLB with an addressable range).\n\nCreate the Traefik Dashboard IngressRoute\n[https://doc.traefik.io/traefik/providers/kubernetes-crd/] in a YAML file:\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: PathPrefix(`/dashboard`) || PathPrefix(`/api`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService\n\nAnd deploy it:\n\nroot@k0s-host ➜ kubectl apply -f traefik-dashboard.yaml\ningressroute.traefik.containo.us/dashboard created\n\nYou can now access it from your browser by visiting \nhttp://172.16.100.215/dashboard/:\n\nGreat, now let’s deploy a simple “whoami” service.\n\nCreate the whoami Deployment, Service, and Kubernetes Ingress\n[https://kubernetes.io/docs/concepts/services-networking/ingress/] manifest:\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whoami-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: whoami\n  template:\n    metadata:\n      labels:\n        app: whoami\n    spec:\n      containers:\n      - name: whoami-container\n        image: containous/whoami\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: whoami-service\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: whoami\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: whoami-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /whoami\n        pathType: Exact\n        backend:\n          service:\n            name: whoami-service\n            port:\n              number: 80\n\nAnd now, deploy and test it…\n\nroot@k0s-host ➜ kubectl apply -f whoami.yaml\ndeployment.apps/whoami-deployment created\nservice/whoami-service created\ningress.networking.k8s.io/whoami-ingress created\n# test the route\nroot@k0s-host ➜ curl http://172.16.100.215/whoami\nHostname: whoami-deployment-85bfbd48f-7l77c\nIP: 127.0.0.1\nIP: ::1\nIP: 10.244.214.198\nIP: fe80::b049:f8ff:fe77:3e64\nRemoteAddr: 10.244.214.196:34858\nGET /whoami HTTP/1.1\nHost: 172.16.100.215\nUser-Agent: curl/7.68.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.16.100.77\nX-Forwarded-Host: 172.16.100.215\nX-Forwarded-Port: 80\nX-Forwarded-Proto: http\nX-Forwarded-Server: traefik-1607085579-77bbc57699-b2f2t\nX-Real-Ip: 172.16.100.77\n\nSummary\nThis post covered installing k0s, setting up a fully functional Load Balancer\nand Ingress controller for use in your local environment. From here, you could\nuse a tool such as ngrok [https://ngrok.io] to expose your Load Balancer to the\nworld and set up Let’s Encrypt\n[https://doc.traefik.io/traefik/v2.0/user-guides/crd-acme/] so you can provision\nyour own SSL certificates.\n\nThe design of k0s as a single binary installer that allows modular\ncustomizability makes it a unique offering in the Kubernetes community. You can\nlearn more about how to leverage Kubernetes Ingress with Traefik on our site. In\naddition, you can learn more about installing k0s on Mirantis' blog\n[https://www.mirantis.com/blog/how-to-set-up-k0s-kubernetes-a-quick-and-dirty-guide/]\n. While k0s is still relatively new to the scene, I hope this post gives you an\nidea of what it’s capable of and how you can start experimenting with your own\ncustomized Kubernetes setup.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik-1.png\" class=\"kg-image\" alt=\"Getting Started with k0s and Traefik\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 1600w, https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: markdown--><p><a href=\"https://k0sproject.io/\" target=\"_blank\" rel=\"nofollow\">K0s</a> is a new Kubernetes distribution from Mirantis. It's similar to Rancher Labs' K3s, yet it ships with only the bare minimum of extensions. This allows flexibility for users who want to customize it to their needs by defining their own ingress, storage, and other controllers in the CRD manifest, configuring the cluster during bootstrap.</p>\n<!--kg-card-end: markdown--><p>In the examples below, I’ll guide you through how to accomplish getting a functioning Kubernetes cluster by:</p><ol><li>Installing k0s on a clean Linux VM</li><li>Configuring Traefik and MetalLB as an extension</li><li>Starting k0s</li><li>Deploying the Traefik Dashboard IngressRoute and an example service</li></ol><h2 id=\"step-1\">Step 1</h2><p>Before we start, you should plan to do this on a clean install of Linux, probably in a VM. You will be running k0s as a server/worker, and the worker installs components into the <code>/var/lib</code> filesystem as root (so root access is a requirement). My understanding is there are plans to allow non-root workers in the future. Hopefully, in addition to non-root, the k0s binary will allow worker installations in a configurable location.</p><blockquote>Note: Cleanly shutting down and wiping the cluster is not a feature yet in the k0s binary. For now, rebooting the system and wiping <code>/var/lib/k0s</code> is the easiest option.</blockquote><p>Once you have a clean Linux VM (I’m using Ubuntu 20.04.1), you’ll want to install the Helm and <code>kubectl</code> binaries.</p><pre><code class=\"language-bash\">curl -O https://get.helm.sh/helm-v3.4.1-linux-amd64.tar.gz\ntar xvzf helm-v3.4.1-linux-amd64.tar.gz\nsudo mv linux-amd64/helm /usr/local/bin\n\ncurl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin</code></pre><p>Once those are installed, install the k0s binary, create the working directory for k0s, and create a default config.</p><blockquote>Note: The installer and running k0s itself both require root</blockquote><pre><code class=\"language-bash\"># make sure you're running as root\ncurl -sSLf get.k0s.sh | sh\n# create the working directory and set the permissions\nmkdir -p /var/lib/k0s &amp;&amp; chmod 755 /var/lib/k0s\n# create the default config\nk0s default-config &gt; /var/lib/k0s/k0s.yaml</code></pre><h2 id=\"step-2\">Step 2</h2><!--kg-card-begin: markdown--><p>In this step, you’ll configure Traefik and <a href=\"https://metallb.universe.tf/\" rel=\"nofollow\">MetalLB</a> as extensions that will be installed during the cluster's bootstrap. Traefik will function as an ingress controller and MetalLB will allow you to access services from a logical IP address deployed as a <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer\" rel=\"nofollow\">service load balancer</a>. You will want to have a small range of IP addresses that are addressable on your network, preferably outside the range of your DHCP server.</p>\n<!--kg-card-end: markdown--><p>Modify the newly created k0s.yaml file in <code>/var/lib/k0s/k0s.yaml</code>:</p><pre><code class=\"language-yaml\">apiVersion: k0s.k0sproject.io/v1beta1\nkind: Cluster\nmetadata:\n  name: k0s\n...\nextensions:\n  helm:\n    repositories:\n    - name: traefik\n      url: https://helm.traefik.io/traefik\n    - name: bitnami\n      url: https://charts.bitnami.com/bitnami\n    charts:\n    - name: traefik\n      chartname: traefik/traefik\n      version: \"9.11.0\"\n      namespace: default\n    - name: metallb\n      chartname: bitnami/metallb\n      version: \"1.0.1\"\n      namespace: default\n      values: |2\n        configInline:\n          address-pools:\n          - name: generic-cluster-pool\n            protocol: layer2\n            addresses:\n            - 172.16.100.215-172.16.100.220</code></pre><p>Again, be sure to provide a range of IPs for MetalLB that are addressable on your network if you want to access the LoadBalancer and Ingress services from outside this machine.</p><h2 id=\"step-3\">Step 3</h2><p>Now it's time to run k0s and let it automatically set up the server and worker, and deploy and configure Traefik and MetalLB:</p><pre><code class=\"language-bash\">cd /var/lib/k0s\nk0s server --enable-worker &lt;/dev/null &amp;&gt;/dev/null &amp;</code></pre><p>After a minute or two, you should be able to access the cluster using the certificate generated by k0s, located in <code>/var/lib/k0s/pki/admin.conf</code>, and see that MetalLB was deployed along with the Traefik Ingress Controller.</p><pre><code class=\"language-bash\">root@k0s-host ➜ export KUBECONFIG=/var/lib/k0s/pki/admin.conf\nroot@k0s-host ➜ kubectl get all\nNAME                                                 READY   STATUS    RESTARTS   AGE\npod/metallb-1607085578-controller-864c9757f6-bpx6r   1/1     Running   0          81s\npod/metallb-1607085578-speaker-245c2                 1/1     Running   0          60s\npod/traefik-1607085579-77bbc57699-b2f2t              1/1     Running   0          81s\n\nNAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/kubernetes           ClusterIP      10.96.0.1        &lt;none&gt;           443/TCP                      96s\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s\n\nNAME                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/metallb-1607085578-speaker   1         1         1       1            1           kubernetes.io/os=linux   87s\n\nNAME                                            READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/metallb-1607085578-controller   1/1     1            1           87s\ndeployment.apps/traefik-1607085579              1/1     1            1           84s\n\nNAME                                                       DESIRED   CURRENT   READY   AGE\nreplicaset.apps/metallb-1607085578-controller-864c9757f6   1         1         1       81s\nreplicaset.apps/traefik-1607085579-77bbc57699              1         1         1       81s</code></pre><p>Take note of the IP address assigned to the Traefik Load Balancer here:</p><pre><code>NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s</code></pre><p>You will need the <code>EXTERNAL-IP</code> (in this case, <code>172.16.100.215</code>) later, when accessing Ingress resources on your cluster.</p><h2 id=\"step-4\">Step 4</h2><ul><li>Deploy the Traefik dashboard</li><li>Deploy the sample “whoami” service</li></ul><p>Now that you have a functional and addressable load balancer on your cluster, you can easily deploy the Traefik dashboard and access it from anywhere on your local network (provided that you configured MetalLB with an addressable range).</p><p>Create the Traefik Dashboard <a href=\"https://doc.traefik.io/traefik/providers/kubernetes-crd/\">IngressRoute</a> in a YAML file:</p><pre><code class=\"language-yaml\">apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: PathPrefix(`/dashboard`) || PathPrefix(`/api`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService</code></pre><p>And deploy it:</p><pre><code class=\"language-bash\">root@k0s-host ➜ kubectl apply -f traefik-dashboard.yaml\ningressroute.traefik.containo.us/dashboard created</code></pre><p>You can now access it from your browser by visiting <code>http://172.16.100.215/dashboard/</code>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/12/image.png\" class=\"kg-image\" alt srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/image.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/image.png 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/image.png 1600w, https://containous.ghost.io/content/images/2020/12/image.png 1743w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Great, now let’s deploy a simple “whoami” service.</p><!--kg-card-begin: markdown--><p>Create the <code>whoami</code> Deployment, Service, and <a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\" rel=\"nofollow\">Kubernetes Ingress</a> manifest:</p>\n<!--kg-card-end: markdown--><pre><code class=\"language-yaml\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whoami-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: whoami\n  template:\n    metadata:\n      labels:\n        app: whoami\n    spec:\n      containers:\n      - name: whoami-container\n        image: containous/whoami\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: whoami-service\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: whoami\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: whoami-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /whoami\n        pathType: Exact\n        backend:\n          service:\n            name: whoami-service\n            port:\n              number: 80</code></pre><p>And now, deploy and test it…</p><pre><code class=\"language-bash\">root@k0s-host ➜ kubectl apply -f whoami.yaml\ndeployment.apps/whoami-deployment created\nservice/whoami-service created\ningress.networking.k8s.io/whoami-ingress created\n# test the route\nroot@k0s-host ➜ curl http://172.16.100.215/whoami\nHostname: whoami-deployment-85bfbd48f-7l77c\nIP: 127.0.0.1\nIP: ::1\nIP: 10.244.214.198\nIP: fe80::b049:f8ff:fe77:3e64\nRemoteAddr: 10.244.214.196:34858\nGET /whoami HTTP/1.1\nHost: 172.16.100.215\nUser-Agent: curl/7.68.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.16.100.77\nX-Forwarded-Host: 172.16.100.215\nX-Forwarded-Port: 80\nX-Forwarded-Proto: http\nX-Forwarded-Server: traefik-1607085579-77bbc57699-b2f2t\nX-Real-Ip: 172.16.100.77</code></pre><h2 id=\"summary\">Summary</h2><!--kg-card-begin: markdown--><p>This post covered installing k0s, setting up a fully functional Load Balancer and Ingress controller for use in your local environment. From here, you could use a tool such as <a href=\"https://ngrok.io\" target=\"_blank\" rel=\"nofollow\">ngrok</a> to expose your Load Balancer to the world and <a href=\"https://doc.traefik.io/traefik/v2.0/user-guides/crd-acme/\">set up Let’s Encrypt</a> so you can provision your own SSL certificates.</p>\n<p>The design of k0s as a single binary installer that allows modular customizability makes it a unique offering in the Kubernetes community. You can learn more about how to leverage Kubernetes Ingress with Traefik on <a h ref=\"https://traefik.io/solutions/kubernetes-ingress/\">our site</a>. In addition, you can learn more about installing k0s on <a href=\"https://www.mirantis.com/blog/how-to-set-up-k0s-kubernetes-a-quick-and-dirty-guide/\" rel=\"nofollow\">Mirantis' blog</a>. While k0s is still relatively new to the scene, I hope this post gives you an idea of what it’s capable of and how you can start experimenting with your own customized Kubernetes setup.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/from-zero-to-hero-getting-started-with-k0s-and-traefik/","canonical_url":null,"uuid":"52748163-308e-42aa-8993-8a805ee3500e","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5fce60e016db8f0039b4334b","reading_time":5}},{"node":{"id":"Ghost__Post__5fc64b2616db8f0039b432b7","title":"Observing Kubernetes Ingress Traffic using Metrics","slug":"observing-kubernetes-ingress-traffic-using-metrics","featured":true,"feature_image":"https://containous.ghost.io/content/images/2020/12/Blog@2x-2.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/e1059f243239fbb89e6142ce8204cd42/f3583/Blog%402x-2.png","srcSet":"/static/e1059f243239fbb89e6142ce8204cd42/630fb/Blog%402x-2.png 300w,\n/static/e1059f243239fbb89e6142ce8204cd42/2a4de/Blog%402x-2.png 600w,\n/static/e1059f243239fbb89e6142ce8204cd42/f3583/Blog%402x-2.png 1200w,\n/static/e1059f243239fbb89e6142ce8204cd42/bbee5/Blog%402x-2.png 1800w,\n/static/e1059f243239fbb89e6142ce8204cd42/0ef64/Blog%402x-2.png 2400w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Monitoring Kubernetes ingress traffic is a critical part of an effective strategy for detecting and managing potential issues in real-time.","custom_excerpt":"Monitoring Kubernetes ingress traffic is a critical part of an effective strategy for detecting and managing potential issues in real-time.","visibility":"public","created_at_pretty":"01 December, 2020","published_at_pretty":"December 3, 2020","updated_at_pretty":"08 December, 2020","created_at":"2020-12-01T13:54:46.000+00:00","published_at":"2020-12-03T02:13:39.000+00:00","updated_at":"2020-12-08T03:16:46.000+00:00","meta_title":"Observing Kubernetes Ingress Traffic using Metrics","meta_description":"Monitoring Kubernetes ingress traffic is a critical part of an effective strategy for detecting and managing potential issues in real-time.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/12/Twitter@2x-1.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Kubernetes","slug":"kubernetes","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Enterprise engineering teams are continuously striving to deliver the best user\nfacing experience possible for the applications they manage. Adopting Kubernetes\n(k8s) is helping in this regard by allowing organizations to easily manage\nlifecycle operations for workloads in a repeatable manner. Because of this,\nKubernetes has been a key enabler towards accelerating implementation of\npurpose-specific services to meet business requirements. While k8s provides a\nstrong foundation for stable operations, proactive measures must still be taken\nto avoid negative impacts including performance or functional issues. Monitoring\nKubernetes ingress traffic is a critical part of an effective strategy for\ndetecting and managing potential issues in real-time. In this article, we’ll\ndiscuss this topic including:\n\n * Where to integrate in a Kubernetes system to obtain metrics\n * How monitoring data can be stored effectively\n * What visualization tools can be used to understand metrics data\n\nObtaining ingress traffic metrics\nWhere and how ingress traffic network statistics can be collected depends upon\nthe adopted approach\n[https://traefik.io/blog/combining-ingress-controllers-and-external-load-balancers-with-kubernetes/] \nfor exposing services. Let’s dive into the two strategies often used with\nKubernetes:\n\n 1. External Load Balancers\n 2. Ingress Controllers\n\nMetrics with External Load Balancers\nWhen service configurations are defined appropriately by operators, Kubernetes\ncan automate the deployment of managed load balancers. For example, when\nlaunched within AWS, a Kubernetes Service can instantiate a cloud load balancer\ninstance without any out-of-band provisioning steps required by developers. The\nimplementations of these load balancers are black boxes, but they all expose\nmechanisms for monitoring and tracing. In the case of AWS, time-series data and\nrequest logs can be collected and accessed using accompanying integrated\nservices such as CloudWatch and CloudTrail. One potential drawback of these\ntightly integrated proprietary services is that these systems often do not\nintegrate easily with external data storage and visualization tools.\n\nCapturing Metrics from Load Balancers and Ingress ControllersMetrics with\nIngress Controllers\nWhen thinking about monitoring Ingress Controllers, it’s useful to keep in mind\nthat they are implemented as standard Kubernetes applications. This means that\nany monitoring approaches adopted by organizations to track the health and\nliveliness of k8s workloads can be applied to Ingress Controllers. Tracking\nnetwork traffic statistics in particular, however, requires taking advantage of\ncontroller-specific mechanisms. Similar to external load balancers, the specific\nmetrics exposed vary depending on the controller, but any production quality\nimplementation will provide built-in metric collection capabilities that can be\nintegrated with an external data storage system.\n\nData storage for Ingress Monitoring\nSelecting a data storage solution is an important part of defining a traffic\nmonitoring architecture for Ingress Controllers. There are two general\ncategories of implementations that one can choose between: \n\n 1. Self-managed (typically open source) database systems\n 2. Managed SaaS database systems.\n\nWhile applications often use general-purpose SQL databases for their structured\ndata, with monitoring data it’s advantageous to utilize a system optimized for\nstoring and querying time-series data. There are multiple open source options\nfor time-series databases, including InfluxDB [https://www.influxdata.com/] and \nPrometheus [https://prometheus.io/], either is typically deployed in the same\nk8s cluster as the Ingress controller. Once these systems are provisioned, it’s\njust a matter of configuring settings for the Ingress controller to enable\nautomated metric data collection in the database.\n\nSome teams may prefer to take the route of a fully managed data provider to\navoid the overheads of maintaining a database. There are options such as DataDog\n[https://datadoghq.com] or Elasticsearch [https://www.elastic.co/elastic-stack] \navailable that meet this demand in the form of a cloud-based SaaS monitoring\nplatform. The providers are well supported by controller implementations due to\ntheir popularity, and Ingress controllers such as Traefik are designed to easily\nintegrate with it.\n\nVisualizing Ingress Traffic Metrics\nGetting metrics into a database is a first step towards effective ingress\nmonitoring, but providing engineering teams with actionable information in\nreal-time requires being able to easily interpret the information. Visualizing\ntime-series data is the most effective way to convert raw metrics into\nhuman-digestible form. For example, visualizations are often combined into\ndashboards and used by Site Reliability Engineers to track the status of\nservices and as an information source when live-site issues occur. Grafana\n[https://grafana.com/] is a widely adopted open source software for data\nvisualization which works well with databases such as InfluxDB and Prometheus.\nAlternatively, the managed solutions mentioned earlier, such as DataDog, provide\nbuilt-in visualization capabilities as part of their holistic platforms.\n\n\n\n\n\nSummary\nMonitoring ingress traffic is an important part of managing the health of\nexternal-facing services. As outlined in this article, best-of-breed metric\nstorage and visualization technologies can be adopted for Kubernetes monitoring\nby virtue of capabilities provided by Ingress Controller implementations such as\nTraefik. This means organizations can easily rollout effective monitoring for\nk8s clusters providing peace of mind for engineering teams and end-users.\n\nFurthermore, Traefik metrics and reporting are available through Traefik\nEnterprise and Traefik Pilot. You can sign up for a demo\n[https://info.traefik.io/en/request-demo-traefik-enterprise] of Traefik\nEnterprise today, and Traefik Pilot [https://traefik.io/traefik-pilot/] is\nalready available for users of the popular open source Traefik Proxy project.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/12/Blog@2x.png\" class=\"kg-image\" alt=\"Observing Kubernetes Ingress Traffic using Metrics\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/Blog@2x.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/Blog@2x.png 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/Blog@2x.png 1600w, https://containous.ghost.io/content/images/2020/12/Blog@2x.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Enterprise engineering teams are continuously striving to deliver the best user facing experience possible for the applications they manage. Adopting Kubernetes (k8s) is helping in this regard by allowing organizations to easily manage lifecycle operations for workloads in a repeatable manner. Because of this, Kubernetes has been a key enabler towards accelerating implementation of purpose-specific services to meet business requirements. While k8s provides a strong foundation for stable operations, proactive measures must still be taken to avoid negative impacts including performance or functional issues. Monitoring Kubernetes ingress traffic is a critical part of an effective strategy for detecting and managing potential issues in real-time. In this article, we’ll discuss this topic including:</p><ul><li>Where to integrate in a Kubernetes system to obtain metrics</li><li>How monitoring data can be stored effectively</li><li>What visualization tools can be used to understand metrics data</li></ul><h3 id=\"obtaining-ingress-traffic-metrics\">Obtaining ingress traffic metrics</h3><p>Where and how ingress traffic network statistics can be collected depends upon the <a href=\"https://traefik.io/blog/combining-ingress-controllers-and-external-load-balancers-with-kubernetes/\">adopted approach</a> for exposing services. Let’s dive into the two strategies often used with Kubernetes:</p><ol><li>External Load Balancers</li><li>Ingress Controllers</li></ol><!--kg-card-begin: markdown--><h3 id=\"metricswithexternalloadbalancers\">Metrics with External Load Balancers</h3>\n<p>When service configurations are defined appropriately by operators, Kubernetes can automate the deployment of managed load balancers. For example, when launched within AWS, a Kubernetes Service can instantiate a cloud load balancer instance without any out-of-band provisioning steps required by developers. The implementations of these load balancers are black boxes, but they all expose mechanisms for monitoring and tracing. In the case of AWS, time-series data and request logs can be collected and accessed using accompanying integrated services such as CloudWatch and CloudTrail. One potential drawback of these tightly integrated proprietary services is that these systems often do not integrate easily with external data storage and visualization tools.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/12/Capturing-Metrics-from-Load-Balancers-and-Ingress-Controllers.png\" class=\"kg-image\" alt=\"Capturing Metrics from Load Balancers and Ingress Controllers\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/Capturing-Metrics-from-Load-Balancers-and-Ingress-Controllers.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/Capturing-Metrics-from-Load-Balancers-and-Ingress-Controllers.png 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/Capturing-Metrics-from-Load-Balancers-and-Ingress-Controllers.png 1600w, https://containous.ghost.io/content/images/2020/12/Capturing-Metrics-from-Load-Balancers-and-Ingress-Controllers.png 2310w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Capturing Metrics from Load Balancers and Ingress Controllers</figcaption></figure><!--kg-card-begin: markdown--><h3 id=\"metricswithingresscontrollers\">Metrics with Ingress Controllers</h3>\n<p>When thinking about monitoring Ingress Controllers, it’s useful to keep in mind that they are implemented as standard Kubernetes applications. This means that any monitoring approaches adopted by organizations to track the health and liveliness of k8s workloads can be applied to Ingress Controllers. Tracking network traffic statistics in particular, however, requires taking advantage of controller-specific mechanisms. Similar to external load balancers, the specific metrics exposed vary depending on the controller, but any production quality implementation will provide built-in metric collection capabilities that can be integrated with an external data storage system.</p>\n<!--kg-card-end: markdown--><h3 id=\"data-storage-for-ingress-monitoring\">Data storage for Ingress Monitoring</h3><p>Selecting a data storage solution is an important part of defining a traffic monitoring architecture for Ingress Controllers. There are two general categories of implementations that one can choose between: </p><ol><li>Self-managed (typically open source) database systems</li><li>Managed SaaS database systems.</li></ol><!--kg-card-begin: markdown--><p>While applications often use general-purpose SQL databases for their structured data, with monitoring data it’s advantageous to utilize a system optimized for storing and querying time-series data. There are multiple open source options for time-series databases, including <a href=\"https://www.influxdata.com/\" rel=\"nofollow\">InfluxDB</a> and <a href=\"https://prometheus.io/\" rel=\"nofollow\">Prometheus</a>, either is typically deployed in the same k8s cluster as the Ingress controller. Once these systems are provisioned, it’s just a matter of configuring settings for the Ingress controller to enable automated metric data collection in the database.</p>\n<p>Some teams may prefer to take the route of a fully managed data provider to avoid the overheads of maintaining a database. There are options such as <a href=\"https://datadoghq.com\" rel=\"nofollow\">DataDog</a> or <a href=\"https://www.elastic.co/elastic-stack\" rel=\"nofollow\">Elasticsearch</a> available that meet this demand in the form of a cloud-based SaaS monitoring platform. The providers are well supported by controller implementations due to their popularity, and Ingress controllers such as Traefik are designed to easily integrate with it.</p>\n<h2 id=\"visualizingingresstrafficmetrics\">Visualizing Ingress Traffic Metrics</h2>\n<p>Getting metrics into a database is a first step towards effective ingress monitoring, but providing engineering teams with actionable information in real-time requires being able to easily interpret the information. Visualizing time-series data is the most effective way to convert raw metrics into human-digestible form. For example, visualizations are often combined into dashboards and used by Site Reliability Engineers to track the status of services and as an information source when live-site issues occur. <a href=\"https://grafana.com/\" rel=\"nofollow\">Grafana</a> is a widely adopted open source software for data visualization which works well with databases such as InfluxDB and Prometheus. Alternatively, the managed solutions mentioned earlier, such as DataDog, provide built-in visualization capabilities as part of their holistic platforms.</p>\n<p><img src=\"https://containous.ghost.io/content/images/2020/12/2020-12-01_8-53-38.png\" alt=\"Traefik Metrics\"></p>\n<p><img src=\"https://containous.ghost.io/content/images/2020/12/2020-12-01_8-16-14.png\" alt=\"Load Balancer Metrics\"></p>\n<h2 id=\"summary\">Summary</h2>\n<p>Monitoring ingress traffic is an important part of managing the health of external-facing services. As outlined in this article, best-of-breed metric storage and visualization technologies can be adopted for Kubernetes monitoring by virtue of capabilities provided by Ingress Controller implementations such as Traefik. This means organizations can easily rollout effective monitoring for k8s clusters providing peace of mind for engineering teams and end-users.</p>\n<p>Furthermore, Traefik metrics and reporting are available through Traefik Enterprise and Traefik Pilot. You can <a href=\"https://info.traefik.io/en/request-demo-traefik-enterprise\">sign up for a demo</a> of Traefik Enterprise today, and <a href=\"https://traefik.io/traefik-pilot/\">Traefik Pilot</a> is already available for users of the popular open source Traefik Proxy project.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/observing-kubernetes-ingress-traffic-using-metrics/","canonical_url":null,"uuid":"90c78d85-ea40-4c48-b992-5eb268482ba7","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5fc64b2616db8f0039b432b7","reading_time":4}},{"node":{"id":"Ghost__Post__5fb434904a99b50039ce6d86","title":"Traefik Hackaethon Is a Wrap","slug":"traefik-hackaethon-is-a-wrap","featured":true,"feature_image":"https://containous.ghost.io/content/images/2020/11/Traefik-Hackaethon-Is-a-Wrap.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/bf1fb8321e805e8c0f912464d2deed79/47498/Traefik-Hackaethon-Is-a-Wrap.jpg","srcSet":"/static/bf1fb8321e805e8c0f912464d2deed79/9dc27/Traefik-Hackaethon-Is-a-Wrap.jpg 300w,\n/static/bf1fb8321e805e8c0f912464d2deed79/4fe8c/Traefik-Hackaethon-Is-a-Wrap.jpg 600w,\n/static/bf1fb8321e805e8c0f912464d2deed79/47498/Traefik-Hackaethon-Is-a-Wrap.jpg 1200w,\n/static/bf1fb8321e805e8c0f912464d2deed79/52258/Traefik-Hackaethon-Is-a-Wrap.jpg 1800w,\n/static/bf1fb8321e805e8c0f912464d2deed79/a41d1/Traefik-Hackaethon-Is-a-Wrap.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Traefik Labs inaugural Traefik Hackaethon is a wrap. The event took place over three days and included multiple contributors from around the world. ","custom_excerpt":"Traefik Labs inaugural Traefik Hackaethon is a wrap. The event took place over three days and included multiple contributors from around the world. ","visibility":"public","created_at_pretty":"17 November, 2020","published_at_pretty":"November 24, 2020","updated_at_pretty":"24 November, 2020","created_at":"2020-11-17T20:37:36.000+00:00","published_at":"2020-11-24T05:42:29.000+00:00","updated_at":"2020-11-24T15:56:04.000+00:00","meta_title":"Traefik Hackaethon is a Wrap","meta_description":"Traefik Labs inaugural Traefik Hackaethon is a wrap. The event took place over three days and included multiple contributors from around the world. ","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/11/Traefik-Hackaethon-Is-a-Wrap---Twitter.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Community","slug":"community","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Traefik Labs inaugural Traefik Hackaethon\n[https://traefik.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/] \nis a wrap. The event took place over three days on a Discord server that\nincluded contributors from around the world. Over 50 individuals joined the\nevent and contributed several new plugins for Traefik, multiple bug fixes for\nYaegi, and new features and capabilities for Traefik itself. This event was the\nfirst time Traefik Labs officially organized a hackathon. We couldn’t be more\npleased with the collaboration between first-time contributors and long-time\nmaintainers within our community.\n\nContributions Are Welcome Here\nThere are two distinct categories of contributions for this event: new plugins\nfor Traefik Pilot [https://pilot.traefik.io/] and pull requests for our open\nsource projects Traefik [https://github.com/traefik/traefik] and Yaegi\n[https://github.com/traefik/yaegi]. Over a dozen individual contributors created\nnew plugins, and we were pleasantly surprised by contributions to our open\nsource projects in the form of new features, bug reports, and other\nimprovements.\n\nIn this post, I’ll cover the contributions that the team was most impressed with\nand which were awarded the grand prizes. In addition to the grand prizes,\nseveral others deserve mention for their collective efforts, and I’ll cover\nthose too! I want to give a special thanks to the engineering team at Traefik\nfor engaging with the community and working with them to bring their ideas to\nlife.\n\nThe entire team is looking forward to the next time we do this, and I’ll talk a\nlittle bit about that at the end of this post.\n\nThe Grand Prizes\nOne of the newest features of Traefik is support for adding customized\nfunctionality to the processing of requests handled by the Traefik Proxy. These\nare called Traefik Plugins, and nearly all ten bounties were claimed by our\ncontributors! Each of the grand prizes went to a team or individual who\ncontributed a plugin. The second prize has a bit of a caveat attached to it, but\nmore on that later.\n\nFirst Prize - Team Fail2Ban\nhttps://pilot.traefik.io/plugins/280093067746214409/fail2-ban\n\n [https://pilot.traefik.io/plugins/280093067746214409/fail2-ban]\n\nThe first prize went to a team that was formed by a few contributors who had\nearlier worked on another plugin named Header Transformation\n[https://pilot.traefik.io/plugins/279923829278507529/header-transformation] \n(more about that below). One of the contributors not only produced a great blog\npost [https://blog.moulard.org/traefik-hackaethon/] about their experience with\nthe event, but they came together to create a handy plugin that will block\nrequests originating from a source that fails to authenticate after a specific\nnumber of times. While the concept of Fail2ban\n[https://en.wikipedia.org/wiki/Fail2ban] isn’t necessarily new, nor is the\nimplementation of it within a reverse proxy, this is the first time it’s become\naccessible without the use of external dependencies, complex iptables\n[https://en.wikipedia.org/wiki/Iptables], or integrations with commercial\npackages. The implementation is complete and functionality impressive, given the\ntight deadlines and scope of the plugin. Thank you to Tom and the team for\nputting together two great plugins.\n\nSecond Prize - Team Brotli\nhttps://github.com/traefik/yaegi/pulls?q=is%3Apr+author%3Arsteube\n\n [https://github.com/traefik/yaegi/pulls?q=is%3Apr+author%3Arsteube]\n\nThis plugin (that is still in progress) gets the second place award after the\ncreator worked to implement a compression algorithm ported entirely over to Go,\nwhich coincidentally helped us bring even more compatibility to our runtime Go\ninterpreter Yaegi [https://github.com/traefik/yaegi]. When we kicked off this\nHackathon, we knew that the underlying engine that interprets code in real time,\nusually compiled, is still considered experimental. That didn’t stop this\ncontributor. He worked all three days with Marc, the Yaegi project lead, to\nidentify and fix numerous issues they found while incorporating the ported\ncompression algorithm. This work led to several PRs and improvements made by the\nauthor and the Yaegi team. While the plugin wasn’t eligible for the plugin\nbounty, we felt his contributions to the Yaegi project were so impactful that\nthis contributor deserved the second grand prize.\n\nThird Prize - Team Containers On-Demand\nhttps://pilot.traefik.io/plugins/280027003970650633/containers-on-demand\n\n\n\nImagine being able to scale up services from zero with Traefik when the load\nbalancer receives a request. Two developers on this team hatched this idea\ntogether after discussing the concept and built a service that integrates with\nDocker Swarm to interact with the Docker API. The judges felt this plugin\ndeserved the grand prize for two distinct reasons: First, developers’\npersistence in finding a solution that works given the design constraints; and\nsecond, their creativity in deciding what to build. The plugin engine was\ncreated for users to be creative and bend Traefik in ways the developers at\nTraefik Labs might never have considered. This team’s contribution fits nicely\ninto the vision the team had.\n\nPlugin Bounties\nEach of the above plugins was awarded a bounty (except for Brotli, since it’s\ntechnically still a WIP), but there are a few plugins that deserve mention.\n\nTraefik Fault Injection\nhttps://pilot.traefik.io/plugins/279918789803378185/fault-injection\n\nPurposely introducing faults and errors into an environment is a practice known\nas chaos engineering. This plugin allows for failures to be induced\nprogrammatically via the load balancer. It can be used to purposely inject\nfailures of a specific type and rate to any service. Teams that are looking to\nbuild for resilience and solutions engineers who are looking to induce failures\nwithout having to modify application source code may find this plugin useful.\n\nHeader Transformation\nhttps://pilot.traefik.io/plugins/279923829278507529/header-transformation\n\nAuthored by Team Fail2ban, this plugin allows for headers to be modified based\non simple regex-based rulesets: Set, Rename, Del, and Join. Using these rules,\noperators can modify headers sent from the client before they reach their\nservice destination.\n\nDatadog Event\nhttps://pilot.traefik.io/plugins/280005610925195785/datadog-event\n\nOperators who install this plugin may generate an event in Datadog when a\nresponse code or contents matches a regex-based rule.\n\nOpen Source Contributions\nWe saw several PRs opened against Yaegi and Traefik Proxy. These included bug\nfixes, documentation improvements, new features, and capabilities. Below are two\nof the larger pull requests proposed, and while they’re both incomplete, we want\nto thank the authors for their contribution and hard work.\n\nExponential Backoff for Retry Middleware\nhttps://github.com/traefik/traefik/pull/7460\n\nThe author of this PR initially tried to implement a DynamoDB cache plugin, but\nhe encountered a limitation with the AWS SDK and Yaegi. Instead of giving up, he\njumped right into an open issue and started working with the open source\nengineers at Traefik to develop a solution.\n\nFluentD Log Hook\nhttps://github.com/bearstech/traefik/pull/1\n\nThis work is incomplete, but it seems to be ninety-percent there. This feature,\nwhen merged, would allow operators of Traefik to directly connect access logs to\na log exporter, rather than having to use a log scraping implementation. We’re\nlooking forward to seeing this feature finished up and opened as a PR.\n\nAnd ... It's A Wrap\n\n\nWe couldn’t be more excited to see the contributions and collaboration at our\nfirst Traefik Hackaethon. We’ll be doing this again next year and have already\nstarted planning for the spring. In the meantime, our team would love to hear\nfrom you on ideas for themes and bounties. We’ve opened a thread\n[https://community.traefik.io/t/traefik-hackaethon-2-0/8632] on our community\nforums to discuss what you’d like to see the next time.\n\nThank you to all the participants, and your contributions to the Traefik\necosystem are sincerely appreciated. We can’t wait to see what you’re going to\nbuild next.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/11/Traefik-Hackaethon-Is-a-Wrap-1.jpg\" class=\"kg-image\" alt=\"Traefik Hackaethon Is a Wrap\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/11/Traefik-Hackaethon-Is-a-Wrap-1.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/11/Traefik-Hackaethon-Is-a-Wrap-1.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/11/Traefik-Hackaethon-Is-a-Wrap-1.jpg 1600w, https://containous.ghost.io/content/images/2020/11/Traefik-Hackaethon-Is-a-Wrap-1.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Traefik Labs inaugural <a href=\"https://traefik.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/\">Traefik Hackaethon</a> is a wrap. The event took place over three days on a Discord server that included contributors from around the world. Over 50 individuals joined the event and contributed several new plugins for Traefik, multiple bug fixes for Yaegi, and new features and capabilities for Traefik itself. This event was the first time Traefik Labs officially organized a hackathon. We couldn’t be more pleased with the collaboration between first-time contributors and long-time maintainers within our community.</p><!--kg-card-begin: markdown--><h2 id=\"contributionsarewelcomehere\">Contributions Are Welcome Here</h2>\n<!--kg-card-end: markdown--><p>There are two distinct categories of contributions for this event: new plugins for <a href=\"https://pilot.traefik.io/\">Traefik Pilot</a> and pull requests for our open source projects <a href=\"https://github.com/traefik/traefik\">Traefik</a> and <a href=\"https://github.com/traefik/yaegi\">Yaegi</a>. Over a dozen individual contributors created new plugins, and we were pleasantly surprised by contributions to our open source projects in the form of new features, bug reports, and other improvements.</p><p>In this post, I’ll cover the contributions that the team was most impressed with and which were awarded the grand prizes. In addition to the grand prizes, several others deserve mention for their collective efforts, and I’ll cover those too! I want to give a special thanks to the engineering team at Traefik for engaging with the community and working with them to bring their ideas to life.</p><p>The entire team is looking forward to the next time we do this, and I’ll talk a little bit about that at the end of this post.</p><!--kg-card-begin: markdown--><h2 id=\"thegrandprizes\">The Grand Prizes</h2>\n<p>One of the newest features of Traefik is support for adding customized functionality to the processing of requests handled by the Traefik Proxy. These are called Traefik Plugins, and nearly all ten bounties were claimed by our contributors! Each of the grand prizes went to a team or individual who contributed a plugin. The second prize has a bit of a caveat attached to it, but more on that later.</p>\n<h3 id=\"firstprizeteamfail2ban\">First Prize - Team Fail2Ban</h3>\n<p><a href=\"https://pilot.traefik.io/plugins/280093067746214409/fail2-ban\">https://pilot.traefik.io/plugins/280093067746214409/fail2-ban</a></p>\n<p><a href=\"https://pilot.traefik.io/plugins/280093067746214409/fail2-ban\"><img style=\"float: right; margin: 10px; width: 260px;\" src=\"https://containous.ghost.io/content/images/2020/11/fail2ban-snap.png\" alt=\"Fail2Ban Plugin\"></a></p>\n<p>The first prize went to a team that was formed by a few contributors who had earlier worked on another plugin named <a href=\"https://pilot.traefik.io/plugins/279923829278507529/header-transformation\">Header Transformation</a> (more about that below). One of the contributors not only produced a <a href=\"https://blog.moulard.org/traefik-hackaethon/\">great blog post</a> about their experience with the event, but they came together to create a handy plugin that will block requests originating from a source that fails to authenticate after a specific number of times. While the concept of <a href=\"https://en.wikipedia.org/wiki/Fail2ban\" rel=\"nofollow\">Fail2ban</a> isn’t necessarily new, nor is the implementation of it within a reverse proxy, this is the first time it’s become accessible without the use of external dependencies, complex <a href=\"https://en.wikipedia.org/wiki/Iptables\" rel=\"nofollow\">iptables</a>, or integrations with commercial packages. The implementation is complete and functionality impressive, given the tight deadlines and scope of the plugin. Thank you to Tom and the team for putting together two great plugins.</p>\n<h3 id=\"secondprizeteambrotli\">Second Prize - Team Brotli</h3>\n<p><a href=\"https://github.com/traefik/yaegi/pulls?q=is%3Apr+author%3Arsteube\">https://github.com/traefik/yaegi/pulls?q=is%3Apr+author%3Arsteube</a></p>\n<p><a href=\"https://github.com/traefik/yaegi/pulls?q=is%3Apr+author%3Arsteube\"><img style=\"float: right; margin: 10px; width: 260px\" src=\"https://containous.ghost.io/content/images/2020/11/brotli-snap.png\" alt=\"Team Brotli Contributions\"></a></p>\n<p>This plugin (that is still in progress) gets the second place award after the creator worked to implement a compression algorithm ported entirely over to Go, which coincidentally helped us bring even more compatibility to our <a href=\"https://github.com/traefik/yaegi\">runtime Go interpreter Yaegi</a>. When we kicked off this Hackathon, we knew that the underlying engine that interprets code in real time, usually compiled, is still considered experimental. That didn’t stop this contributor. He worked all three days with Marc, the Yaegi project lead, to identify and fix numerous issues they found while incorporating the ported compression algorithm. This work led to several PRs and improvements made by the author and the Yaegi team. While the plugin wasn’t eligible for the plugin bounty, we felt his contributions to the Yaegi project were so impactful that this contributor deserved the second grand prize.</p>\n<h3 id=\"thirdprizeteamcontainersondemand\">Third Prize - Team Containers On-Demand</h3>\n<p><a href=\"https://pilot.traefik.io/plugins/280027003970650633/containers-on-demand\">https://pilot.traefik.io/plugins/280027003970650633/containers-on-demand</a></p>\n<p><a https://containous.ghost.io/blog/traefik-hackaethon-is-a-wrap/href=\"\"><img style=\"float: right; margin: 10px; width: 260px;\" src=\"https://containous.ghost.io/content/images/2020/11/cod-snap.png\" alt=\"Containers On-Demand Plugin\"></a></p>\n<p>Imagine being able to scale up services from zero with Traefik when the load balancer receives a request. Two developers on this team hatched this idea together after discussing the concept and built a service that integrates with Docker Swarm to interact with the Docker API. The judges felt this plugin deserved the grand prize for two distinct reasons: First, developers’ persistence in finding a solution that works given the design constraints; and second, their creativity in deciding what to build. The plugin engine was created for users to be creative and bend Traefik in ways the developers at Traefik Labs might never have considered. This team’s contribution fits nicely into the vision the team had.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"pluginbounties\">Plugin Bounties</h2>\n<p>Each of the above plugins was awarded a bounty (except for Brotli, since it’s technically still a WIP), but there are a few plugins that deserve mention.</p>\n<h3 id=\"traefikfaultinjection\">Traefik Fault Injection</h3>\n<p><a href=\"https://pilot.traefik.io/plugins/279918789803378185/fault-injection\">https://pilot.traefik.io/plugins/279918789803378185/fault-injection</a></p>\n<p>Purposely introducing faults and errors into an environment is a practice known as chaos engineering. This plugin allows for failures to be induced programmatically via the load balancer. It can be used to purposely inject failures of a specific type and rate to any service. Teams that are looking to build for resilience and solutions engineers who are looking to induce failures without having to modify application source code may find this plugin useful.</p>\n<h3 id=\"headertransformation\">Header Transformation</h3>\n<p><a href=\"https://pilot.traefik.io/plugins/279923829278507529/header-transformation\">https://pilot.traefik.io/plugins/279923829278507529/header-transformation</a></p>\n<p>Authored by Team Fail2ban, this plugin allows for headers to be modified based on simple regex-based rulesets: <code>Set</code>, <code>Rename</code>, <code>Del</code>, and <code>Join</code>. Using these rules, operators can modify headers sent from the client before they reach their service destination.</p>\n<h3 id=\"datadogevent\">Datadog Event</h3>\n<p><a href=\"https://pilot.traefik.io/plugins/280005610925195785/datadog-event\">https://pilot.traefik.io/plugins/280005610925195785/datadog-event</a></p>\n<p>Operators who install this plugin may generate an event in Datadog when a response code or contents matches a regex-based rule.</p>\n<h2 id=\"opensourcecontributions\">Open Source Contributions</h2>\n<p>We saw several PRs opened against Yaegi and Traefik Proxy. These included bug fixes, documentation improvements, new features, and capabilities. Below are two of the larger pull requests proposed, and while they’re both incomplete, we want to thank the authors for their contribution and hard work.</p>\n<h3 id=\"exponentialbackoffforretrymiddleware\">Exponential Backoff for Retry Middleware</h3>\n<p><a href=\"https://github.com/traefik/traefik/pull/7460\">https://github.com/traefik/traefik/pull/7460</a></p>\n<p>The author of this PR initially tried to implement a DynamoDB cache plugin, but he encountered a limitation with the AWS SDK and Yaegi. Instead of giving up, he jumped right into an open issue and started working with the open source engineers at Traefik to develop a solution.</p>\n<h3 id=\"fluentdloghook\">FluentD Log Hook</h3>\n<p><a href=\"https://github.com/bearstech/traefik/pull/1\">https://github.com/bearstech/traefik/pull/1</a></p>\n<p>This work is incomplete, but it seems to be ninety-percent there. This feature, when merged, would allow operators of Traefik to directly connect access logs to a log exporter, rather than having to use a log scraping implementation. We’re looking forward to seeing this feature finished up and opened as a PR.</p>\n<h2 id=\"anditsawrap\">And ... It's A Wrap</h2>\n<p><img src=\"https://containous.ghost.io/content/images/2020/11/Haekaton-scene.png\" alt=\"Haekaton-scene\"></p>\n<p>We couldn’t be more excited to see the contributions and collaboration at our first Traefik Hackaethon. We’ll be doing this again next year and have already started planning for the spring. In the meantime, our team would love to hear from you on ideas for themes and bounties. We’ve <a href=\"https://community.traefik.io/t/traefik-hackaethon-2-0/8632\">opened a thread</a> on our community forums to discuss what you’d like to see the next time.</p>\n<p>Thank you to all the participants, and your contributions to the Traefik ecosystem are sincerely appreciated. We can’t wait to see what you’re going to build next.</p>\n<!--kg-card-end: markdown--><p></p>","url":"https://containous.ghost.io/blog/traefik-hackaethon-is-a-wrap/","canonical_url":null,"uuid":"cd60da37-1574-4e2d-8dc8-5f6b1a207c8b","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5fb434904a99b50039ce6d86","reading_time":5}},{"node":{"id":"Ghost__Post__5f7f21459ccef80039928ddc","title":"Leveraging your Ingress Controller to easily migrate to Kubernetes","slug":"leveraging-your-ingress-controller-to-easily-migrate-to-kubernetes","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/ea29e913bf4a4db59cb25046b9525998/47498/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg","srcSet":"/static/ea29e913bf4a4db59cb25046b9525998/9dc27/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg 300w,\n/static/ea29e913bf4a4db59cb25046b9525998/4fe8c/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg 600w,\n/static/ea29e913bf4a4db59cb25046b9525998/47498/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg 1200w,\n/static/ea29e913bf4a4db59cb25046b9525998/52258/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg 1800w,\n/static/ea29e913bf4a4db59cb25046b9525998/a41d1/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"In this article, we’ll delve into the question of migrating legacy applications by discussing the specific challenges these workloads pose and outlining a strategy to overcome them.","custom_excerpt":"In this article, we’ll delve into the question of migrating legacy applications by discussing the specific challenges these workloads pose and outlining a strategy to overcome them.","visibility":"public","created_at_pretty":"08 October, 2020","published_at_pretty":"November 10, 2020","updated_at_pretty":"03 December, 2020","created_at":"2020-10-08T14:25:09.000+00:00","published_at":"2020-11-10T01:46:18.000+00:00","updated_at":"2020-12-03T02:14:07.000+00:00","meta_title":"Leveraging your Ingress Controller to easily migrate to Kubernetes","meta_description":"This article delves into migrating legacy applications by discussing the specific challenges these workloads pose and outlining a strategy to overcome them.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes---Twitter.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Kubernetes","slug":"kubernetes","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Many enterprise organizations choose Kubernetes (k8s) [https://kubernetes.io] as\nthe foundation of their IT modernization efforts due to its alignment with cloud\nnative practices. However, a question naturally arises during the adoption\nprocess: How should existing legacy applications be handled as part of a broader\nKubernetes migration? As it turns out, the answer ties to the Ingress\nController, one of the core components in a Kubernetes cluster. In this article,\nwe’ll delve into the question of migrating legacy applications by discussing the\nspecific challenges these workloads pose and outlining a strategy to overcome\nthem.\n\nLegacy applications and Kubernetes\nThe functionality provided by legacy workloads typically encapsulates\nsignificant business value for organizations. Having been designed and\nimplemented in an earlier era, they also tend to gravitate towards monolithic\narchitectures powered by older programming languages and toolchains. For these\nreasons, they're often stagnant with little ongoing development other than to\naddress high priority bugs or significant security vulnerabilities.\n\nHere lies the dilemma: on the one hand, these legacy workloads are highly\nvaluable. Modifying them in any way, including their operating environment,\ncreates risks associated with the business's daily operation. On the other hand,\nleaving them out of a Kubernetes migration means maintaining older operating\nenvironments and preventing teams from reaping the benefits provided by\nKubernetes with these critical applications. What's needed is a way for IT\nleaders to mitigate the migration risks associated with legacy applications.\n\nDiscussions around Ingress Controllers often arise as part of networking and\nrouting in Kubernetes, particularly in connecting external users to applications\n[https://traefik.io/blog/connecting-users-to-applications-with-kubernetes-ingress-controllers/]\n. Due to their strategic placement in the overall architecture, in practice,\ntheir capabilities can extend benefits to use cases well beyond just\nconnectivity. As we'll discuss in more detail, used effectively, Ingress\nControllers can help ease the process of migrating and running legacy\napplications on Kubernetes by reducing or mitigating many of the risks that may\notherwise prevent IT from making the transition process. To illustrate where\nIngress Controllers fit into the overall migration picture, consider a\nhigh-level outline of a general migration strategy (we'll dive into each area\nnext):\n\nMigrating your Legacy Applications using Kubernetes Ingress * Deploy legacy\n   workloads on Kubernetes - Get legacy applications running on k8s as simply\n   and quickly as possible\n * Select an option\n   for ongoing development / maintenance: * Build around a legacy application -\n      Use Ingress Controller functionality to route traffic in a manner which\n      allows for building on top of legacy without modifying it\n    * Build your way out of a legacy\n      application - Use Ingress Controller functionality to enable iterative\n      refactoring of legacy\n   \n   \n\nLift and Shift: Deploy legacy workloads on Kubernetes\nThe first step of our migration strategy entails establishing a baseline for\ndeploying legacy codebase running on Kubernetes. The goal is to help achieve a\nstandardizing operating environment for all workloads and serve as a starting\npoint for further improvements. To accomplish this, one must containerize the\nmonolithic codebase and its associated dependencies. While there is no single\nrecipe for containerization that will work across all applications, there are\nwell-known items that need addressing as part of a \"lift and shift\" operation.\n\nFirst, an appropriate Docker base image should be selected or defined for the\nlegacy application. Depending upon the language and technology stack used in its\nimplementation, there may be viable candidates available on Docker Hub\n[https://hub.docker.com/]. Otherwise, DevOps engineers will need to craft a\ncustom image. Once the team establishes a base image, they leverage it to\niterate on the monolithic application's candidate release images. In some cases,\nengineers will augment base images by injecting build artifacts. In others, it\nmay be necessary to generate artifacts using the base image itself through\nmulti-stage build processes. Once the containerized image is available, it can\nbe deployed onto a Kubernetes cluster and validated.\n\nBuild around legacy applications with Ingress Controllers\nOnce the team establishes a baseline deployment, they have options for managing\nthe future legacy workload. There will inevitably be a need to extend the\nmonolith functionally, and this is where Ingress Controllers can help reduce\ncomplexity and risk. Specifically, instead of taking an approach where\ndevelopers must modify or refactor the legacy applications, the core application\ncan be left intact while using Ingress Controllers. This approach permits\nadditional functionality by injecting new services that logically sit between\nend users and the monolith. Since developers are empowered to build these\nservices from scratch, they are implementable using cloud native best practices.\nTraffic from external users routes to the intervening service layer by\nconfiguring the Ingress Controller for the cluster. When requests are received,\nthe containerized legacy application operates as needed for specific\nfunctionality.\n\nBuild away from legacy applications with Ingress Controllers\nAn alternative approach towards realizing additional functionality around a\nlegacy application once deployed on Kubernetes is to employ the so-called\nStrangler pattern. As may be apparent from the name, this strategy consists of\nreplacing legacy codebases gradually by migrating features to new microservice\nimplementations, which may also incorporate additional capabilities. Compared to\na wholesale reimplementation, the overall risk spreads over time. In addition,\nif needed, teams can always fall back to the original implementation since it is\nleft intact. The Ingress Controller is the key to enabling this strategy on\nKubernetes as it allows operators to route traffic from external users to the\nrefactored microservices versus the legacy application. As functionality\ncontinues to shift away from the monolith, it is \"strangled\" out, and\neventually, the legacy application is ready to be removed from the cluster\naltogether.\n\nConclusion\nFor many enterprise organizations, legacy applications continue to support\ncritical processes that form the business's backbone. Therefore, IT leaders need\nto understand potential strategies for handling these workloads during a\nKubernetes migration.\n\nIn this article, we've reviewed how Ingress Controllers can significantly reduce\nthe risk of legacy migrations while also enabling continued development around\nlegacy implementations. While the directions outlined are available today with\navailable Ingress Controllers, this area is also rapidly evolving within the\nKubernetes ecosystem, as evidenced by its Service API evolution\n[https://traefik.io/blog/kubernetes-ingress-service-api-demystified/].\nEnterprises can safely assume that the ability to leverage resources such as\nIngress Controllers to help ease migration challenges is only going to improve\nin the future.\n\nLearn more about Traefik Enterprise\n[https://info.traefik.io/en/request-demo-traefik-enterprise] today and learn how\nbusinesses are leveraging the power of enterprise-grade Kubernetes Ingress to\nsolve their most demanding challenges.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes.jpg\" class=\"kg-image\" alt=\"Leveraging your Ingress Controller to easily migrate to Kubernetes\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes.jpg 1600w, https://containous.ghost.io/content/images/2020/11/Leveraging-your-Ingress-Controller-to-easily-migrate-to-Kubernetes.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: markdown--><p>Many enterprise organizations choose <a href=\"https://kubernetes.io\" target=\"_blank\" rel=\"nofollow\">Kubernetes (k8s)</a> as the foundation of their IT modernization efforts due to its alignment with cloud native practices. However, a question naturally arises during the adoption process: How should existing legacy applications be handled as part of a broader Kubernetes migration? As it turns out, the answer ties to the Ingress Controller, one of the core components in a Kubernetes cluster. In this article, we’ll delve into the question of migrating legacy applications by discussing the specific challenges these workloads pose and outlining a strategy to overcome them.</p>\n<h2 id=\"legacyapplicationsandkubernetes\">Legacy applications and Kubernetes</h2>\n<p>The functionality provided by legacy workloads typically encapsulates significant business value for organizations. Having been designed and implemented in an earlier era, they also tend to gravitate towards monolithic architectures powered by older programming languages and toolchains. For these reasons, they're often stagnant with little ongoing development other than to address high priority bugs or significant security vulnerabilities.</p>\n<p>Here lies the dilemma: on the one hand, these legacy workloads are highly valuable. Modifying them in any way, including their operating environment, creates risks associated with the business's daily operation. On the other hand, leaving them out of a Kubernetes migration means maintaining older operating environments and preventing teams from reaping the benefits provided by Kubernetes with these critical applications. What's needed is a way for IT leaders to mitigate the migration risks associated with legacy applications.</p>\n<p>Discussions around Ingress Controllers often arise as part of networking and routing in Kubernetes, particularly in <a href=\"https://traefik.io/blog/connecting-users-to-applications-with-kubernetes-ingress-controllers/\">connecting external users to applications</a>. Due to their strategic placement in the overall architecture, in practice, their capabilities can extend benefits to use cases well beyond just connectivity. As we'll discuss in more detail, used effectively, Ingress Controllers can help ease the process of migrating and running legacy applications on Kubernetes by reducing or mitigating many of the risks that may otherwise prevent IT from making the transition process. To illustrate where Ingress Controllers fit into the overall migration picture, consider a high-level outline of a general migration strategy (we'll dive into each area next):</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/10/Strangler_Pattern_Blog_Image.svg\" class=\"kg-image\" alt=\"Migrating your Legacy Applications using Kubernetes Ingress\"><figcaption>Migrating your Legacy Applications using Kubernetes Ingress</figcaption></figure><!--kg-card-begin: markdown--><ul>\n<li>Deploy legacy workloads on Kubernetes - Get legacy applications running on k8s as simply and quickly as possible</li>\n<li>Select an option for ongoing development / maintenance:\n<ul>\n<li>Build around a legacy application - Use Ingress Controller functionality to route traffic in a manner which allows for building on top of legacy without modifying it</li>\n<li>Build your way out of a legacy application - Use Ingress Controller functionality to enable iterative refactoring of legacy</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"liftandshiftdeploylegacyworkloadsonkubernetes\">Lift and Shift: Deploy legacy workloads on Kubernetes</h2>\n<p>The first step of our migration strategy entails establishing a baseline for deploying legacy codebase running on Kubernetes. The goal is to help achieve a standardizing operating environment for all workloads and serve as a starting point for further improvements. To accomplish this, one must containerize the monolithic codebase and its associated dependencies. While there is no single recipe for containerization that will work across all applications, there are well-known items that need addressing as part of a &quot;lift and shift&quot; operation.</p>\n<p>First, an appropriate Docker base image should be selected or defined for the legacy application. Depending upon the language and technology stack used in its implementation, there may be viable candidates available on <a href=\"https://hub.docker.com/\" rel=\"nofollow\" target=\"_blank\">Docker Hub</a>. Otherwise, DevOps engineers will need to craft a custom image. Once the team establishes a base image, they leverage it to iterate on the monolithic application's candidate release images. In some cases, engineers will augment base images by injecting build artifacts. In others, it may be necessary to generate artifacts using the base image itself through multi-stage build processes. Once the containerized image is available, it can be deployed onto a Kubernetes cluster and validated.</p>\n<h2 id=\"buildaroundlegacyapplicationswithingresscontrollers\">Build around legacy applications with Ingress Controllers</h2>\n<p>Once the team establishes a baseline deployment, they have options for managing the future legacy workload. There will inevitably be a need to extend the monolith functionally, and this is where Ingress Controllers can help reduce complexity and risk. Specifically, instead of taking an approach where developers must modify or refactor the legacy applications, the core application can be left intact while using Ingress Controllers. This approach permits additional functionality by injecting new services that logically sit between end users and the monolith. Since developers are empowered to build these services from scratch, they are implementable using cloud native best practices. Traffic from external users routes to the intervening service layer by configuring the Ingress Controller for the cluster. When requests are received, the containerized legacy application operates as needed for specific functionality.</p>\n<h2 id=\"buildawayfromlegacyapplicationswithingresscontrollers\">Build away from legacy applications with Ingress Controllers</h2>\n<p>An alternative approach towards realizing additional functionality around a legacy application once deployed on Kubernetes is to employ the so-called Strangler pattern. As may be apparent from the name, this strategy consists of replacing legacy codebases gradually by migrating features to new microservice implementations, which may also incorporate additional capabilities. Compared to a wholesale reimplementation, the overall risk spreads over time. In addition, if needed, teams can always fall back to the original implementation since it is left intact. The Ingress Controller is the key to enabling this strategy on Kubernetes as it allows operators to route traffic from external users to the refactored microservices versus the legacy application. As functionality continues to shift away from the monolith, it is &quot;strangled&quot; out, and eventually, the legacy application is ready to be removed from the cluster altogether.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>For many enterprise organizations, legacy applications continue to support critical processes that form the business's backbone. Therefore, IT leaders need to understand potential strategies for handling these workloads during a Kubernetes migration.</p>\n<p>In this article, we've reviewed how Ingress Controllers can significantly reduce the risk of legacy migrations while also enabling continued development around legacy implementations. While the directions outlined are available today with available Ingress Controllers, this area is also rapidly evolving within the Kubernetes ecosystem, as evidenced by its <a href=\"https://traefik.io/blog/kubernetes-ingress-service-api-demystified/\">Service API evolution</a>. Enterprises can safely assume that the ability to leverage resources such as Ingress Controllers to help ease migration challenges is only going to improve in the future.</p>\n<p><a href=\"https://info.traefik.io/en/request-demo-traefik-enterprise\">Learn more about Traefik Enterprise</a> today and learn how businesses are leveraging the power of enterprise-grade Kubernetes Ingress to solve their most demanding challenges.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/leveraging-your-ingress-controller-to-easily-migrate-to-kubernetes/","canonical_url":null,"uuid":"0428ce65-eac9-4f98-9d45-20c721ff9acb","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f7f21459ccef80039928ddc","reading_time":4}},{"node":{"id":"Ghost__Post__5f7f0f1a9ccef80039928d25","title":"Traefik Hackaethon 2020: Middleware Plugins Brain Dump","slug":"traefik-hackaethon-2020-middleware-plugins-brain-dump","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/979b7c781828b335e54a8c988b9c18c8/47498/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg","srcSet":"/static/979b7c781828b335e54a8c988b9c18c8/9dc27/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg 300w,\n/static/979b7c781828b335e54a8c988b9c18c8/4fe8c/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg 600w,\n/static/979b7c781828b335e54a8c988b9c18c8/47498/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg 1200w,\n/static/979b7c781828b335e54a8c988b9c18c8/52258/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg 1800w,\n/static/979b7c781828b335e54a8c988b9c18c8/a41d1/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"The team at Traefik Labs will be hosting a Hackathon next week, and plugins are a significant theme. Awards, bounties, and prizes are available for those who participate. ","custom_excerpt":"The team at Traefik Labs will be hosting a Hackathon next week, and plugins are a significant theme. Awards, bounties, and prizes are available for those who participate. ","visibility":"public","created_at_pretty":"08 October, 2020","published_at_pretty":"October 12, 2020","updated_at_pretty":"03 November, 2020","created_at":"2020-10-08T13:07:38.000+00:00","published_at":"2020-10-12T23:04:00.000+00:00","updated_at":"2020-11-03T17:21:07.000+00:00","meta_title":"Traefik Hackaethon 2020: Middleware Plugins Brain Dump","meta_description":"The team at Traefik Labs will be hosting a Hackathon next week, and plugins are a significant theme. ","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump---Twitter.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Announcements","slug":"announcements","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"One of the most powerful features of the Traefik software-based load balancer is\nits support for middlewares\n[https://doc.traefik.io/traefik/middlewares/overview/]. These packages are\nresponsible for applying transformations, validations, redirections, omissions,\nand additions to requests before passing them on, either to another middleware\npackage or to their final destination.\n\nOver the past several years, Traefik has received dozens of ideas and concepts\nfor middlewares through feature and pull requests. Some of these proposals\nsuggested additional functionality for existing middlewares. Others introduced\nbespoke middleware for specific use cases.\n\nWhen these proposals weren't aligned to the vision of the Traefik community they\nlanguished on the Traefik issue board. There they lay dormant, waiting for the\nday that users could easily build custom plugins for Traefik\n[https://traefik.io/blog/unleash-custom-networking-logic-with-traefik-plugins/].\nThat day is here, and this post will provide an outline for those interested in\nbuilding and extending the capabilities of Traefik with their own middlewares.\n\nThe team at Traefik Labs will be hosting a Hackathon next week, and plugins are\na significant theme. Awards, bounties, and prizes are available for those who\nparticipate. You can learn more and sign up here\n[https://info.traefik.io/traefik-hackaethon-2020]. In the meantime, here are\nsome great ideas for middleware plugins that drew from issues on the Traefik\nrepository.\n\nOct 20-22nd: Traefik's Inaugeral Hackaethon - Sign Up Today\n[https://traefik.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/]\nPopular Middleware Ideas\nForward-Auth with Selective Headers\nhttps://github.com/containous/traefik/issues/6493\n\nThe forward auth middleware included with Traefik will forward all headers\nincluded in the original request. But in some cases, users may want to exclude\nspecific headers from the forwarded request. Instead, they would rather the\nheaders are forwarded only in the response from the auth server.\n\nQuery Parameter Modification\nhttps://github.com/containous/traefik/issues/6276\n\nIn some cases, operators may want to modify the request's query keys or convert\nquery parameters into a path. In either scenario, this can be useful for several\nuse cases. But along with the usefulness comes additional complexity in test\nscenarios and implementations. These constraints make it a prime candidate for\nadoption as a custom plugin.\n\nHeader Transformation\nhttps://github.com/traefik/traefik/issues/6047\n\nThe scope of the Header middleware's current implementation is limited to adding\nor removing headers (which is only available through a file type provider).\nUsers may want to perform more complex operations on headers, such as renaming a\nkey or transforming a value. These operations could be achievable through regex\nor simple pattern matching.\n\nEnhanced Retry and Backoff\nhttps://github.com/traefik/traefik/issues/5282\nhttps://github.com/traefik/traefik/issues/4578\n\nCases exist where operators may want to retry on certain conditions, such as a\n5xx error or connection refused. Without exponential backoff or retries based on\nresponse code, retrying on those parameters isn't feasible. For additional\ninspiration, Spring Cloud Gateway\n[https://cloud.spring.io/spring-cloud-gateway/reference/html/#the-retry-gatewayfilter-factory] \nhas a design that handles both cases.\n\nCustom Response Code Overrides\nhttps://github.com/traefik/traefik/issues/2039\n\nWhen users receive an error message, this can sometimes indicate a particular\nresource's presence or absence. Also, when it’s impossible to modify the\nclient’s behavior this can be worked-around by intercepting an erroneous\nresponse and handling it by return a different error response or page. This\nplugin would effectively intercept the service's error response and map an\nalternative response, such as a 200 response instead of a 501 response, or a 404\nrather than a 401 or 403.\n\nCDN AllowList\nhttps://github.com/traefik/traefik/issues/4145\n\nCDNs publish their IP addresses from consumable public resources. When hosting a\nparticular resource that should only be accessible from the CDN (for\ncache-fronting reasons), it’s logical that users want to block any request that\ndoes not originate from an IP address published on that list.\n\nBasicAuth Overrides\nhttps://github.com/traefik/traefik/issues/4429\n\nIn some instances, users have asked to allow Basic Auth to allow programmatic\noverrides by either a custom header or originating from a specific IP address\n(or set of IP addresses). Both options could be implemented into a custom\nauthentication plugin, with support for IP ranges as well.\n\nRate Limiting Enhancements\nhttps://github.com/traefik/traefik/issues/4548\nhttps://github.com/traefik/traefik/issues/6042\n\nUsers have requested the ability to incorporate multiple rate limiting\nstrategies concurrently; for example, combining client.ip and request.host on a\nsingle frontend. Users have also asked to store rate limiting data external to\nTraefik, enabling more extended duration limits to survive restarts and share\nlimits across multiple instances. These would likely be two separate plugins as\nthey’re two distinctly different features.\n\nResponse Header Redirect\nhttps://github.com/traefik/traefik/issues/5154\n\nThere is a request to allow a service to command Traefik to internally redirect\nto another service provider through a custom header. This capability could be\nuseful when the client doesn't require exposure to an internal redirect's\ndetails.\n\nBrotli Compression\nhttps://github.com/traefik/traefik/issues/4202\n\nThis plugin has already been implemented as a PR to Traefik. However, the\nlicensing model on one of the dependencies prevented it from being merged as-is.\nThis compression middleware would be relatively straightforward to implement as\na plugin.\n\nAdditional Plugin Ideas\nThere are other plugin ideas out there. We don't want to limit your creativity,\neither, so plugin bounties are not limited to this list. As long as the plugin\nisn't trivial and is deemed functionality by the judges, it is eligible for the\nprize. Here are a few more issues if you're not interested in the ideas listed\nabove.\n\n * HTTP Cache Backends - https://github.com/traefik/traefik/issues/878\n * Containers on Demand - https://github.com/traefik/traefik/issues/6993\n * Open Policy Agent - https://github.com/traefik/traefik/issues/4894\n\nWrapping Up\nSign up for the Hackaethon today\n[https://traefik.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/] \nand receive a t-shirt and sticker for participating!In addition to the plugin\nideas curated above, we are working on putting together a list of issues that\ncontributors can work on if they're not interested in building a plugin. We want\nto ensure that anyone can participate in the Hackaethon, including features,\nbugs, and documentation tasks that anyone can pick up and start working on.\n\nFor those interested in building custom plugins, we have a meetup scheduled next\nweek before the Hackaethon to demonstrate how easy they are to develop. You can \nsign up for the plugin meetup\n[https://us02web.zoom.us/webinar/register/WN_9LpcglyRSJy89iEYN0ZsbQ] and receive\nthe link today. We’re looking forward to seeing everyone at the meetup and the\nHackaethon next week and look forward to seeing what you build.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump.jpg\" class=\"kg-image\" alt=\"Traefik Hackaethon 2020: Middleware Plugins Brain Dump\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump.jpg 1600w, https://containous.ghost.io/content/images/2020/10/Traefik-Hackaethon-2020---Middleware-Plugins-Brain-Dump.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: markdown--><p>One of the most powerful features of the Traefik software-based load balancer is its support for <a href=\"https://doc.traefik.io/traefik/middlewares/overview/\">middlewares</a>. These packages are responsible for applying transformations, validations, redirections, omissions, and additions to requests before passing them on, either to another middleware package or to their final destination.</p>\n<!--kg-card-end: markdown--><p>Over the past several years, Traefik has received dozens of ideas and concepts for middlewares through feature and pull requests. Some of these proposals suggested additional functionality for existing middlewares. Others introduced bespoke middleware for specific use cases.</p><!--kg-card-begin: markdown--><p>When these proposals weren't aligned to the vision of the Traefik community they languished on the Traefik issue board. There they lay dormant, waiting for the day that users could easily build <a href=\"https://traefik.io/blog/unleash-custom-networking-logic-with-traefik-plugins/\">custom plugins for Traefik</a>. That day is here, and this post will provide an outline for those interested in building and extending the capabilities of Traefik with their own middlewares.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>The team at Traefik Labs will be hosting a Hackathon next week, and plugins are a significant theme. Awards, bounties, and prizes are available for those who participate. You can learn more and <a href=\"https://info.traefik.io/traefik-hackaethon-2020\">sign up here</a>. In the meantime, here are some great ideas for middleware plugins that drew from issues on the Traefik repository.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/10/Haekaton-scene.svg\" class=\"kg-image\" alt=\"Oct 20-22nd: Traefik's Inaugeral Hackaethon\"><figcaption>Oct 20-22nd: Traefik's Inaugeral Hackaethon - <a href=\"https://traefik.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/\">Sign Up Today</a></figcaption></figure><!--kg-card-begin: markdown--><h2 id=\"popularmiddlewareideas\">Popular Middleware Ideas</h2>\n<h3 id=\"forwardauthwithselectiveheaders\">Forward-Auth with Selective Headers</h3>\n<p><a href=\"https://github.com/containous/traefik/issues/6493\">https://github.com/containous/traefik/issues/6493</a></p>\n<p>The forward auth middleware included with Traefik will forward all headers included in the original request. But in some cases, users may want to exclude specific headers from the forwarded request. Instead, they would rather the headers are forwarded only in the response from the auth server.</p>\n<h3 id=\"queryparametermodification\">Query Parameter Modification</h3>\n<p><a href=\"https://github.com/containous/traefik/issues/6276\">https://github.com/containous/traefik/issues/6276</a></p>\n<p>In some cases, operators may want to modify the request's query keys or convert query parameters into a path. In either scenario, this can be useful for several use cases. But along with the usefulness comes additional complexity in test scenarios and implementations. These constraints make it a prime candidate for adoption as a custom plugin.</p>\n<h3 id=\"headertransformation\">Header Transformation</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/6047\">https://github.com/traefik/traefik/issues/6047</a></p>\n<p>The scope of the Header middleware's current implementation is limited to adding or removing headers (which is only available through a file type provider). Users may want to perform more complex operations on headers, such as renaming a key or transforming a value. These operations could be achievable through regex or simple pattern matching.</p>\n<h3 id=\"enhancedretryandbackoff\">Enhanced Retry and Backoff</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/5282\">https://github.com/traefik/traefik/issues/5282</a><br>\n<a href=\"https://github.com/traefik/traefik/issues/4578\">https://github.com/traefik/traefik/issues/4578</a></p>\n<p>Cases exist where operators may want to retry on certain conditions, such as a 5xx error or connection refused. Without exponential backoff or retries based on response code, retrying on those parameters isn't feasible. For additional inspiration, <a href=\"https://cloud.spring.io/spring-cloud-gateway/reference/html/#the-retry-gatewayfilter-factory\" target=\"_blank\" rel=\"nofollow\">Spring Cloud Gateway</a> has a design that handles both cases.</p>\n<h3 id=\"customresponsecodeoverrides\">Custom Response Code Overrides</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/2039\">https://github.com/traefik/traefik/issues/2039</a></p>\n<p>When users receive an error message, this can sometimes indicate a particular resource's presence or absence. Also, when it’s impossible to modify the client’s behavior this can be worked-around by intercepting an erroneous response and handling it by return a different error response or page. This plugin would effectively intercept the service's error response and map an alternative response, such as a 200 response instead of a 501 response, or a 404 rather than a 401 or 403.</p>\n<h3 id=\"cdnallowlist\">CDN AllowList</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/4145\">https://github.com/traefik/traefik/issues/4145</a></p>\n<p>CDNs publish their IP addresses from consumable public resources. When hosting a particular resource that should only be accessible from the CDN (for cache-fronting reasons), it’s logical that users want to block any request that does not originate from an IP address published on that list.</p>\n<h3 id=\"basicauthoverrides\">BasicAuth Overrides</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/4429\">https://github.com/traefik/traefik/issues/4429</a></p>\n<p>In some instances, users have asked to allow Basic Auth to allow programmatic overrides by either a custom header or originating from a specific IP address (or set of IP addresses). Both options could be implemented into a custom authentication plugin, with support for IP ranges as well.</p>\n<h3 id=\"ratelimitingenhancements\">Rate Limiting Enhancements</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/4548\">https://github.com/traefik/traefik/issues/4548</a><br>\n<a href=\"https://github.com/traefik/traefik/issues/6042\">https://github.com/traefik/traefik/issues/6042</a></p>\n<p>Users have requested the ability to incorporate multiple rate limiting strategies concurrently; for example, combining client.ip and request.host on a single frontend. Users have also asked to store rate limiting data external to Traefik, enabling more extended duration limits to survive restarts and share limits across multiple instances. These would likely be two separate plugins as they’re two distinctly different features.</p>\n<h3 id=\"responseheaderredirect\">Response Header Redirect</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/5154\">https://github.com/traefik/traefik/issues/5154</a></p>\n<p>There is a request to allow a service to command Traefik to internally redirect to another service provider through a custom header. This capability could be useful when the client doesn't require exposure to an internal redirect's details.</p>\n<h3 id=\"brotlicompression\">Brotli Compression</h3>\n<p><a href=\"https://github.com/traefik/traefik/issues/4202\">https://github.com/traefik/traefik/issues/4202</a></p>\n<p>This plugin has already been implemented as a PR to Traefik. However, the licensing model on one of the dependencies prevented it from being merged as-is. This compression middleware would be relatively straightforward to implement as a plugin.</p>\n<h3 id=\"additionalpluginideas\">Additional Plugin Ideas</h3>\n<p>There are other plugin ideas out there. We don't want to limit your creativity, either, so plugin bounties are not limited to this list. As long as the plugin isn't trivial and is deemed functionality by the judges, it is eligible for the prize. Here are a few more issues if you're not interested in the ideas listed above.</p>\n<ul>\n<li>HTTP Cache Backends - <a href=\"https://github.com/traefik/traefik/issues/878\">https://github.com/traefik/traefik/issues/878</a></li>\n<li>Containers on Demand - <a href=\"https://github.com/traefik/traefik/issues/6993\">https://github.com/traefik/traefik/issues/6993</a></li>\n<li>Open Policy Agent - <a href=\"https://github.com/traefik/traefik/issues/4894\">https://github.com/traefik/traefik/issues/4894</a></li>\n</ul>\n<h2 id=\"wrappingup\">Wrapping Up</h2>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/10/Twitter.jpg\" class=\"kg-image\" alt=\"Sign up for the Hackaethon today and receive a t-shirt and sticker for participating!\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/10/Twitter.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/10/Twitter.jpg 1000w, https://containous.ghost.io/content/images/2020/10/Twitter.jpg 1024w\" sizes=\"(min-width: 720px) 720px\"><figcaption><a href=\"https://traefik.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/\">Sign up for the Hackaethon today</a> and receive a t-shirt and sticker for participating!</figcaption></figure><!--kg-card-begin: markdown--><p>In addition to the plugin ideas curated above, we are working on putting together a list of issues that contributors can work on if they're not interested in building a plugin. We want to ensure that anyone can participate in the Hackaethon, including features, bugs, and documentation tasks that anyone can pick up and start working on.</p>\n<p>For those interested in building custom plugins, we have a meetup scheduled next week before the Hackaethon to demonstrate how easy they are to develop. You can <a href=\"https://us02web.zoom.us/webinar/register/WN_9LpcglyRSJy89iEYN0ZsbQ\" rel=\"nofollow\" target=\"_blank\">sign up for the plugin meetup</a> and receive the link today. We’re looking forward to seeing everyone at the meetup and the Hackaethon next week and look forward to seeing what you build.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/traefik-hackaethon-2020-middleware-plugins-brain-dump/","canonical_url":null,"uuid":"c570517f-07fb-4aea-94f4-cc5d9c2ef32f","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f7f0f1a9ccef80039928d25","reading_time":5}},{"node":{"id":"Ghost__Post__5f61f4b1a72a090039800f54","title":"Announcing the Inaugural Traefik Hackaethon 2020 in October","slug":"announcing-the-inaugural-traefik-hackaethon-2020-in-october","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/ba50fc1aabb024410cdee0199dc261fc/47498/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg","srcSet":"/static/ba50fc1aabb024410cdee0199dc261fc/9dc27/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg 300w,\n/static/ba50fc1aabb024410cdee0199dc261fc/4fe8c/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg 600w,\n/static/ba50fc1aabb024410cdee0199dc261fc/47498/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg 1200w,\n/static/ba50fc1aabb024410cdee0199dc261fc/52258/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg 1800w,\n/static/ba50fc1aabb024410cdee0199dc261fc/a41d1/Announcing-the-Inaugural-Traefik-Hackaethon-2020-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Join the team of engineers who maintain Traefik and the Traefik Ambassadors for a week of virtual hacking and collaboration on the open source projects Traefik and Maesh.","custom_excerpt":"Join the team of engineers who maintain Traefik and the Traefik Ambassadors for a week of virtual hacking and collaboration on the open source projects Traefik and Maesh.","visibility":"public","created_at_pretty":"16 September, 2020","published_at_pretty":"September 17, 2020","updated_at_pretty":"12 October, 2020","created_at":"2020-09-16T11:19:13.000+00:00","published_at":"2020-09-17T17:09:59.000+00:00","updated_at":"2020-10-12T23:56:50.000+00:00","meta_title":"Announcing the Inaugural Traefik Hackaethon 2020 in October","meta_description":"Join the team of engineers who maintain Traefik and Traefik Ambassadors for a week of virtual hacking on the open source projects Traefik and Maesh.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020---Twitter.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Announcements","slug":"announcements","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Join the team of engineers who maintain Traefik and the Traefik Ambassadors for\na week of virtual hacking and collaboration on the open source projects Traefik\nand Maesh. The hackathon will take place for three days, across multiple time\nzones, on October 20th through the 22nd. All participants who sign up today\n[https://info.containo.us/traefik-hackaethon-2020] will receive an invitation to\nthe Discord server a few days before the event where they will be able to\nconnect, collaborate, and pair up with other participants and developers to\ncontribute towards making Traefik even better.\n\nAll participants will receive a limited edition t-shirt, stickers, and bonus\nprizes are up for grabs including multiple $100 gift card bounties for plugins,\nand grand prizes of $500, $250, and $100.\n\nParticipate and Collaborate\nTo be eligible as a participant, be sure to sign up for the event below and\ncheck-in for at least one day during the hackaethon and participate in the\nactivities! During the event, you’ll be provided a link where you can provide\ndetails about your contribution, whether you’ve created a Traefik Plugin,\ncontributed to an issue or PR, or had a PR merged in one of our projects. Be\nsure to include your address so we can send you some swag, and enter you for the\ngrand prize drawings.\n\nIn the coming weeks, we’ll post more about the event, so be sure to sign up now\n[https://info.containo.us/traefik-hackaethon-2020] so you can be notified about\nupcoming meetups and blog posts that are related to the event. We’ll be hosting\na meetup about building your own plugin, and posting a blog on ideas for plugin\ndevelopment so keep an eye out.\n\nThere are plenty of cool activities to get involved in, and not all of them\ninvolve writing code:\n\n * Build Traefik Plugins for the newly announced Traefik Pilot Plugin\n   Marketplace\n * Contribute new features, fix bugs, or even reproduce some hard to find bugs\n   in Traefik and Maesh\n * Pair up with other developers and contributors to write documentation, tests,\n   feature requests, and more\n\nSign Up for the Hackaethon 2020 Invitation\n[https://info.containo.us/traefik-hackaethon-2020]\n\nPlugin Bounties\nPlugins are eligible to be awarded a $100 gift card bounty. Successful\nimplementations of a plugin during the Hackaethon may be awarded a bounty after\nmeeting the quality criteria by the judges. Participants may implement their own\nplugin ideas or implement the suggested plugins from the blog post, either are\nequally eligible for the bounty. Up to 10 plugins will each be awarded a $100\ngift card bounty.\n\nQuality Criteria:\n\n * Functionality - Does it do what it says it does\n * Testing - Are there functional unit tests that confirm the functionality\n * Value - Will the community actually use this\n\nGrand Prizes\nEvery participant who contributes during the Hackaethon is eligible to be\nawarded the grand prize. Judges will determine the winners based on their level\nof participation, contributions, and engagement with the community during the\nevent.\n\n * 1st Prize -- $500 gift card and exclusive Hackaethon Hoodie\n * 2nd Prize - $250 gift card\n * 3rd Prize - $100 gift card\n\nSee You in October\nWe are really excited about engaging with the community, collaborating with\nother developers, our ambassadors, and working together to make the most\npowerful and easiest to use open source cloud native networking tools on the\nplanet. We are looking forward to seeing you all in October.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020.jpg\" class=\"kg-image\" alt=\"Announcing the Inaugural Traefik Hackaethon 2020\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020.jpg 1600w, https://containous.ghost.io/content/images/2020/09/Announcing-the-Inaugural-Traefik-Hackaethon-2020.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Join the team of engineers who maintain Traefik and the Traefik Ambassadors for a week of virtual hacking and collaboration on the open source projects Traefik and Maesh. The hackathon will take place for three days, across multiple time zones, on October 20th through the 22nd. All participants who <a href=\"https://info.containo.us/traefik-hackaethon-2020\">sign up today</a> will receive an invitation to the Discord server a few days before the event where they will be able to connect, collaborate, and pair up with other participants and developers to contribute towards making Traefik even better.</p><p>All participants will receive a limited edition t-shirt, stickers, and bonus prizes are up for grabs including multiple $100 gift card bounties for plugins, and grand prizes of $500, $250, and $100.</p><h2 id=\"participate-and-collaborate\">Participate and Collaborate</h2><p>To be eligible as a participant, be sure to sign up for the event below and check-in for at least one day during the hackaethon and participate in the activities! During the event, you’ll be provided a link where you can provide details about your contribution, whether you’ve created a Traefik Plugin, contributed to an issue or PR, or had a PR merged in one of our projects. Be sure to include your address so we can send you some swag, and enter you for the grand prize drawings.</p><p>In the coming weeks, we’ll post more about the event, so be sure to <a href=\"https://info.containo.us/traefik-hackaethon-2020\">sign up now</a> so you can be notified about upcoming meetups and blog posts that are related to the event. We’ll be hosting a meetup about building your own plugin, and posting a blog on ideas for plugin development so keep an eye out.</p><p>There are plenty of cool activities to get involved in, and not all of them involve writing code:</p><ul><li>Build Traefik Plugins for the newly announced Traefik Pilot Plugin Marketplace</li><li>Contribute new features, fix bugs, or even reproduce some hard to find bugs in Traefik and Maesh</li><li>Pair up with other developers and contributors to write documentation, tests, feature requests, and more</li></ul><!--kg-card-begin: html--><p style=\"text-align: center\"><a href=\"https://info.containo.us/traefik-hackaethon-2020\" target=\"_blank\"><b>Sign Up for the Hackaethon 2020 Invitation</b></a></p><!--kg-card-end: html--><h3 id=\"plugin-bounties\">Plugin Bounties</h3><p>Plugins are eligible to be awarded a $100 gift card bounty. Successful implementations of a plugin during the Hackaethon may be awarded a bounty after meeting the quality criteria by the judges. Participants may implement their own plugin ideas or implement the suggested plugins from the blog post, either are equally eligible for the bounty. Up to 10 plugins will each be awarded a $100 gift card bounty.</p><p><strong>Quality Criteria:</strong></p><ul><li>Functionality - Does it do what it says it does</li><li>Testing - Are there functional unit tests that confirm the functionality</li><li>Value - Will the community actually use this</li></ul><h3 id=\"grand-prizes\">Grand Prizes</h3><p>Every participant who contributes during the Hackaethon is eligible to be awarded the grand prize. Judges will determine the winners based on their level of participation, contributions, and engagement with the community during the event.</p><ul><li>1st Prize -- $500 gift card and exclusive Hackaethon Hoodie</li><li>2nd Prize - $250 gift card</li><li>3rd Prize - $100 gift card</li></ul><h2 id=\"see-you-in-october\">See You in October</h2><p>We are really excited about engaging with the community, collaborating with other developers, our ambassadors, and working together to make the most powerful and easiest to use open source cloud native networking tools on the planet. We are looking forward to seeing you all in October.</p>","url":"https://containous.ghost.io/blog/announcing-the-inaugural-traefik-hackaethon-2020-in-october/","canonical_url":null,"uuid":"4c52c64f-3b90-421d-a920-f898028e5c3c","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f61f4b1a72a090039800f54","reading_time":2}},{"node":{"id":"Ghost__Post__5ec861094e2e9a0045ce7983","title":"Five ways to control access to your applications on Kubernetes","slug":"five-ways-to-control-access-to-your-applications-on-kubernetes","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/05/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/b860b48631b12a5416a73a890556681c/47498/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg","srcSet":"/static/b860b48631b12a5416a73a890556681c/9dc27/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg 300w,\n/static/b860b48631b12a5416a73a890556681c/4fe8c/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg 600w,\n/static/b860b48631b12a5416a73a890556681c/47498/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg 1200w,\n/static/b860b48631b12a5416a73a890556681c/52258/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg 1800w,\n/static/b860b48631b12a5416a73a890556681c/a41d1/5-ways-to-control-access-to-your-applications-on-Kubernetes-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"How should developers implement access control, particularly authentication, within the context of k8s?","custom_excerpt":"How should developers implement access control, particularly authentication, within the context of k8s?","visibility":"public","created_at_pretty":"22 May, 2020","published_at_pretty":"May 27, 2020","updated_at_pretty":"16 June, 2020","created_at":"2020-05-22T23:32:25.000+00:00","published_at":"2020-05-27T05:20:11.000+00:00","updated_at":"2020-06-16T14:27:07.000+00:00","meta_title":"Five ways to control access to your applications on Kubernetes","meta_description":"How should developers implement access control, particularly authentication, within the context of k8s?","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/05/5-ways-to-control-access-to-your-applications-on-Kubernetes-Twitter.jpg","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Kubernetes","slug":"kubernetes","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Development teams have grown adept at leveraging modern programming languages\nand cloud technologies in a bid to increase their productivity and reduce\ndevelopment cycle times. Given the flexibility of the cloud-native ecosystem,\nthese advancements have also expanded the surface area of security-related\nissues such as access-control. While many organizations are adopting Kubernetes\n[https://kubernetes.io/] (K8s) as their platform of choice for deploying and\nmanaging containerized applications, a natural question arises: How should\ndevelopers implement access control, particularly authentication, within the\ncontext of k8s? In this article, we’ll explore this question by covering the\nfollowing topics:\n\n 1. Reviewing common methods for authentication\n 2. Identifying how some of these methods can be readily integrated with\n    Kubernetes\n\nCommon authentication approaches\nLDAP\nMany organizations have historically adopted some form of directory service\nimplementation such as Active Directory (AD) for storing information including\nuser and organizational data. The majority of these systems support the open \nLightweight Directory Access Protocol (LDAP) protocol\n[https://tools.ietf.org/html/rfc4511] standard. By integrating with LDAP\napplications may seamlessly authenticate users within an organization by\nleveraging the existing user information managed by IT. Moreover, LDAP allows\napplications to utilize additional information such as groups and policies to\nenforce access-control. Therefore, integrating with LDAP for both is a\nreasonable option to consider for line-of-business and internal-facing\nworkloads.\n\nOAuth 2.0\nIn the context of third-party web applications, users often find themselves\nhaving to log in to many disparate systems where a central user identity service\nisn’t available. While creating unique accounts for each service is an option,\nthis solution does not scale. The OAuth 2.0 protocol\n[https://tools.ietf.org/html/rfc6749] is one approach that can help solve this\nchallenge, and it is commonly used as part of authentication flow\nimplementations such as the OpenID Connect [https://openid.net/connect/] \nstandard. The main benefit of using OAuth 2.0 is it gives the ability for the\nuser to approve delegated access for applications. This enables users to\nleverage existing identity providers (such as their Google account) to\nauthenticate themselves, allowing control over the information being shared,\nwith third-party applications.\n\nJSON Web Token (JWT)\nJSON web tokens [https://tools.ietf.org/html/rfc7519] are an increasingly\npopular choice for authentication, particularly for APIs. These tokens are\ncomposed of Base64URL [https://base64.guru/standards/base64url] encoded JSON\nobjects. Specifically, the token is constructed by concatenating a header JSON\nobject, payload JSON object, and signature. The cryptographic signature is\ncalculated using a shared secret or public/private key pair and can be used to\nauthenticate the source of the object. For example, given a shared secret, a JWT\nsignature can be computed using the HS256 (HMAC with SHA-256) algorithm as\nfollows:\n\nsignature = HS256(\n    Base64URLEncoding(header) + '.' + Base64URLEncoding(payload),\n    secret\n)\n\n\nThe final JWT is derived by concatenation of the three components:\n\nBase64URLEncoding(header) + '.' + Base64URLEncoding(payload) + '.' + signature\n\n\nIt’s worth noting these tokens won’t provide data security as they aren’t\nencrypted but their straight forward approach can be used by APIs to identify\ncallers. JWTs are a good option when integrating authentication providers with\nuser-facing APIs and inter-service communications, and are often implemented\nutilizing OAuth 2.0 flows [https://oauth.net/2/jwt/].\n\nHMAC\nThe JWT example above highlights the use of the HMAC with SHA-256 algorithm\n[https://tools.ietf.org/html/rfc2104.html] when computing the signature of the\ntoken header and payload. The use of HMACs can be generalized in that a\nsignature for any payload can be generated using any number of specifications.\nThe JWT is a special case where the payload happens to be a JSON object but the\nsame mechanism can be used with other data to achieve the objective of\nauthenticating a signed message.\n\nMutual TLS\nTLS authentication [https://en.wikipedia.org/wiki/Transport_Layer_Security] in\nthe context of web applications is fairly ubiquitous these days. The general\nidea is that certificates are used to authenticate a website (or web service) so\nthe client can be confident that the server is who it claims to be. Mutual TLS\nextends this model to be bidirectional. Not only does the client authenticate\nthe server identity, but the server confirms the identity of the client so that\nit may enforce access control and authorization policies. Mutual TLS\n[https://en.wikipedia.org/wiki/Mutual_authentication] is commonly deployed as\npart of inter-service and business-to-business communications where there are a\nlimited and known set of clients that are designed to access common endpoints.\n\nIntegrating application authentication with Kubernetes\nGiven our brief review of common authentication approaches, let’s turn to the\nquestion of how they can be incorporated when applications are deployed on\nKubernetes. As is often the case with K8s, there is a high degree of flexibility\nto implement a solution that meets the needs of individual organizations. Let’s\nreview a couple of important patterns that can be adopted for most use cases.\n\nIngress Controllers\nIngress Controllers are the most common mechanism used today when connecting\nusers to applications in Kubernetes\n[/blog/connecting-users-to-applications-with-kubernetes-ingress-controllers/].\nThere are many considerations to make when selecting a specific controller, as\neach is often implemented differently and based upon different underlying\ntechnology. Among the many decision criteria when comparing controllers\n[/blog/13-key-considerations-when-selecting-an-ingress-controller-for-kubernetes-d3e5d98ed8b7/]\n, one must consider how well candidates can support the relevant subset of\nauthentication approaches we’ve highlighted.\n\nTraefik [/traefik/] comes with a built-in ForwardAuth middleware\n[https://docs.traefik.io/middlewares/forwardauth/] feature that can be used to\ndelegate authentication to an external service. By integrating this capability\nas part of your K8s Ingress strategy, all services exposed in the traffic flow\nobtain the benefits of authentication management without incurring the\ncomplexity at the individual service layer. TraefikEE [/traefikee/] simplifies\nthe management of auth providers even further by integrating support for LDAP,\nOAuth 2.0, JWT, and HMAC all within a unified solution.\n\nAuthentication servers\nThe pattern of integrating authentication capabilities through an Ingress\nController can be extended even further by employing dedicated authentication\nservers into the architecture. Authelia [https://github.com/authelia/authelia] \nis an example of an open-source authentication and authorization server which\nworks with K8s and has been successfully integrated with Ingress technologies\nsuch as Traefik. In addition to the mechanisms covered earlier, these\nfunction-specific services can provide advanced authentication capabilities such\nas 2FA [https://en.wikipedia.org/wiki/Multi-factor_authentication] and SSO\n[https://en.wikipedia.org/wiki/Single_sign-on].\n\nConclusion\nControlling application access through authentication is an important\nconsideration in any enterprise scenario, and its importance is only amplified\nwhen adopting Kubernetes. By thoughtfully selecting architectural patterns and\ntechnologies, users can easily integrate their choice of best-practice\nauthentication approaches with minimal additional effort.\n\nThere has never been a better time than now to get started with Traefik in\nKubernetes. Our open-source Traefik edition\n[https://github.com/containous/traefik] with the support of a large and active\ncommunity is available for free and includes support for the most recent\nadvancements in Kubernetes Ingress technology. If you’re an enterprise looking\nto implement the most popular cloud-native load balancer with commercial\nsupport, high-availability, and authentication modules already built-in you\nshould schedule a demo [https://info.containo.us/request-demo-traefikee] with\nour sales team and learn more about how we make networking boring.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/05/5-ways-to-control-access-to-your-applications-on-Kubernetes.jpg\" class=\"kg-image\" alt=\"Kubernetes Authentication\"></figure><!--kg-card-begin: markdown--><p>Development teams have grown adept at leveraging modern programming languages and cloud technologies in a bid to increase their productivity and reduce development cycle times. Given the flexibility of the cloud-native ecosystem, these advancements have also expanded the surface area of security-related issues such as access-control. While many organizations are adopting <a href=\"https://kubernetes.io/\">Kubernetes</a> (K8s) as their platform of choice for deploying and managing containerized applications, a natural question arises: How should developers implement access control, particularly authentication, within the context of k8s? In this article, we’ll explore this question by covering the following topics:</p>\n<ol>\n<li>Reviewing common methods for authentication</li>\n<li>Identifying how some of these methods can be readily integrated with Kubernetes</li>\n</ol>\n<!--kg-card-end: markdown--><h2 id=\"common-authentication-approaches\">Common authentication approaches</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/05/Common-authentication-approaches@1x.jpg\" class=\"kg-image\" alt=\"Common Authentication Approach\"></figure><!--kg-card-begin: markdown--><h3 id=\"ldap\">LDAP</h3>\n<p>Many organizations have historically adopted some form of directory service implementation such as Active Directory (AD) for storing information including user and organizational data. The majority of these systems support the open <a href=\"https://tools.ietf.org/html/rfc4511\" target=\"_blank\" rel=\"nofollow\">Lightweight Directory Access Protocol (LDAP) protocol</a> standard. By integrating with LDAP applications may seamlessly authenticate users within an organization by leveraging the existing user information managed by IT. Moreover, LDAP allows applications to utilize additional information such as groups and policies to enforce access-control. Therefore, integrating with LDAP for both is a reasonable option to consider for line-of-business and internal-facing workloads.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"oauth20\">OAuth 2.0</h3>\n<p>In the context of third-party web applications, users often find themselves having to log in to many disparate systems where a central user identity service isn’t available. While creating unique accounts for each service is an option, this solution does not scale. The <a href=\"https://tools.ietf.org/html/rfc6749\" target=\"_blank\" rel=\"nofollow\">OAuth 2.0 protocol</a> is one approach that can help solve this challenge, and it is commonly used as part of authentication flow implementations such as the <a href=\"https://openid.net/connect/\" target=\"_blank\" rel=\"nofollow\">OpenID Connect</a> standard. The main benefit of using OAuth 2.0 is it gives the ability for the user to approve delegated access for applications. This enables users to leverage existing identity providers (such as their Google account) to authenticate themselves, allowing control over the information being shared, with third-party applications.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"jsonwebtokenjwt\">JSON Web Token (JWT)</h3>\n<p><a href=\"https://tools.ietf.org/html/rfc7519\" target=\"_blank\" rel=\"nofollow\">JSON web tokens</a> are an increasingly popular choice for authentication, particularly for APIs. These tokens are composed of <a href=\"https://base64.guru/standards/base64url\" target=\"_blank\" rel=\"nofollow\">Base64URL</a> encoded JSON objects. Specifically, the token is constructed by concatenating a header JSON object, payload JSON object, and signature. The cryptographic signature is calculated using a shared secret or public/private key pair and can be used to authenticate the source of the object. For example, given a shared secret, a JWT signature can be computed using the HS256 (HMAC with SHA-256) algorithm as follows:</p>\n<pre><code>signature = HS256(\n    Base64URLEncoding(header) + '.' + Base64URLEncoding(payload),\n    secret\n)\n</code></pre>\n<p>The final JWT is derived by concatenation of the three components:</p>\n<pre><code>Base64URLEncoding(header) + '.' + Base64URLEncoding(payload) + '.' + signature\n</code></pre>\n<p>It’s worth noting these tokens won’t provide data security as they aren’t encrypted but their straight forward approach can be used by APIs to identify callers. JWTs are a good option when integrating authentication providers with user-facing APIs and inter-service communications, and are often implemented utilizing <a href=\"https://oauth.net/2/jwt/\" target=\"_blank\" rel=\"nofollow\">OAuth 2.0 flows</a>.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"hmac\">HMAC</h3>\n<p>The JWT example above highlights the use of the <a href=\"https://tools.ietf.org/html/rfc2104.html\" target=\"_blank\" rel=\"nofollow\">HMAC with SHA-256 algorithm</a> when computing the signature of the token header and payload. The use of HMACs can be generalized in that a signature for any payload can be generated using any number of specifications. The JWT is a special case where the payload happens to be a JSON object but the same mechanism can be used with other data to achieve the objective of authenticating a signed message.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"mutualtls\">Mutual TLS</h3>\n<p><a href=\"https://en.wikipedia.org/wiki/Transport_Layer_Security\" target=\"_blank\" rel=\"nofollow\">TLS authentication</a> in the context of web applications is fairly ubiquitous these days. The general idea is that certificates are used to authenticate a website (or web service) so the client can be confident that the server is who it claims to be. Mutual TLS extends this model to be bidirectional. Not only does the client authenticate the server identity, but the server confirms the identity of the client so that it may enforce access control and authorization policies. <a href=\"https://en.wikipedia.org/wiki/Mutual_authentication\" target=\"_blank\" rel=\"nofollow\">Mutual TLS</a> is commonly deployed as part of inter-service and business-to-business communications where there are a limited and known set of clients that are designed to access common endpoints.</p>\n<!--kg-card-end: markdown--><h2 id=\"integrating-application-authentication-with-kubernetes\">Integrating application authentication with Kubernetes</h2><p>Given our brief review of common authentication approaches, let’s turn to the question of how they can be incorporated when applications are deployed on Kubernetes. As is often the case with K8s, there is a high degree of flexibility to implement a solution that meets the needs of individual organizations. Let’s review a couple of important patterns that can be adopted for most use cases.</p><h3 id=\"ingress-controllers\">Ingress Controllers</h3><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/05/Traefik-Ingress-Controller.jpg\" class=\"kg-image\" alt=\"Ingress Controller with Traefik\"></figure><!--kg-card-begin: markdown--><p>Ingress Controllers are the most common mechanism used today when <a href=\"https://containous.ghost.io/blog/connecting-users-to-applications-with-kubernetes-ingress-controllers/\">connecting users to applications in Kubernetes</a>. There are many considerations to make when selecting a specific controller, as each is often implemented differently and based upon different underlying technology. Among the many <a href=\"https://containous.ghost.io/blog/13-key-considerations-when-selecting-an-ingress-controller-for-kubernetes-d3e5d98ed8b7/\">decision criteria when comparing controllers</a>, one must consider how well candidates can support the relevant subset of authentication approaches we’ve highlighted.</p>\n<p><a href=\"https://containous.ghost.io/traefik/\">Traefik</a> comes with a built-in <a href=\"https://docs.traefik.io/middlewares/forwardauth/\">ForwardAuth middleware</a> feature that can be used to delegate authentication to an external service. By integrating this capability as part of your K8s Ingress strategy, all services exposed in the traffic flow obtain the benefits of authentication management without incurring the complexity at the individual service layer. <a href=\"https://containous.ghost.io/traefikee/\">TraefikEE</a> simplifies the management of auth providers even further by integrating support for LDAP, OAuth 2.0, JWT, and HMAC all within a unified solution.</p>\n<h3 id=\"authenticationservers\">Authentication servers</h3>\n<p>The pattern of integrating authentication capabilities through an Ingress Controller can be extended even further by employing dedicated authentication servers into the architecture. <a href=\"https://github.com/authelia/authelia\" target=\"_blank\" rel=\"nofollow\">Authelia</a> is an example of an open-source authentication and authorization server which works with K8s and has been successfully integrated with Ingress technologies such as Traefik. In addition to the mechanisms covered earlier, these function-specific services can provide advanced authentication capabilities such as <a href=\"https://en.wikipedia.org/wiki/Multi-factor_authentication\" target=\"_blank\" rel=\"nofollow\">2FA</a> and <a href=\"https://en.wikipedia.org/wiki/Single_sign-on\" target=\"_blank\" rel=\"nofollow\">SSO</a>.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>Controlling application access through authentication is an important consideration in any enterprise scenario, and its importance is only amplified when adopting Kubernetes. By thoughtfully selecting architectural patterns and technologies, users can easily integrate their choice of best-practice authentication approaches with minimal additional effort.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/05/TraefikEE-Ingress-Controller.jpg\" class=\"kg-image\" alt=\"Ingress Controller with TraefikEE\"></figure><!--kg-card-begin: markdown--><p>There has never been a better time than now to get started with Traefik in Kubernetes. Our <a href=\"https://github.com/containous/traefik\">open-source Traefik edition</a> with the support of a large and active community is available for free and includes support for the most recent advancements in Kubernetes Ingress technology. If you’re an enterprise looking to implement the most popular cloud-native load balancer with commercial support, high-availability, and authentication modules already built-in you should <a href=\"https://info.containo.us/request-demo-traefikee\" target=\"_blank\" rel=\"nofollow\">schedule a demo</a> with our sales team and learn more about how we make networking boring.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/five-ways-to-control-access-to-your-applications-on-kubernetes/","canonical_url":null,"uuid":"26e84f80-3637-4600-82da-292eb70149e2","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ec861094e2e9a0045ce7983","reading_time":5}},{"node":{"id":"Ghost__Post__5eb58b45c49e39004576b610","title":"Combining Ingress Controllers and External Load Balancers with Kubernetes","slug":"combining-ingress-controllers-and-external-load-balancers-with-kubernetes","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/05/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes-containous-2.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/9b55622b4567a60fc818e7ec45f13481/47498/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes-containous-2.jpg","srcSet":"/static/9b55622b4567a60fc818e7ec45f13481/9dc27/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes-containous-2.jpg 300w,\n/static/9b55622b4567a60fc818e7ec45f13481/4fe8c/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes-containous-2.jpg 600w,\n/static/9b55622b4567a60fc818e7ec45f13481/47498/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes-containous-2.jpg 1200w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"The great promise of Kubernetes is the ability to easily deploy and scale containerized applications. How Load Balancers work together with the Ingress Controllers in a Kubernetes architecture?","custom_excerpt":"The great promise of Kubernetes is the ability to easily deploy and scale containerized applications. How Load Balancers work together with the Ingress Controllers in a Kubernetes architecture?","visibility":"public","created_at_pretty":"08 May, 2020","published_at_pretty":"May 14, 2020","updated_at_pretty":"09 June, 2020","created_at":"2020-05-08T16:39:33.000+00:00","published_at":"2020-05-14T05:05:21.000+00:00","updated_at":"2020-06-09T05:37:52.000+00:00","meta_title":"Combining Ingress Controllers & External Load Balancers with Kubernetes","meta_description":"The great promise of Kubernetes is the ability to easily deploy and scale containerized applications. How Load Balancers work together with the Ingress Controllers in a Kubernetes architecture?","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/05/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes-Twitter.jpg","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Kubernetes","slug":"kubernetes","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#kubernetes-ingress-related-resource","slug":"hash-kubernetes-ingress-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"The great promise of Kubernetes [https://kubernetes.io/] (k8s) is the ability to\neasily deploy and scale containerized applications. By automating the process of\nallocating and provisioning compute and storage resources for Pods across nodes,\nk8s reduces the operational complexity of day-to-day operations. However,\norchestrating containers alone doesn’t necessarily help engineers meet the\nconnectivity requirements for users. Specifically, a Kubernetes Deployment\nconfigures Pods with private IP addresses and precludes incoming traffic over\nthe network. Outside of Kubernetes, operators are typically familiar with\ndeploying external load balancers, either in cloud or physical data center\nenvironments, to route traffic to application instances. However, effectively\nmapping these operational patterns to k8s requires understanding how Load\nBalancers [https://kubernetes.io/docs/concepts/services-networking/] work\ntogether with the Ingress Controllers\n[https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/] \nin a Kubernetes architecture.\n\nExternal load balancers and Kubernetes\nOverview of external LBs and K8s\nIn order to expose application endpoints, Kubernetes networking allows users to\nexplicitly define Services\n[https://kubernetes.io/docs/concepts/services-networking/service/]. K8s then\nautomates provisioning appropriate networking resources based upon the service\ntype specified. The NodePort service type exposes an allocated port that can be\naccessed over the network on each node in the k8s cluster. The LoadBalancer\nservice type uses this same mechanism to deploy and configure an external load\nbalancer (often through a cloud-managed API) which forwards traffic to an\napplication using the NodePort. When a request is routed to the configured port\non a node, it forwards packets as needed to direct traffic to the destination\nPods using kube-proxy.\n\nFig. a: External load balancer defined for each applicationGiven the ability to\neasily define LoadBalancer services to route incoming traffic from external\nclients, the story may seemingly sound complete. However, in any real-life\nscenario, directly using external load balancers for every application (fig. a) \nthat needs external access has significant drawbacks including:\n\n * Cost overheads: External load balancers, whether cloud-managed or\n   instantiated through physical network appliances on-premises, can be\n   expensive. For k8s clusters with many applications, these costs will quickly\n   add up.\n * Operational complexity: Load balancers require various resources (IP\n   addresses, DNS, certificates, etc.) that can be painful to manage,\n   particularly in highly dynamic environments where there may be transient\n   endpoints for staging and development deployments.\n * Monitoring and logging: Given the importance of external load balancers in\n   the traffic flow, being able to effectively centralize monitoring and logging\n   data is critical. However, this may become challenging in practice when there\n   are multiple load balancers involved.\n\nThe perfect marriage: Load balancers and Ingress Controllers\nIt’s clear that external load balancers alone aren’t a practical solution for\nproviding the networking capabilities necessary for a k8s environment. Luckily,\nthe Kubernetes architecture allows users to combine load balancers with an\nIngress Controller. The core concepts are as follows: instead of provisioning an\nexternal load balancer for every application service that needs external\nconnectivity, users deploy and configure a single load balancer that targets an\nIngress Controller. The Ingress Controller serves as a single entrypoint and can\nthen route traffic to multiple applications in the cluster. Key elements of this\napproach include:\n\n * Ingress Controllers are k8s applications: While they may seem somewhat\n   magical, it’s useful to keep in mind that Ingress Controllers are nothing\n   more than standard Kubernetes applications instantiated via Pods.\n * Ingress Controllers are exposed as a service: The k8s application that\n   constitutes an Ingress Controller is exposed through a LoadBalancer service\n   type thereby mapping it to an external load balancer.\n * Ingress Controllers route to underlying applications using ClusterIPs: As an\n   intermediary between the external load balancer and applications, the Ingress\n   Controller uses ClusterIP service types to route and balance traffic across\n   application instances based upon operator-provided configurations.\n\nFig. b: Dynamic load balancing through ingressInjecting the Ingress Controller\nin the traffic path allows users to gain the benefits of external load balancer\ncapabilities while avoiding the pitfalls of relying upon them exclusively (fig.\nb). Indeed, the Kubernetes architecture allows operators to integrate multiple\nIngress Controllers, thereby providing a high degree of flexibility to meet\nspecific requirements. This can be a bit overwhelming for those new to\nKubernetes networking, so let’s review a few example deployment patterns.\n\nExample deployment patterns\nLoad balancer with NodePorts and traffic forwarding\nAs mentioned earlier, a LoadBalancer service type results in an external load\nbalancer that uses NodePorts to reach backend services. Since every node exposes\nthe target port, the load balancer can spread traffic across all of them.\nHowever, the underlying Pods may only be running on a subset of the k8s nodes\ncreating the potential need for traffic forwarding. As part of forwarding\ntraffic, the kube-proxy performs source network address translation (SNAT).\nWhile this obfuscates the source IP address of requestors, the use of HTTP\nheaders such as X-Forwarded-For (and its standardized variant Forwarded) can be\nutilized where business requirements require it (e.g. for compliance purposes).\n\nLoad balancer with NodePorts and no SNAT\nTo avoid SNAT in the traffic flow, we can modify the previous deployment pattern\nto force the external load balancer to only target nodes that reflect Pods\nrunning the Ingress Controller deployment. Specifically, the\nexternalTrafficPolicy on the LoadBalancer service for the Ingress Controller can\nbe set to Local instead of the default Cluster value. Some potential drawbacks\nof this pattern, however, include:\n\n * Reduced load-spreading: Since all traffic is funneled to a subset of nodes,\n   there may be traffic imbalances\n * Use of health checks: The external load balancer uses a health check to\n   determine which nodes to target, and these can result in transient errors\n   (e.g. due to rolling deployments, health check timeouts, etc.)\n\nMultiple external LBs and Ingress Controllers: Craft a solution that meets your\nneeds\nAs a final deployment pattern, we can create advanced configurations consisting\nof multiple external load balancers each of which map to a different Ingress\nController. Users can select a technology-specific Ingress Controller based upon\ndesired feature capabilities (e.g. NGINX or Traefik), and configure Ingress\nresources for underlying applications accordingly. Examples of potential\ncriteria\n[/blog/13-key-considerations-when-selecting-an-ingress-controller-for-kubernetes-d3e5d98ed8b7/] \nthat may be relevant when comparing candidate controllers include:\n\n * Protocol support: If your needs extend beyond just HTTP(S) and may require\n   routing TCP/UDP or gRPC, it’s important to recognize that not all controller\n   implementations support the full array of protocols\n * Zero-downtime configuration updates: Not all controllers support\n   configuration updates without incurring downtime\n * High availability (HA): If you want to avoid your ingress controller becoming\n   a potential single point of failure (SPOF) for external traffic, you should\n   identify controllers that support HA configurations\n * Enterprise support: While many open source controller options are available,\n   not all provide enterprise support options that teams can rely on when needed \n\nThe aspects of previous deployment patterns such as configuring\nexternalTrafficPolicy to allow for load spreading or avoiding SNAT can be\nincorporated, with each Ingress Controller potentially configured differently.\nThe ability to easily piece together external load balancers and Ingress\nControllers in a manner that meets the unique business needs of an organization\nexemplifies the benefits that the flexibility of k8s networking can provide.\n\nTo learn more, check out this video\n[https://info.containo.us/webinar-deploying-external-load-balancers-in-kubernetes] \nwe recorded recently that further explains Kubernetes Ingress and the different\npatterns for external load balancers in k8s\n[https://info.containo.us/webinar-deploying-external-load-balancers-in-kubernetes]\n.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/05/Combining-Ingress-Controllers-and-External-Load-Balancers-with-Kubernetes.jpg\" class=\"kg-image\"></figure><p>The great promise of <a href=\"https://kubernetes.io/\">Kubernetes</a> (k8s) is the ability to easily deploy and scale containerized applications. By automating the process of allocating and provisioning compute and storage resources for Pods across nodes, k8s reduces the operational complexity of day-to-day operations. However, orchestrating containers alone doesn’t necessarily help engineers meet the connectivity requirements for users. Specifically, a Kubernetes Deployment configures Pods with private IP addresses and precludes incoming traffic over the network. Outside of Kubernetes, operators are typically familiar with deploying external load balancers, either in cloud or physical data center environments, to route traffic to application instances. However, effectively mapping these operational patterns to k8s requires understanding how <a href=\"https://kubernetes.io/docs/concepts/services-networking/\">Load Balancers</a> work together with the <a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/\">Ingress Controllers</a> in a Kubernetes architecture.</p><h2 id=\"external-load-balancers-and-kubernetes\">External load balancers and Kubernetes</h2><h3 id=\"overview-of-external-lbs-and-k8s\">Overview of external LBs and K8s</h3><p>In order to expose application endpoints, Kubernetes networking allows users to explicitly define <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Services</a>. K8s then automates provisioning appropriate networking resources based upon the service type specified. The NodePort service type exposes an allocated port that can be accessed over the network on each node in the k8s cluster. The LoadBalancer service type uses this same mechanism to deploy and configure an external load balancer (often through a cloud-managed API) which forwards traffic to an application using the NodePort. When a request is routed to the configured port on a node, it forwards packets as needed to direct traffic to the destination Pods using kube-proxy.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/05/services_loadbalancer.png\" class=\"kg-image\" alt=\"External-load-balancer\"><figcaption><strong>Fig. a</strong>: External load balancer defined for each application</figcaption></figure><p>Given the ability to easily define LoadBalancer services to route incoming traffic from external clients, the story may seemingly sound complete. However, in any real-life scenario, directly using external load balancers for every application <em>(fig. a)</em> that needs external access has significant drawbacks including:</p><ul><li><strong>Cost overheads</strong>: External load balancers, whether cloud-managed or instantiated through physical network appliances on-premises, can be expensive. For k8s clusters with many applications, these costs will quickly add up.</li><li><strong>Operational complexity</strong>: Load balancers require various resources (IP addresses, DNS, certificates, etc.) that can be painful to manage, particularly in highly dynamic environments where there may be transient endpoints for staging and development deployments.</li><li><strong>Monitoring and logging</strong>: Given the importance of external load balancers in the traffic flow, being able to effectively centralize monitoring and logging data is critical. However, this may become challenging in practice when there are multiple load balancers involved.</li></ul><h2 id=\"the-perfect-marriage-load-balancers-and-ingress-controllers\">The perfect marriage: Load balancers and Ingress Controllers</h2><p>It’s clear that external load balancers alone aren’t a practical solution for providing the networking capabilities necessary for a k8s environment. Luckily, the Kubernetes architecture allows users to combine load balancers with an Ingress Controller. The core concepts are as follows: instead of provisioning an external load balancer for every application service that needs external connectivity, users deploy and configure a single load balancer that targets an Ingress Controller. The Ingress Controller serves as a single entrypoint and can then route traffic to multiple applications in the cluster. Key elements of this approach include:</p><ul><li><strong>Ingress Controllers are k8s applications:</strong> While they may seem somewhat magical, it’s useful to keep in mind that Ingress Controllers are nothing more than standard Kubernetes applications instantiated via Pods.</li><li><strong>Ingress Controllers are exposed as a service:</strong> The k8s application that constitutes an Ingress Controller is exposed through a LoadBalancer service type thereby mapping it to an external load balancer.</li><li><strong>Ingress Controllers route to underlying applications using ClusterIPs</strong>: As an intermediary between the external load balancer and applications, the Ingress Controller uses ClusterIP service types to route and balance traffic across application instances based upon operator-provided configurations.</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/05/ingress_have_services_too.png\" class=\"kg-image\" alt=\"Dynamic-load-balancing-through-ingress\"><figcaption><strong>Fig. b</strong>: Dynamic load balancing through ingress</figcaption></figure><p>Injecting the Ingress Controller in the traffic path allows users to gain the benefits of external load balancer capabilities while avoiding the pitfalls of relying upon them exclusively <em>(fig. b)</em>. Indeed, the Kubernetes architecture allows operators to integrate multiple Ingress Controllers, thereby providing a high degree of flexibility to meet specific requirements. This can be a bit overwhelming for those new to Kubernetes networking, so let’s review a few example deployment patterns.</p><h2 id=\"example-deployment-patterns\">Example deployment patterns</h2><h3 id=\"load-balancer-with-nodeports-and-traffic-forwarding\">Load balancer with NodePorts and traffic forwarding</h3><p>As mentioned earlier, a LoadBalancer service type results in an external load balancer that uses NodePorts to reach backend services. Since every node exposes the target port, the load balancer can spread traffic across all of them. However, the underlying Pods may only be running on a subset of the k8s nodes creating the potential need for traffic forwarding. As part of forwarding traffic, the kube-proxy performs source network address translation (SNAT). While this obfuscates the source IP address of requestors, the use of HTTP headers such as X-Forwarded-For (and its standardized variant Forwarded) can be utilized where business requirements require it (e.g. for compliance purposes).</p><h3 id=\"load-balancer-with-nodeports-and-no-snat\">Load balancer with NodePorts and no SNAT</h3><p>To avoid SNAT in the traffic flow, we can modify the previous deployment pattern to force the external load balancer to only target nodes that reflect Pods running the Ingress Controller deployment. Specifically, the externalTrafficPolicy on the LoadBalancer service for the Ingress Controller can be set to Local instead of the default Cluster value. Some potential drawbacks of this pattern, however, include:</p><ul><li><strong>Reduced load-spreading:</strong> Since all traffic is funneled to a subset of nodes, there may be traffic imbalances</li><li><strong>Use of health checks:</strong> The external load balancer uses a health check to determine which nodes to target, and these can result in transient errors (e.g. due to rolling deployments, health check timeouts, etc.)</li></ul><h3 id=\"multiple-external-lbs-and-ingress-controllers-craft-a-solution-that-meets-your-needs\">Multiple external LBs and Ingress Controllers: Craft a solution that meets your needs</h3><p>As a final deployment pattern, we can create advanced configurations consisting of multiple external load balancers each of which map to a different Ingress Controller. Users can select a technology-specific Ingress Controller based upon desired feature capabilities (e.g. NGINX or Traefik), and configure Ingress resources for underlying applications accordingly. <a href=\"https://containous.ghost.io/blog/13-key-considerations-when-selecting-an-ingress-controller-for-kubernetes-d3e5d98ed8b7/\">Examples of potential criteria</a> that may be relevant when comparing candidate controllers include:</p><ul><li><strong>Protocol support</strong>: If your needs extend beyond just HTTP(S) and may require routing TCP/UDP or gRPC, it’s important to recognize that not all controller implementations support the full array of protocols</li><li><strong>Zero-downtime configuration updates</strong>: Not all controllers support configuration updates without incurring downtime</li><li><strong>High availability (HA)</strong>: If you want to avoid your ingress controller becoming a potential single point of failure (SPOF) for external traffic, you should identify controllers that support HA configurations</li><li><strong>Enterprise support</strong>: While many open source controller options are available, not all provide enterprise support options that teams can rely on when needed </li></ul><p>The aspects of previous deployment patterns such as configuring externalTrafficPolicy to allow for load spreading or avoiding SNAT can be incorporated, with each Ingress Controller potentially configured differently. The ability to easily piece together external load balancers and Ingress Controllers in a manner that meets the unique business needs of an organization exemplifies the benefits that the flexibility of k8s networking can provide.</p><p>To learn more, <strong><a href=\"https://info.containo.us/webinar-deploying-external-load-balancers-in-kubernetes\">check out this video</a></strong> we recorded recently that further explains <strong><a href=\"https://info.containo.us/webinar-deploying-external-load-balancers-in-kubernetes\">Kubernetes Ingress and the different patterns for external load balancers in k8s</a></strong>.<br></p>","url":"https://containous.ghost.io/blog/combining-ingress-controllers-and-external-load-balancers-with-kubernetes/","canonical_url":null,"uuid":"8e267865-103f-4587-bfe2-78d34b1a16c6","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb58b45c49e39004576b610","reading_time":5}},{"node":{"id":"Ghost__Post__5e9116ed1afff4004456e002","title":"The Importance of Distributed Tracing and Monitoring in a Microservice Architecture","slug":"the-importance-of-distributed-tracing-and-monitoring-in-a-microservice-architecture","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/05/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Blog-2.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/bc214844165f4ac2399fc1548c498842/47498/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Blog-2.jpg","srcSet":"/static/bc214844165f4ac2399fc1548c498842/9dc27/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Blog-2.jpg 300w,\n/static/bc214844165f4ac2399fc1548c498842/4fe8c/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Blog-2.jpg 600w,\n/static/bc214844165f4ac2399fc1548c498842/47498/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Blog-2.jpg 1200w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"How do teams diagnose latency between microservices or collate logs from dozens of loosely coupled services, while also ensuring that any logging overhead is kept to a minimum?","custom_excerpt":"How do teams diagnose latency between microservices or collate logs from dozens of loosely coupled services, while also ensuring that any logging overhead is kept to a minimum?","visibility":"public","created_at_pretty":"11 April, 2020","published_at_pretty":"May 5, 2020","updated_at_pretty":"22 May, 2020","created_at":"2020-04-11T01:01:33.000+00:00","published_at":"2020-05-05T14:40:44.000+00:00","updated_at":"2020-05-22T00:25:50.000+00:00","meta_title":"Distributed Tracing & Monitoring in a Microservice Architecture","meta_description":"Often microservices can be thought of as a single application, even though internally there may be several services involved in fulfilling requests.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/05/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Twitter.jpg","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Microservices","slug":"microservices","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Microservices have many advantages, such as the ability to independently deploy\ndecoupled services instead of having to deploy an entire monolithic application\nor scaling out components independently. However, for all their advantages,\nmicroservices also introduce complexities that should be understood by teams\nthat choose to implement them. One of those challenges is monitoring application\nhealth and tracing traffic flows through a distributed system.\n\nOften microservices can logically be thought of as a single application, even\nthough internally there may be several services involved in fulfilling requests\nto the end-user. If each request is routed through a series of services, how do\nteams trace and troubleshoot issues? Even if the system as a whole is working \nfunctionally, perhaps your overall transaction time is unacceptable. How do\nteams diagnose latency between microservices or collate logs from dozens of\nloosely coupled services, while also ensuring that any logging overhead is kept\nto a minimum?\n\nLogging, Monitoring, and Tracing\nBefore we continue, let us disambiguate logging, monitoring, and tracing. These\nterms are often used interchangeably, but there are some subtle differences.\n\nTypically, logging is focused on diagnosing errors or providing auditing\ncapabilities at the component (or microservice) level. Logging is also usually\nreactive in nature and is often the first tool that operators use when\ntroubleshooting service errors or investigating security incidents.\n\nMonitoring is focused on proactive metrics and thresholds that let operators\nknow how a service is handling its requests. These metrics are usually focused\non the underlying infrastructure, such as CPU, Memory, and I/O in addition to\nthe runtime metrics generated by the application itself. These include\nstatistics like heap size, thread count, and memory management (garbage\ncollection).\n\nTracing is typically focused on optimization and performance across multiple\nservices. It includes correlating a single “logical request” to multiple\nphysical requests as they propagate through multiple services. While tracing is\nconcerned with each service in a chain, it is usually focused at the application\nlevel. There are additional benefits to tracing as a troubleshooting tool since\nany exception or error is usually captured along with the entire context of a\nrequest.\n\nWhile logging is important, in this article we will focus on monitoring and\ntracing since they span multiple services.\n\nMonitoring\nMonitoring is the process of recording information, or predefined metrics,\nallowing operators to achieve visibility into their applications state. These\nmetrics help answer questions around resource allocation or to determine if\nrequests are going where they should. This becomes increasingly important when\ntraffic shifting and other advanced routing mechanisms like throttling or\ncircuit breakers are used within microservice applications. Knowing when a\nrequest hit a service is important but knowing why it was forwarded to that\nservice can be just as important. Monitoring can also help operators determine\nwhen circuit breakers are triggered on or off or which traffic shifting rule was\ninvoked in routing the request. Traefik generates metrics around these types of\nKey Performance Indicators (KPIs) and exposes that data through various\nimplementations such as Prometheus.\n\nTracing\nTracing starts at the entry-point of a request into an application. A trace is\nstarted for the request and will have a unique identifier\n[https://www.w3.org/TR/trace-context/] generated for that request. As traffic\nflows from service to service, each service adds some information to the trace,\nlike the time the request arrived at the service as well as how long it took to\nprocess. This allows open source tools such as Jaeger\n[https://www.jaegertracing.io/] and Elastic APM [https://www.elastic.co/apm] to\nvisualize the entire call flow.\n\nHow is tracing implemented in a microservices application? In most cases, there\nare libraries and tools to help instrument the most popular application runtimes\nand frameworks. You could also code it yourself, intercepting calls and adding\nheaders to downstream requests or using some other mechanism to add metadata to\ntraffic. In addition to these techniques, you can utilize tracing with Traefik\n[/traefik/] and Maesh [/maesh/] to gain additional observability within your\napplication environments.\n\nTraefik supports tracing via OpenTracing [https://opentracing.io/], an open\nstandard designed for distributed tracing. You enable tracing via configuration\nand can also specify which backend you want to utilize: Jaeger\n[https://www.jaegertracing.io/], Zipkin [https://zipkin.io/], or DataDog\n[https://www.datadoghq.com/].\n\nTracing or Monitoring, or Both?\nThe distinction between monitoring and tracing is often academic. Some teams\nutilize monitoring and metrics alongside distributed tracing, while other teams\nprefer to keep tracing and monitoring as separate but complementary concerns. In\nmany cases, the aggregate data provided by tracing generates the information\nthey need to determine when and where to scale out their services.\n\nMonitoring is typically easier to implement, so teams usually start their\ndiagnostic journey with metrics. Tracing allows a deeper (or wider) view but\ntypically requires more effort to implement because of the requirements in\ncollecting, storing, and analyzing the vast amounts of telemetry which is\ngenerated by tracing. Of course, there are vendors such as DataDog\n[https://www.datadoghq.com/] and Instana [https://www.instana.com/] which can\noffload most of that work, but those solutions are costly and hard to justify\nwhen first starting out.\n\nBoth monitoring and tracing can be used to help detect when individual services\nare not behaving as they should. Tracing, when properly implemented, will help\nyou not only detect anomalies but give you the information needed to understand\nwhat may be causing them. Ultimately, when you are to the point where you need\nto focus on optimization and improve end-to-end performance, then you’re going\nto have no choice but to utilize tracing. Tools such as Traefik [/traefik/] and \nMaesh [/maesh/] can be used to introduce distributed tracing without the\nsignificant overhead involved with instrumenting every service with open source\ntools and having to manage all that additional telemetry.\n\nConclusion\nBoth monitoring and tracing are important to creating stable, reliable, and\nperformant microservice-based applications. Monitoring provides health checks on\nplatform services and critical infrastructure, while tracing allows you to\ndiagnose end-to-end traffic for requests. As applications mature, they typically\nrequire both monitoring and tracing for efficient and optimal service\nmanagement.\n\nWant to learn more about microservice architecture best practices? Check out\nthis white paper\n[https://info.containo.us/request-white-paper-routing-in-the-cloud] that\naddresses production challenges (including tracing and monitoring) related to\nadopting microservices with a cloud-native mindset.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/05/Containous---The-Importance-of-Distributed-Tracing-and-Monitoring-in-a-Microservice-Architecture---Blog.jpg\" class=\"kg-image\"></figure><p>Microservices have many advantages, such as the ability to independently deploy decoupled services instead of having to deploy an entire monolithic application or scaling out components independently. However, for all their advantages, microservices also introduce complexities that should be understood by teams that choose to implement them. One of those challenges is monitoring application health and tracing traffic flows through a distributed system.</p><p>Often microservices can <em>logically</em> be thought of as a single application, even though internally there may be several services involved in fulfilling requests to the end-user. If each request is routed through a series of services, how do teams trace and troubleshoot issues? Even if the system as a whole is working <em>functionally</em>, perhaps your overall transaction time is unacceptable. How do teams diagnose latency between microservices or collate logs from dozens of loosely coupled services, while also ensuring that any logging overhead is kept to a minimum?</p><h2 id=\"logging-monitoring-and-tracing\">Logging, Monitoring, and Tracing</h2><p>Before we continue, let us disambiguate logging, monitoring, and tracing. These terms are often used interchangeably, but there are some subtle differences.</p><p>Typically, logging is focused on diagnosing errors or providing auditing capabilities at the component (or microservice) level. Logging is also usually reactive in nature and is often the first tool that operators use when troubleshooting service errors or investigating security incidents.</p><p>Monitoring is focused on proactive metrics and thresholds that let operators know how a service is handling its requests. These metrics are usually focused on the underlying infrastructure, such as CPU, Memory, and I/O in addition to the runtime metrics generated by the application itself. These include statistics like heap size, thread count, and memory management (garbage collection).</p><p>Tracing is typically focused on optimization and performance across multiple services. It includes correlating a single “logical request” to multiple physical requests as they propagate through multiple services. While tracing is concerned with each service in a chain, it is usually focused at the application level. There are additional benefits to tracing as a troubleshooting tool since any exception or error is usually captured along with the entire context of a request.</p><p>While logging is important, in this article we will focus on monitoring and tracing since they span multiple services.</p><h2 id=\"monitoring\">Monitoring</h2><p>Monitoring is the process of recording information, or predefined metrics, allowing operators to achieve visibility into their applications state. These metrics help answer questions around resource allocation or to determine if requests are going where they should. This becomes increasingly important when traffic shifting and other advanced routing mechanisms like throttling or circuit breakers are used within microservice applications. Knowing when a request hit a service is important but knowing why it was forwarded to that service can be just as important. Monitoring can also help operators determine when circuit breakers are triggered on or off or which traffic shifting rule was invoked in routing the request. Traefik generates metrics around these types of Key Performance Indicators (KPIs) and exposes that data through various implementations such as Prometheus.</p><h2 id=\"tracing\">Tracing</h2><p>Tracing starts at the entry-point of a request into an application. A trace is started for the request and will have a <a href=\"https://www.w3.org/TR/trace-context/\">unique identifier</a> generated for that request. As traffic flows from service to service, each service adds some information to the trace, like the time the request arrived at the service as well as how long it took to process. This allows open source tools such as <a href=\"https://www.jaegertracing.io/\">Jaeger</a> and <a href=\"https://www.elastic.co/apm\">Elastic APM</a> to visualize the entire call flow.</p><p>How is tracing implemented in a microservices application? In most cases, there are libraries and tools to help instrument the most popular application runtimes and frameworks. You could also code it yourself, intercepting calls and adding headers to downstream requests or using some other mechanism to add metadata to traffic. In addition to these techniques, you can utilize tracing with <a href=\"https://containous.ghost.io/traefik/\">Traefik</a> and <a href=\"https://containous.ghost.io/maesh/\">Maesh</a> to gain additional observability within your application environments.</p><p>Traefik supports tracing via <a href=\"https://opentracing.io/\">OpenTracing</a>, an open standard designed for distributed tracing. You enable tracing via configuration and can also specify which backend you want to utilize: <a href=\"https://www.jaegertracing.io/\">Jaeger</a>, <a href=\"https://zipkin.io/\">Zipkin</a>, or <a href=\"https://www.datadoghq.com/\">DataDog</a>.</p><h2 id=\"tracing-or-monitoring-or-both\">Tracing or Monitoring, or Both?</h2><p>The distinction between monitoring and tracing is often academic. Some teams utilize monitoring and metrics alongside distributed tracing, while other teams prefer to keep tracing and monitoring as separate but complementary concerns. In many cases, the aggregate data provided by tracing generates the information they need to determine when and where to scale out their services.</p><p>Monitoring is typically easier to implement, so teams usually start their diagnostic journey with metrics. Tracing allows a deeper (or wider) view but typically requires more effort to implement because of the requirements in collecting, storing, and analyzing the vast amounts of telemetry which is generated by tracing. Of course, there are vendors such as <a href=\"https://www.datadoghq.com/\">DataDog</a> and <a href=\"https://www.instana.com/\">Instana</a> which can offload most of that work, but those solutions are costly and hard to justify when first starting out.</p><p>Both monitoring and tracing can be used to help detect when individual services are not behaving as they should. Tracing, when properly implemented, will help you not only detect anomalies but give you the information needed to understand what may be causing them. Ultimately, when you are to the point where you need to focus on optimization and improve end-to-end performance, then you’re going to have no choice but to utilize tracing. Tools such as <a href=\"https://containous.ghost.io/traefik/\">Traefik</a> and <a href=\"https://containous.ghost.io/maesh/\">Maesh</a> can be used to introduce distributed tracing without the significant overhead involved with instrumenting every service with open source tools and having to manage all that additional telemetry.</p><h2 id=\"conclusion\">Conclusion</h2><p>Both monitoring and tracing are important to creating stable, reliable, and performant microservice-based applications. Monitoring provides health checks on platform services and critical infrastructure, while tracing allows you to diagnose end-to-end traffic for requests. As applications mature, they typically require both monitoring and tracing for efficient and optimal service management.</p><p>Want to learn more about <strong>microservice architecture best practices</strong>? <a href=\"https://info.containo.us/request-white-paper-routing-in-the-cloud\">Check out this white paper</a> that addresses<strong> production challenges </strong>(including tracing and monitoring) <strong>related to adopting microservices with a cloud-native mindset</strong>.</p>","url":"https://containous.ghost.io/blog/the-importance-of-distributed-tracing-and-monitoring-in-a-microservice-architecture/","canonical_url":null,"uuid":"abf91c0f-1147-4f72-be6e-11329e668272","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e9116ed1afff4004456e002","reading_time":4}}]}},"pageContext":{"slug":"kevincrawley","limit":9,"skip":0,"numberOfPages":1,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":null,"previousPagePath":null,"nextPagePath":null}},"staticQueryHashes":["1274566015","2561578252","2731221146","394248586","4145280475","749840385"]}