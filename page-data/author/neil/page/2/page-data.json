{"componentChunkName":"component---src-templates-author-tsx","path":"/author/neil/page/2/","result":{"data":{"ghostAuthor":{"slug":"neil","name":"Neil McAllister","bio":null,"cover_image":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","location":"San Francisco, USA","website":null,"twitter":null,"facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5ef263fe60f25700399d089d","title":"Beyond Kubernetes: Bringing Microservices Together with Service Mesh","slug":"beyond-kubernetes-bringing-microservices-together-with-service-mesh","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/06/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/9c9a2faffb966d5a2991625087a01021/47498/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh.jpg","srcSet":"/static/9c9a2faffb966d5a2991625087a01021/9dc27/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh.jpg 300w,\n/static/9c9a2faffb966d5a2991625087a01021/4fe8c/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh.jpg 600w,\n/static/9c9a2faffb966d5a2991625087a01021/47498/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh.jpg 1200w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"When adopting microservices, Kubernetes alone may not be enough to handle more complex networking challenges that arise. This is the job of a service mesh.","custom_excerpt":"When adopting microservices, Kubernetes alone may not be enough to handle more complex networking challenges that arise. This is the job of a service mesh.","visibility":"public","created_at_pretty":"23 June, 2020","published_at_pretty":"June 24, 2020","updated_at_pretty":"16 July, 2020","created_at":"2020-06-23T20:20:14.000+00:00","published_at":"2020-06-24T06:43:11.000+00:00","updated_at":"2020-07-16T13:26:09.000+00:00","meta_title":"Beyond Kubernetes: Bringing Microservices Together with Service Mesh","meta_description":"When adopting microservices, Kubernetes alone may not be enough to handle more complex networking challenges that arise. This is the job of a service mesh.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/06/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh---Twitter.jpg","twitter_title":null,"authors":[{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Kubernetes","slug":"kubernetes","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"When adopting the microservices application model, Kubernetes is a natural\nstarting point. Extensible, open source, and with a thriving ecosystem,\nKubernetes has emerged as the go-to orchestrator for containerized\ninfrastructure. When used as the foundation for microservices, however, you may\nfind that Kubernetes alone isn’t enough to handle the more complex networking\nchallenges that arise. This is the job of a service mesh.\n\nOne of the most important aspects to consider about the microservices model is\nits heavy dependence on networking. Unfortunately, a network is seldom as\nreliable or resilient as its hypothetical diagram suggests. Services fail,\nnetwork routes change or disappear, and unexpected traffic can disrupt normal\nusage patterns. This is even more true for containerized microservices, which by\ntheir nature tend to be stateless, ephemeral, and disposable. Maintaining the\nperformance and stability of such an environment is anything but simple.\nKubernetes addresses the first part of this challenge by automating the\nlifecycles of containers and their associated applications. When coupled with an \nIngress controller\n[https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/],\nsuch as Contour or Traefik [/traefik/], Kubernetes also manages communications\nfrom the external network to workloads running in the cluster and vice versa\n(sometimes called north-south traffic).\n\nService Mesh BasicsOf equal importance in a microservices environment, however,\nare communications between services within the cluster (known as east-west \ntraffic). While basic networking within the cluster is handled by Kubernetes\nitself, a service mesh is a dedicated infrastructure layer that handles many of\nthe routine networking tasks that are necessary for a loose collection of\ncontainerized services to work together as a cohesive application.\n\nThe Role of Service Mesh\nAn important property of a service mesh is that it decouples east-west\nnetworking functions from application logic. As the environment scales and new\nservices are added to the mix, they should be able to expect the same level of\nmanagement as their peers, without code changes or refactoring. Examples of\nfunctions of a service mesh include:\n\nTraffic control. Communications between the cluster and the external network\nrequire routing and management, and so do communications between services on the\ncluster. Tasks such as advanced load balancing\n[https://en.wikipedia.org/wiki/Load_balancing_(computing)] and rate limiting\n[https://cloud.google.com/solutions/rate-limiting-strategies-techniques] of\nservice-to-service traffic are primary functions of the service mesh, which\nhelps to prevent and contain disruptions and performance degradations that\nmisconfigured or misbehaving services can cause.\n\nSecurity. Even when ingress controls are in place to protect the cluster from\nexternal networking threats, attackers may still attempt to exploit trusted\nrelationships between services on the cluster. A service mesh can help here by\nproviding seamless authentication, access control, and management of encrypted\nlinks between services, among other security features.\n\nObservability. Another important factor is the ability of a service mesh to\nprovide consistent logging, metrics, and visibility into the inner workings of a\ncluster. The insights gained from these functions are invaluable for maintaining\nthe health and proper operation of microservices-based applications.\n\nOptions and Standards\nOver the years, various forms of application middleware have implemented\neast-west networking functions in various ways. It is only since the rise of\ncontainerized infrastructure, and Kubernetes in particular, that the concept of\na service mesh as a dedicated layer has truly crystallized. Even so, opinions on\nhow a mesh should be implemented still differ.\n\nStandardization offers some hope for clarity. Recently, a consortium of\ncloud-native software vendors has begun collaborating on the Service Mesh\nInterface (SMI) [https://smi-spec.io/], an evolving effort that is shepherded by\nthe Cloud Native Computing Foundation (CNCF) [https://cncf.io/]. The SMI\nspecification defines APIs for many of the networking functions described\nearlier. Still, these APIs can be implemented in multiple ways.\n\nThe sidecar pattern\n[https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/#example-1-sidecar-containers] \nis one way to design a service mesh for Kubernetes. In this model, a so-called\nsidecar container is deployed alongside each instance of a service within a pod\nto handle east-west traffic for that instance. This is a popular pattern for\nimplementing a service mesh, and is the method adopted by the likes of Istio and\nLinkerd (the latter a CNCF incubating project).\n\nAn alternative method is to deploy a service mesh proxy endpoint that runs as\nits own pod on each node of a cluster, using the Kubernetes concept of a \nDaemonSet [https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/]\n. This method has the advantage of being less invasive, in that the mesh proxy\ndoes not need to modify any Kubernetes objects and no network traffic is\nmodified without a service owner’s consent. This is the model adopted by Maesh\n[/maesh/].\n\nHow to Move Forward\nSo, while standardization helps make it easier to know what to expect from a\nservice mesh, important decisions remain before adopting a specific solution.\nEven choosing how to begin deploying a mesh can be challenging, owing to the\npotential for disruption of existing communication patterns within a cluster.\n\nThese decisions are made significantly easier when dealing with so-called\ngreenfield projects, where the clustered, microservices-based application is\nbuilt from the ground up, without dependencies on legacy infrastructure. This is\na happy situation to have, but it’s not always realistic, especially in\nenvironments where adoption of containerization is already mature.\n\nIf it will be necessary to run some services on a service mesh alongside other\nservices for which it is preferable to have them manage their own east-west\ntraffic, it may be worth looking for a loosely coupled solution, such as Maesh.\nThis has the advantage of allowing the teams that own individual services to opt\ninto the mesh when they are ready, rather than forcing a mass migration with\ninterdependencies that may be difficult to test.\n\nHowever you choose to proceed, the key takeaway should be that service mesh for\nKubernetes, while still an emerging technology, can often provide the “missing\npiece” that Kubernetes alone does not. By abstracting key east-west networking\nfeatures away from application logic, mesh solutions enable distributed,\nmicroservices-based applications to operate in a way that is managed,\nobservable, and secure, both when communicating with the outside world and\nwithin the cluster itself.\n\nTo learn more, check out this video\n[https://info.containo.us/video-understanding-service-mesh] about the advantages\nand disadvantages of a service mesh, and the appropriate situations for using\none.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/06/Beyond-Kubernetes-Bringing-Microservices-Together-with-Service-Mesh-1.jpg\" class=\"kg-image\" alt=\"Bringing microservices together with service mesh\"></figure><p>When adopting the microservices application model, Kubernetes is a natural starting point. Extensible, open source, and with a thriving ecosystem, Kubernetes has emerged as the go-to orchestrator for containerized infrastructure. When used as the foundation for microservices, however, you may find that Kubernetes alone isn’t enough to handle the more complex networking challenges that arise. This is the job of a <strong>service mesh</strong>.</p><p>One of the most important aspects to consider about the microservices model is its heavy dependence on networking. Unfortunately, a network is seldom as reliable or resilient as its hypothetical diagram suggests. Services fail, network routes change or disappear, and unexpected traffic can disrupt normal usage patterns. This is even more true for containerized microservices, which by their nature tend to be stateless, ephemeral, and disposable. Maintaining the performance and stability of such an environment is anything but simple. Kubernetes addresses the first part of this challenge by automating the lifecycles of containers and their associated applications. When coupled with an <a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/\">Ingress controller</a>, such as Contour or <a href=\"https://containous.ghost.io/traefik/\">Traefik</a>, Kubernetes also manages communications from the external network to workloads running in the cluster and vice versa (sometimes called <em>north-south</em> traffic).</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/06/Service-Mesh-Diagram@2x.jpg\" class=\"kg-image\" alt=\"Service Mesh Basics\"><figcaption>Service Mesh Basics</figcaption></figure><p>Of equal importance in a microservices environment, however, are communications between services within the cluster (known as <em>east-west</em> traffic). While basic networking within the cluster is handled by Kubernetes itself, a service mesh is a dedicated infrastructure layer that handles many of the routine networking tasks that are necessary for a loose collection of containerized services to work together as a cohesive application.</p><h2 id=\"the-role-of-service-mesh\">The Role of Service Mesh</h2><p>An important property of a service mesh is that it decouples east-west networking functions from application logic. As the environment scales and new services are added to the mix, they should be able to expect the same level of management as their peers, without code changes or refactoring. Examples of functions of a service mesh include:</p><!--kg-card-begin: markdown--><p><strong>Traffic control.</strong> Communications between the cluster and the external network require routing and management, and so do communications between services on the cluster. Tasks such as advanced <a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\" target=\"_blank\" rel=\"nofollow\">load balancing</a> and <a href=\"https://cloud.google.com/solutions/rate-limiting-strategies-techniques\" target=\"_blank\" rel=\"nofollow\">rate limiting</a> of service-to-service traffic are primary functions of the service mesh, which helps to prevent and contain disruptions and performance degradations that misconfigured or misbehaving services can cause.</p>\n<!--kg-card-end: markdown--><p><strong>Security. </strong>Even when ingress controls are in place to protect the cluster from external networking threats, attackers may still attempt to exploit trusted relationships between services on the cluster. A service mesh can help here by providing seamless authentication, access control, and management of encrypted links between services, among other security features.</p><p><strong>Observability. </strong>Another important factor is the ability of a service mesh to provide consistent logging, metrics, and visibility into the inner workings of a cluster. The insights gained from these functions are invaluable for maintaining the health and proper operation of microservices-based applications.</p><h2 id=\"options-and-standards\">Options and Standards</h2><p>Over the years, various forms of application middleware have implemented east-west networking functions in various ways. It is only since the rise of containerized infrastructure, and Kubernetes in particular, that the concept of a service mesh as a dedicated layer has truly crystallized. Even so, opinions on how a mesh should be implemented still differ.</p><p>Standardization offers some hope for clarity. Recently, a consortium of cloud-native software vendors has begun collaborating on the<a href=\"https://smi-spec.io/\"> Service Mesh Interface (SMI)</a>, an evolving effort that is shepherded by the Cloud Native<a href=\"https://cncf.io/\"> Computing Foundation (CNCF)</a>. The SMI specification defines APIs for many of the networking functions described earlier. Still, these APIs can be implemented in multiple ways.</p><!--kg-card-begin: markdown--><p>The <a href=\"https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/#example-1-sidecar-containers\" target=\"_blank\" rel=\"nofollow\">sidecar pattern</a> is one way to design a service mesh for Kubernetes. In this model, a so-called sidecar container is deployed alongside each instance of a service within a pod to handle east-west traffic for that instance. This is a popular pattern for implementing a service mesh, and is the method adopted by the likes of Istio and Linkerd (the latter a CNCF incubating project).</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>An alternative method is to deploy a service mesh proxy endpoint that runs as its own pod on each node of a cluster, using the Kubernetes concept of a <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/\" target=\"_blank\" rel=\"nofollow\">DaemonSet</a>. This method has the advantage of being less invasive, in that the mesh proxy does not need to modify any Kubernetes objects and no network traffic is modified without a service owner’s consent. This is the model adopted by <a href=\"https://containous.ghost.io/maesh/\">Maesh</a>.</p>\n<!--kg-card-end: markdown--><h2 id=\"how-to-move-forward\">How to Move Forward</h2><p>So, while standardization helps make it easier to know what to expect from a service mesh, important decisions remain before adopting a specific solution. Even choosing how to begin deploying a mesh can be challenging, owing to the potential for disruption of existing communication patterns within a cluster.</p><p>These decisions are made significantly easier when dealing with so-called greenfield projects, where the clustered, microservices-based application is built from the ground up, without dependencies on legacy infrastructure. This is a happy situation to have, but it’s not always realistic, especially in environments where adoption of containerization is already mature.</p><p>If it will be necessary to run some services on a service mesh alongside other services for which it is preferable to have them manage their own east-west traffic, it may be worth looking for a loosely coupled solution, such as Maesh. This has the advantage of allowing the teams that own individual services to opt into the mesh when they are ready, rather than forcing a mass migration with interdependencies that may be difficult to test.</p><p>However you choose to proceed, the key takeaway should be that service mesh for Kubernetes, while still an emerging technology, can often provide the “missing piece” that Kubernetes alone does not. By abstracting key east-west networking features away from application logic, mesh solutions enable distributed, microservices-based applications to operate in a way that is managed, observable, and secure, both when communicating with the outside world and within the cluster itself.</p><p>To learn more, <a href=\"https://info.containo.us/video-understanding-service-mesh\">check out this video</a> about the advantages and disadvantages of a <strong>service mesh</strong>, and the appropriate situations for using one.</p>","url":"https://containous.ghost.io/blog/beyond-kubernetes-bringing-microservices-together-with-service-mesh/","canonical_url":null,"uuid":"4b55f40d-0afe-4880-8a03-6815bd0e7bb9","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ef263fe60f25700399d089d","reading_time":4}},{"node":{"id":"Ghost__Post__5ee81ca7292c470045af26fe","title":"Securing your Kubernetes environment against external traffic threats","slug":"securing-your-kubernetes-environment-against-external-traffic-threats","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/06/Securing-your-Kubernetes-environment-against-external-traffic-threats-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/c597de81abf63dccc70c384729c03cf7/47498/Securing-your-Kubernetes-environment-against-external-traffic-threats-1.jpg","srcSet":"/static/c597de81abf63dccc70c384729c03cf7/9dc27/Securing-your-Kubernetes-environment-against-external-traffic-threats-1.jpg 300w,\n/static/c597de81abf63dccc70c384729c03cf7/4fe8c/Securing-your-Kubernetes-environment-against-external-traffic-threats-1.jpg 600w,\n/static/c597de81abf63dccc70c384729c03cf7/47498/Securing-your-Kubernetes-environment-against-external-traffic-threats-1.jpg 1200w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Kubernetes is often used to manage external-facing applications, so the need for protecting applications from harmful external traffic is nearly universal.","custom_excerpt":"Kubernetes is often used to manage external-facing applications, so the need for protecting applications from harmful external traffic is nearly universal.","visibility":"public","created_at_pretty":"16 June, 2020","published_at_pretty":"June 16, 2020","updated_at_pretty":"10 September, 2020","created_at":"2020-06-16T01:13:11.000+00:00","published_at":"2020-06-16T14:27:27.000+00:00","updated_at":"2020-09-10T05:14:27.000+00:00","meta_title":"Securing Kubernetes environment against external traffic threats","meta_description":"Kubernetes is often used to manage external-facing applications, so the need for protecting applications from harmful external traffic is nearly universal.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/06/Securing-your-Kubernetes-environment-against-external-traffic-threats-Twitter.jpg","twitter_title":null,"authors":[{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Kubernetes","slug":"kubernetes","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Kubernetes delivers many quality-of-life improvements for software engineering\nteams out of the box by automating the deployment and lifecycle management of\ncontainerized applications. However, security is one area where developers must\nstill be proactive, by identifying threat models and applying appropriate\nKubernetes security best practices to address them. \n\nGiven that Kubernetes is often used to manage external-facing applications, the\nneed for protecting applications from harmful external traffic is nearly\nuniversal. In this article we’ll review some of the general concerns that\ndevelopers should keep in mind in this context, and then discuss relevant\nKubernetes security approaches.\n\nTop external traffic concerns\nWhen it comes to security issues from external traffic, there are myriad\nconcerns that range from unintentional but detrimental behavior to organized,\nmalevolent attacks.\n\nUnfair usage\nAny application of even moderate complexity will exhibit significant variance in\nresource usage and execution time of requests. For example, certain operations\nmight trigger backend batch jobs or invoke complicated queries to datastores.\nAccordingly, the overall load imposed by a specific external client will be a\nfunction of the request types it sends and their distribution over time (for\nexample, bursty versus parallel requests). Because of this, it’s possible for a\nclient to unintentionally use an unfair portion of provisioned resources and\nnegatively impact other users.\n\nMisconfigured clients\nParticularly for API services, it’s common for incoming external traffic to have\nbeen generated by automated systems or client software whose behavior is driven\nby user-specific configuration settings. Settings that are misconfigured –\nwhether maliciously or unintentionally – can lead to anomalous behavior, which\ncan easily lead to undesirable load on the Kubernetes-managed application.\n\nMalicious clients\nAn unfortunate reality for any internet-facing application is that it will\ninevitably face nefarious attempts to identify and/or exploit potential security\nvulnerabilities in the software and gain some form of unauthorized access. Such\nattacks include zero-day exploits and brute-force attempts to penetrate the\nsystem, among others. If successful, these attacks can have significant negative\nconsequences beyond application downtime, including data breaches.\n\nDenial-of-service (DDoS) and distributed denial-of-service (DDoS)\nA malicious attacker may also intentionally try to limit or disrupt the resource\navailability for legitimate traffic, in what is known as a denial-of-service\n(DoS) attack. Such attacks often combine several of the previously mentioned\nelements. In their more sophisticated form, known as distributed\ndenial-of-service (DDoS), they can also be orchestrated such that a distributed\nand possible dynamic set of clients works together to send malformed or\nexcessive traffic simultaneously.\n\nMitigation strategies\nHaving reviewed the top concerns that harmful external traffic creates for\napplications, let’s look at some approaches to mitigating them. Specifically, by\nemploying an Ingress controller for Kubernetes\n[https://containo.us/blog/connecting-users-to-applications-with-kubernetes-ingress-controllers/]\n, multiple options become available to consider as part of a comprehensive\nsecurity strategy.\n\nIP allow/deny lists\nOne approach to integrating security best practices is to employ network-level\nmechanisms. Specifically, the IP addresses of external traffic can be used to\nmake binary decisions on whether the traffic should be allowed at all. If\napplications have a stable set of known clients, a proactive allow list approach\nin which unknown IP addresses are ignored may be applicable. On the other hand,\nif valid traffic could come from anywhere, a reactive deny list can be\nmaintained based upon the identification of malicious traffic sources.\n\nConnection limits\nAnother network-level option is to limit the number of connections that an\nexternal client can create, which can help limit the impact of misconfigured\nclients as well as malicious users. One potential challenge, however, lies in\ndetermining an appropriate value to set for the connection limit. Many\nimplementations require a global setting that impacts all sources of traffic.\nParticularly when imposing connection limits by source IP address, scenarios in\nwhich multiple clients may share an IP address – such as NAT, for example –\nshould be considered.\n\nRate limiting\nMoving up the networking stack, an Ingress controller can be used to enable rate\nlimiting at the request level. These limits gate the number of requests in a\ngiven time window (for example, requests per second) and can be enforced in a\nvariety of ways. Common options include setting rate limits based upon client IP\naddress or a value in the HTTP header. Rate limits can also be configured so a\nmaximum request rate is enforced at service hosts.\n\nLimiting simultaneous requests\nAs mentioned earlier, request-processing times may vary based on a variety of\nfactors. While rate limits can enforce the number of external requests submitted\nby a client in a given time frame, the number of concurrent requests being\nprocessed may vary significantly depending upon the relative processing time of\neach type of request. To address this dimension, external traffic can be managed\nby setting limits so that services don’t become overwhelmed by a large number of\nsimultaneous, resource-intensive requests.\n\nAudit logging\nA question that often arises is how operations engineers can determine when the\naforementioned mitigation mechanisms should be invoked, as well as their overall\neffectiveness. For example, it’s preferable to detect DDoS attacks in their\nearliest stages to minimize disruption to end users. How to spot them when they\nstart? Access logs can be invaluable for this purpose. They are commonly\nincorporated as part of a broader security information and event management\n(SIEM) system. When employed with Kubernetes Ingress controllers like Traefik,\nthese logs also make it possible to automate remediation strategies based upon\ndetected external traffic patterns.\n\nStay vigilant\nWhen considering how best to protect workloads from harmful external traffic,\nthe most effective approach will likely require a combination of several of the\nmechanisms we’ve discussed. But which ones? The need for any one measure may not\nbe immediately apparent, so its utility should be continuously reviewed with the\nhelp of data from audit logs. It’s important that applications teams consider\nthe ability of their Kubernetes platform to provide a broad set of mechanisms\nthat can be called upon as security requirements change and evolve. \n\nSolutions like TraefikEE [https://containo.us/traefikee/] align well with this\nmindset by providing a rich and robust set of security features for managing\nexternal traffic embedded in the Kubernetes Ingress controller\n[https://containo.us/solutions/kubernetes-ingress/]. Learn more about TraefikEE\nin this 5-minute video [https://info.containo.us/request-demo-traefikee].","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/06/Securing-your-Kubernetes-environment-against-external-traffic-threats.jpg\" class=\"kg-image\" alt=\"Securing your Kubernetes environment\"></figure><p>Kubernetes delivers many quality-of-life improvements for software engineering teams out of the box by automating the deployment and lifecycle management of containerized applications. However, security is one area where developers must still be proactive, by identifying threat models and applying appropriate Kubernetes security best practices to address them. </p><p>Given that Kubernetes is often used to manage external-facing applications, the need for protecting applications from harmful external traffic is nearly universal. In this article we’ll review some of the general concerns that developers should keep in mind in this context, and then discuss relevant Kubernetes security approaches.</p><h2 id=\"top-external-traffic-concerns\">Top external traffic concerns</h2><p>When it comes to security issues from external traffic, there are myriad concerns that range from unintentional but detrimental behavior to organized, malevolent attacks.</p><h3 id=\"unfair-usage\">Unfair usage</h3><p>Any application of even moderate complexity will exhibit significant variance in resource usage and execution time of requests. For example, certain operations might trigger backend batch jobs or invoke complicated queries to datastores. Accordingly, the overall load imposed by a specific external client will be a function of the request types it sends and their distribution over time (for example, bursty versus parallel requests). Because of this, it’s possible for a client to unintentionally use an unfair portion of provisioned resources and negatively impact other users.</p><h3 id=\"misconfigured-clients\">Misconfigured clients</h3><p>Particularly for API services, it’s common for incoming external traffic to have been generated by automated systems or client software whose behavior is driven by user-specific configuration settings. Settings that are misconfigured – whether maliciously or unintentionally – can lead to anomalous behavior, which can easily lead to undesirable load on the Kubernetes-managed application.</p><h3 id=\"malicious-clients\">Malicious clients</h3><p>An unfortunate reality for any internet-facing application is that it will inevitably face nefarious attempts to identify and/or exploit potential security vulnerabilities in the software and gain some form of unauthorized access. Such attacks include zero-day exploits and brute-force attempts to penetrate the system, among others. If successful, these attacks can have significant negative consequences beyond application downtime, including data breaches.</p><h3 id=\"denial-of-service-ddos-and-distributed-denial-of-service-ddos-\">Denial-of-service (DDoS) and distributed denial-of-service (DDoS)</h3><p>A malicious attacker may also intentionally try to limit or disrupt the resource availability for legitimate traffic, in what is known as a denial-of-service (DoS) attack. Such attacks often combine several of the previously mentioned elements. In their more sophisticated form, known as distributed denial-of-service (DDoS), they can also be orchestrated such that a distributed and possible dynamic set of clients works together to send malformed or excessive traffic simultaneously.</p><h2 id=\"mitigation-strategies\">Mitigation strategies</h2><p>Having reviewed the top concerns that harmful external traffic creates for applications, let’s look at some approaches to mitigating them. Specifically, by employing an <a href=\"https://containo.us/blog/connecting-users-to-applications-with-kubernetes-ingress-controllers/\">Ingress controller for Kubernetes</a>, multiple options become available to consider as part of a comprehensive security strategy.</p><h3 id=\"ip-allow-deny-lists\">IP allow/deny lists</h3><p>One approach to integrating security best practices is to employ network-level mechanisms. Specifically, the IP addresses of external traffic can be used to make binary decisions on whether the traffic should be allowed at all. If applications have a stable set of known clients, a proactive allow list approach in which unknown IP addresses are ignored may be applicable. On the other hand, if valid traffic could come from anywhere, a reactive deny list can be maintained based upon the identification of malicious traffic sources.</p><h3 id=\"connection-limits\">Connection limits</h3><p>Another network-level option is to limit the number of connections that an external client can create, which can help limit the impact of misconfigured clients as well as malicious users. One potential challenge, however, lies in determining an appropriate value to set for the connection limit. Many implementations require a global setting that impacts all sources of traffic. Particularly when imposing connection limits by source IP address, scenarios in which multiple clients may share an IP address – such as NAT, for example – should be considered.</p><h3 id=\"rate-limiting\">Rate limiting</h3><p>Moving up the networking stack, an Ingress controller can be used to enable rate limiting at the request level. These limits gate the number of requests in a given time window (for example, requests per second) and can be enforced in a variety of ways. Common options include setting rate limits based upon client IP address or a value in the HTTP header. Rate limits can also be configured so a maximum request rate is enforced at service hosts.</p><h3 id=\"limiting-simultaneous-requests\">Limiting simultaneous requests</h3><p>As mentioned earlier, request-processing times may vary based on a variety of factors. While rate limits can enforce the number of external requests submitted by a client in a given time frame, the number of concurrent requests being processed may vary significantly depending upon the relative processing time of each type of request. To address this dimension, external traffic can be managed by setting limits so that services don’t become overwhelmed by a large number of simultaneous, resource-intensive requests.</p><h3 id=\"audit-logging\">Audit logging</h3><p>A question that often arises is how operations engineers can determine when the aforementioned mitigation mechanisms should be invoked, as well as their overall effectiveness. For example, it’s preferable to detect DDoS attacks in their earliest stages to minimize disruption to end users. How to spot them when they start? Access logs can be invaluable for this purpose. They are commonly incorporated as part of a broader security information and event management (SIEM) system. When employed with Kubernetes Ingress controllers like Traefik, these logs also make it possible to automate remediation strategies based upon detected external traffic patterns.</p><h2 id=\"stay-vigilant\">Stay vigilant</h2><p>When considering how best to protect workloads from harmful external traffic, the most effective approach will likely require a combination of several of the mechanisms we’ve discussed. But which ones? The need for any one measure may not be immediately apparent, so its utility should be continuously reviewed with the help of data from audit logs. It’s important that applications teams consider the ability of their Kubernetes platform to provide a broad set of mechanisms that can be called upon as security requirements change and evolve. </p><!--kg-card-begin: markdown--><p>Solutions like <a href=\"https://containo.us/traefikee/\">TraefikEE</a> align well with this mindset by providing a rich and robust set of security features for managing external traffic embedded in the <a href=\"https://containo.us/solutions/kubernetes-ingress/\">Kubernetes Ingress controller</a>. Learn more about TraefikEE in <a href=\"https://info.containo.us/request-demo-traefikee\" target=\"_blank\" rel=\"nofollow\">this 5-minute video</a>.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/securing-your-kubernetes-environment-against-external-traffic-threats/","canonical_url":null,"uuid":"2da8c425-5cf1-4594-83bf-f9732530e7e0","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ee81ca7292c470045af26fe","reading_time":4}}]}},"pageContext":{"slug":"neil","limit":9,"skip":9,"numberOfPages":2,"humanPageNumber":2,"prevPageNumber":1,"nextPageNumber":null,"previousPagePath":"/author/neil/","nextPagePath":null}},"staticQueryHashes":["1274566015","2561578252","2731221146","394248586","4145280475","749840385"]}