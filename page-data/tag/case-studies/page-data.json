{"componentChunkName":"component---src-templates-tag-tsx","path":"/tag/case-studies/","result":{"data":{"ghostTag":{"slug":"case-studies","name":"Case Studies","visibility":"public","feature_image":null,"featureImageSharp":null,"description":null,"meta_title":"Case studies | Containous","meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic."},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5f97b3e69895340039a5049a","title":"How Vaudoise Insurance Deployed Traefik Enterprise to Successfully Modernize with Microservices","slug":"how-vaudoise-insurance-deployed-traefik-enterprise-to-successfully-modernize-with-microservices","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/2a1ae030bfab70f582e8aa01d0400eb8/f3583/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png","srcSet":"/static/2a1ae030bfab70f582e8aa01d0400eb8/630fb/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png 300w,\n/static/2a1ae030bfab70f582e8aa01d0400eb8/2a4de/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png 600w,\n/static/2a1ae030bfab70f582e8aa01d0400eb8/f3583/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png 1200w,\n/static/2a1ae030bfab70f582e8aa01d0400eb8/bbee5/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png 1800w,\n/static/2a1ae030bfab70f582e8aa01d0400eb8/0ef64/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise.png 2400w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"As an insurance company, security and service uptime are two of Vaudoise's highest requirements. Traefik Enterprise provides high availability and encryption capabilities necessary for Vaudoise, in a single, easy-to-use solution.","custom_excerpt":"As an insurance company, security and service uptime are two of Vaudoise's highest requirements. Traefik Enterprise provides high availability and encryption capabilities necessary for Vaudoise, in a single, easy-to-use solution.","visibility":"public","created_at_pretty":"27 October, 2020","published_at_pretty":"October 27, 2020","updated_at_pretty":"17 November, 2020","created_at":"2020-10-27T05:45:10.000+00:00","published_at":"2020-10-27T06:05:22.000+00:00","updated_at":"2020-11-17T05:26:20.000+00:00","meta_title":"How Vaudoise Deployed Traefik Enterprise to Modernize w/ Microservices","meta_description":"Traefik Enterprise provides high availability and encryption capabilities necessary for Vaudoise, in a single, easy-to-use solution.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise---Twitter.png","twitter_title":"How Vaudoise Insurance Deployed Traefik Enterprise to Successfully Modernize with Microservices","authors":[{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Case Studies","slug":"case-studies","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic.","meta_title":"Case studies | Containous","visibility":"public"}],"plaintext":"About Vaudoise Insurance\nVaudoise Insurance [https://www.vaudoise.ch] is the only independent private\ninsurance company with a decision-making center in French-speaking Switzerland.\nFounded in 1895, it is one of the ten largest private insurers in the Swiss\nmarket. Vaudoise provides individuals and SMEs with high-level advice and\nsolutions in all areas of insurance and pension provision. Through its network\nof around 100 branches across Switzerland, it offers its customers local\nservice, in terms of both advice and claims settlement. The Group employs\nroughly 1,550 people, including around 100 apprentices.\n\nOverview\nHow do you modernize a company with 125 years of history? Vaudoise Insurance\nentered the digital age decades ago, yet the technical debt incurred by years of\nlegacy computing was becoming too much to manage. Its monolithic systems were\nburdensome to upgrade and rolling out new features required coordination from\nmultiple teams. The pace of change was too slow.\n\nVaudoise’s technical teams needed to become more agile to match the pace of\ntoday’s business environment. Its 150-200 IT staffers shared the task of\nmanaging some 300 applications, and too many of these were silos. What the\ncompany’s development teams wanted was to expose more of its internal data via\nAPIs, making it easier to build new, lightweight applications based on\nmicroservices.\n\nComplicating matters was the fact that insurance is a highly regulated industry,\nparticularly when it comes to data privacy. That meant Vaudoise would need to\ncontinue to host and manage some of its applications on premises, and any new\ntechnologies introduced could not significantly add to the existing management\nburden.\n\nChallenge\nVaudoise’s strategy was to begin developing new applications as Docker\ncontainers, while simultaneously modernizing its monolithic, legacy applications\nby decomposing them into containerized services. The intent was that this would\nnot only speed time-to-delivery for new applications, but it would also allow\ndevelopment teams to experiment with new technologies (such as NoSQL databases)\nthat simply weren’t available to their legacy systems.\n\nDamien Desvignes and Patrick Monbaron, application lifecycle management (ALM)\nengineer and system engineer at Vaudoise, belong to the multidisciplinary team\nresponsible for the Docker platform. The company chose Docker Enterprise as its\ncontainer platform, both because of its proven technology and because its Docker\nSwarm mode orchestration layer was significantly less complicated to deploy than\nalternatives (such as Kubernetes).\n\nStill this left Damien and Patrick’s team with another problem. Now that it had\ndecided how it would host its containers and services, how would it publish\nthem?\n\n> \"We needed a tool that would allow us to dynamically publish new services, or\nchange the configuration of existing services, that was simple to handle and\nthat did not need a restart, unlike the usual nginx-based tools.” Patrick\nMonbaron, system engineer at Vaudoise\n> “As an insurance company, security and service uptime are two of our highest\nrequirements. Traefik Enterprise provides high availability and encryption\ncapabilities necessary for Vaudoise, in a single, easy-to-use solution.” Patrick\nMonbaron, system engineer at Vaudoise\nSolution\nPrior to the company initiative, Damien had successfully used Traefik for over 3\nyears and was confident that its ease-of-use, versatile feature set, and broad\necosystem made it the right choice for application networking with containers.\n\nAs Vaudoise started this new containerized application strategy, Damien\nimmediately sought out Traefik Enterprise\n[https://traefik.io/traefik-enterprise/] to help satisfy the company’s\nproduction networking requirements. Traefik Enterprise provides out-of-the-box\nhigh availability (HA) and security features that are essential for a business\noperating in the insurance industry. For example, Traefik Enterprise can\ninterface with the Docker Universal Control Plane (UCP) to enable role-based\naccess control (RBAC) on the cluster. Additionally, Traefik Enterprise includes\nfast, responsive enterprise support from Traefik Labs, giving Vaudoise the peace\nof mind of having a partner to rely on.\n\nFrom an operations perspective, Patrick and his infrastructure team benefited\nfrom using Traefik Enterprise by securing and managing Docker Swarm ingress\ntraffic, making it faster and easier to deploy new services. Even HTTPS\nencryption is now centrally managed by the infrastructure team, leaving\ndevelopers free to concentrate on software delivery, without a lot of cross-team\ncoordination.\n\n> “Developers are a lot more autonomous than before. Dev teams can manage the\nrewrite rules on their own, for example, which was not possible before.” Patrick\nMonbaron, system engineer at Vaudoise\nBottom Line\nVaudoise Insurance is only at the beginning of its journey with containers and\nTraefik Enterprise. Damien and Patrick are looking forward to working with\nfeatures introduced in recent versions of Traefik, including the ability to\nsupport applications that use the TCP and UDP protocols, in addition to HTTP.\nEmerging technologies such as service mesh – a feature offered by Traefik\nEnterprise 2.2 – are also under consideration.\n\nDown the road, Vaudoise may even consider moving from Docker Swarm to a more\nfull-featured container orchestrator, such as Kubernetes, confident that Traefik\nEnterprise will continue to support that new environment.\n\nAlready, however, the features of Traefik Enterprise – including enterprise\nsupport from Containous – have been instrumental in Vaudoise’s IT modernization\njourney. Traefik’s vibrant and active ecosystem, coupled with the enterprise\nfeatures and evolving technology roadmap of Traefik Enterprise, allow Vaudoise\nto proceed with confidence, knowing it will be well-positioned for continued\nsuccess as it moves into the next phase of its long history\n\nWhat’s Next?\n * Discover Traefik Enterprise [https://traefik.io/traefik-enterprise/], and \n   request your demo\n   [https://info.traefik.io/en/request-demo-traefik-enterprise].","html":"<figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise-2.jpg\" class=\"kg-image\" alt=\"How Vaudoise Insurance Deployed Traefik Enterprise to Successfully Modernize with Microservices\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise-2.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise-2.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise-2.jpg 1600w, https://containous.ghost.io/content/images/2020/10/How-Vaudoise-Insurance-Deployed-Traefik-Enterprise-2.jpg 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><h2 id=\"about-vaudoise-insurance\"><strong>About Vaudoise Insurance</strong></h2><!--kg-card-begin: markdown--><p><a href=\"https://www.vaudoise.ch\" target=\"_blank\" rel=\"nofollow\">Vaudoise Insurance</a> is the only independent private insurance company with a decision-making center in French-speaking Switzerland. Founded in 1895, it is one of the ten largest private insurers in the Swiss market. Vaudoise provides individuals and SMEs with high-level advice and solutions in all areas of insurance and pension provision. Through its network of around 100 branches across Switzerland, it offers its customers local service, in terms of both advice and claims settlement. The Group employs roughly 1,550 people, including around 100 apprentices.</p>\n<!--kg-card-end: markdown--><h2 id=\"overview\"><strong>Overview</strong></h2><p>How do you modernize a company with 125 years of history? Vaudoise Insurance entered the digital age decades ago, yet the technical debt incurred by years of legacy computing was becoming too much to manage. Its monolithic systems were burdensome to upgrade and rolling out new features required coordination from multiple teams. The pace of change was too slow.</p><p>Vaudoise’s technical teams needed to become more agile to match the pace of today’s business environment. Its 150-200 IT staffers shared the task of managing some 300 applications, and too many of these were silos. What the company’s development teams wanted was to expose more of its internal data via APIs, making it easier to build new, lightweight applications based on microservices.</p><p>Complicating matters was the fact that insurance is a highly regulated industry, particularly when it comes to data privacy. That meant Vaudoise would need to continue to host and manage some of its applications on premises, and any new technologies introduced could not significantly add to the existing management burden.</p><h2 id=\"challenge\"><strong>Challenge</strong></h2><p>Vaudoise’s strategy was to begin developing new applications as Docker containers, while simultaneously modernizing its monolithic, legacy applications by decomposing them into containerized services. The intent was that this would not only speed time-to-delivery for new applications, but it would also allow development teams to experiment with new technologies (such as NoSQL databases) that simply weren’t available to their legacy systems.</p><p>Damien Desvignes and Patrick Monbaron, application lifecycle management (ALM) engineer and system engineer at Vaudoise, belong to the multidisciplinary team responsible for the Docker platform. The company chose Docker Enterprise as its container platform, both because of its proven technology and because its Docker Swarm mode orchestration layer was significantly less complicated to deploy than alternatives (such as Kubernetes).</p><p>Still this left Damien and Patrick’s team with another problem. Now that it had decided how it would host its containers and services, how would it publish them?</p><blockquote>\"We needed a tool that would allow us to dynamically publish new services, or change the configuration of existing services, that was simple to handle and that did not need a restart, unlike the usual nginx-based tools.”<strong> </strong>Patrick Monbaron, system engineer at Vaudoise</blockquote><blockquote>“As an insurance company, security and service uptime are two of our highest requirements. Traefik Enterprise provides high availability and encryption capabilities necessary for Vaudoise, in a single, easy-to-use solution.”<strong> </strong>Patrick Monbaron, system engineer at Vaudoise</blockquote><h2 id=\"solution\"><strong>Solution</strong></h2><p>Prior to the company initiative, Damien had successfully used Traefik for over 3 years and was confident that its ease-of-use, versatile feature set, and broad ecosystem made it the right choice for application networking with containers.</p><p>As Vaudoise started this new containerized application strategy, Damien immediately sought out <a href=\"https://traefik.io/traefik-enterprise/\">Traefik Enterprise</a> to help satisfy the company’s production networking requirements. Traefik Enterprise provides out-of-the-box high availability (HA) and security features that are essential for a business operating in the insurance industry. For example, Traefik Enterprise can interface with the Docker Universal Control Plane (UCP) to enable role-based access control (RBAC) on the cluster. Additionally, Traefik Enterprise includes fast, responsive enterprise support from Traefik Labs, giving Vaudoise the peace of mind of having a partner to rely on.</p><p>From an operations perspective, Patrick and his infrastructure team benefited from using Traefik Enterprise by securing and managing Docker Swarm ingress traffic, making it faster and easier to deploy new services. Even HTTPS encryption is now centrally managed by the infrastructure team, leaving developers free to concentrate on software delivery, without a lot of cross-team coordination.</p><blockquote>“Developers are a lot more autonomous than before. Dev teams can manage the rewrite rules on their own, for example, which was not possible before.” Patrick Monbaron, system engineer at Vaudoise</blockquote><h2 id=\"bottom-line\"><strong>Bottom Line</strong></h2><p>Vaudoise Insurance is only at the beginning of its journey with containers and Traefik Enterprise. Damien and Patrick are looking forward to working with features introduced in recent versions of Traefik, including the ability to support applications that use the TCP and UDP protocols, in addition to HTTP. Emerging technologies such as service mesh – a feature offered by Traefik Enterprise 2.2 – are also under consideration.</p><p>Down the road, Vaudoise may even consider moving from Docker Swarm to a more full-featured container orchestrator, such as Kubernetes, confident that Traefik Enterprise will continue to support that new environment.</p><p>Already, however, the features of Traefik Enterprise – including enterprise support from Containous – have been instrumental in Vaudoise’s IT modernization journey. Traefik’s vibrant and active ecosystem, coupled with the enterprise features and evolving technology roadmap of Traefik Enterprise, allow Vaudoise to proceed with confidence, knowing it will be well-positioned for continued success as it moves into the next phase of its long history</p><h2 id=\"what-s-next\">What’s Next?</h2><ul><li>Discover <a href=\"https://traefik.io/traefik-enterprise/\">Traefik Enterprise</a>, and <a href=\"https://info.traefik.io/en/request-demo-traefik-enterprise\">request your demo</a>.</li></ul>","url":"https://containous.ghost.io/blog/how-vaudoise-insurance-deployed-traefik-enterprise-to-successfully-modernize-with-microservices/","canonical_url":null,"uuid":"0d4cadb3-fdb1-455e-bb85-9e0f8e4cb840","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f97b3e69895340039a5049a","reading_time":4}},{"node":{"id":"Ghost__Post__5f29efcbaf4f3b0045f364ec","title":"Naologic Selects Traefik to Effortlessly Scale Networking to Meet Fast Business Growth","slug":"naologic-surpasses-scaling-demands-of-microservice-infrastructure-by-using-traefik","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/08/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/c7fe0bc1fd91cfa55d4a7a6241be4aba/47498/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg","srcSet":"/static/c7fe0bc1fd91cfa55d4a7a6241be4aba/9dc27/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg 300w,\n/static/c7fe0bc1fd91cfa55d4a7a6241be4aba/4fe8c/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg 600w,\n/static/c7fe0bc1fd91cfa55d4a7a6241be4aba/47498/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg 1200w,\n/static/c7fe0bc1fd91cfa55d4a7a6241be4aba/52258/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg 1800w,\n/static/c7fe0bc1fd91cfa55d4a7a6241be4aba/a41d1/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Implementing Traefik at Naologic saved them over a thousand hours of engineering time, and eliminated time-consuming manual configuration of NGINX.","custom_excerpt":"Implementing Traefik at Naologic saved them over a thousand hours of engineering time, and eliminated time-consuming manual configuration of NGINX.","visibility":"public","created_at_pretty":"04 August, 2020","published_at_pretty":"August 25, 2020","updated_at_pretty":"17 September, 2020","created_at":"2020-08-04T23:31:23.000+00:00","published_at":"2020-08-25T14:30:00.000+00:00","updated_at":"2020-09-17T17:11:08.000+00:00","meta_title":"Naologic Selects Traefik to Scale Networking to Meet Business Growth","meta_description":"Implementing Traefik at Naologic saved them over a thousand hours of engineering time, and eliminated time-consuming manual configuration of NGINX.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/08/Twitter.png","twitter_title":"Naologic Selects Traefik to Effortlessly Scale Networking to Meet Fast Business Growth","authors":[{"name":"Patricia Dugan ","slug":"patricia","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/01/me-looking-cute.JPG","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Patricia Dugan ","slug":"patricia","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/01/me-looking-cute.JPG","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Case Studies","slug":"case-studies","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic.","meta_title":"Case studies | Containous","visibility":"public"}],"plaintext":"About Naologic\nNaologic [https://naologic.com/] is an end-to-end business management solution\nthat allows service providers to manage their teams, finances, and integrate\nproducts. Their low-code Software as a Service ERP platform provides wholesale\nand B2B e-commerce companies with the ability to configure and deploy custom ERP\nsystems with just a few clicks.\n\nOverview\nNaologic empowers customers to build customizable and scalable ERP systems\nwithout the complexity of building functionalities such as searching, invoicing,\norder processing, and reporting.\n\nTheir main offering, the back-office builder (BOB), is an online editor used to\ncreate powerful applications without the need to write code.\n\nTo deliver the platform performance necessary for their customers, Naologic\nbuilt their infrastructure in a highly elastic and dynamic manner, running on\nthree clusters, with over 100 nodes total. The entire software platform is\nmanaged and deployed automatically using Kubernetes, and a Gitlab build\npipeline, relying on open source solutions as a fundamental part of the CI/CD\ntoolchain. \n\nChallenge\nIn order to service the growing customer base, Naologic uses a managed platform\nthat continuously launches thousands of automated, secure systems with complex\nconfigurations behind SSL-capable proxies. At any given time, 20 to 40 ports may\nbe opened for microservices communications (WebSockets, HTTP), using multiple\nDocker networks. Before implementing Traefik, Naologic was using NGINX and\nconstrained by the sheer volume of configuration changes requiring frequent\nrestarts (causing connection drops), making for an increasingly complex and\ntime-consuming process.\n\nSolution\nIn order to simplify the  maintenance of their large scale microservice\ninfrastructure, the team at Naologic decided to move the entire platform to\nKubernetes with Traefik as their Ingress Controller\n[/solutions/kubernetes-ingress/] for managing routing and load balancing of\ntheir applications. \n\n> “The ease of implementation with Traefik saved us over 1,000 engineering hours.\nThe biggest win was being able to launch new developer environments within days\ninstead of weeks.” - Gabriel Paunescu, CEO\nAs an additional benefit, Traefik’s auto-discovery feature, with the ability to\nseamlessly forward Docker network configurations into Traefik, has allowed them\nto streamline efforts when deploying Docker containers using temporary DNS\nconfigurations with their build tool. Since Naologic is operating multiple\nplatforms, including Docker Swarm and Kubernetes, Traefik’s universal approach\nto configuration means they no longer have to maintain independent routing\nsolutions for their various environments.\n\nBottom Line\nImplementing Traefik at Naologic saved them over a thousand hours of engineering\ntime, and eliminated time-consuming manual configuration of NGINX. With this new\ncombination, Naologic is ready and capable of meeting the high-projected growth\nthat they envision for the future.\n\nWhat’s Next?\n * Get started with Traefik [/traefik/] today\n * Ready for production deployments? Discover Traefik Enterprise Edition\n   [/traefikee/], and request your demo\n   [https://info.containo.us/request-demo-traefikee]","html":"<figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/08/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth.jpg\" class=\"kg-image\" alt=\"Naologic Selects Traefik to Effortlessly Scale Networking to Meet Fast Business Growth\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/08/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/08/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/08/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth.jpg 1600w, https://containous.ghost.io/content/images/2020/08/Naologic-Selects-Traefik-to-Effortlessly-Scale-Networking-to-Meet-Fast-Business-Growth.jpg 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><h2 id=\"about-naologic\">About Naologic</h2><!--kg-card-begin: markdown--><p><a href=\"https://naologic.com/\" target=\"_blank\" rel=\"nofollow\">Naologic</a> is an end-to-end business management solution that allows service providers to manage their teams, finances, and integrate products. Their low-code Software as a Service ERP platform provides wholesale and B2B e-commerce companies with the ability to configure and deploy custom ERP systems with just a few clicks.</p>\n<!--kg-card-end: markdown--><h2 id=\"overview\">Overview</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://lh4.googleusercontent.com/-g2XXPxWFVe0LuNdf3fpNzvHZOc5U3GGIKfiZ0UHGVbwQU6a0zjOQpEBH20TeqZzifME7Wacj6iyk3VEpLYwooGL-UNUdGNxrBobSK-Oksbk8SHYiMJeyddauxuWs_3zC-NqTURE\" class=\"kg-image\" alt=\"Naologic Apps\"></figure><p>Naologic empowers customers to build customizable and scalable ERP systems without the complexity of building functionalities such as searching, invoicing, order processing, and reporting.</p><p>Their main offering, the back-office builder (BOB), is an online editor used to create powerful applications without the need to write code.</p><p>To deliver the platform performance necessary for their customers, Naologic built their infrastructure in a highly elastic and dynamic manner, running on three clusters, with over 100 nodes total. The entire software platform is managed and deployed automatically using Kubernetes, and a Gitlab build pipeline, relying on open source solutions as a fundamental part of the CI/CD toolchain. </p><h2 id=\"challenge\">Challenge</h2><p>In order to service the growing customer base, Naologic uses a managed platform that continuously launches thousands of automated, secure systems with complex configurations behind SSL-capable proxies. At any given time, 20 to 40 ports may be opened for microservices communications (WebSockets, HTTP), using multiple Docker networks. Before implementing Traefik, Naologic was using NGINX and constrained by the sheer volume of configuration changes requiring frequent restarts (causing connection drops), making for an increasingly complex and time-consuming process.</p><h2 id=\"solution\">Solution</h2><p>In order to simplify the  maintenance of their large scale microservice infrastructure, the team at Naologic decided to move the entire platform to Kubernetes with <a href=\"https://containous.ghost.io/solutions/kubernetes-ingress/\">Traefik as their Ingress Controller</a> for managing routing and load balancing of their applications. </p><blockquote><em>“The ease of implementation with Traefik saved us over 1,000 engineering hours. The biggest win was being able to launch new developer environments within days instead of weeks.” - Gabriel Paunescu, CEO</em></blockquote><p>As an additional benefit, Traefik’s auto-discovery feature, with the ability to seamlessly forward Docker network configurations into Traefik, has allowed them to streamline efforts when deploying Docker containers using temporary DNS configurations with their build tool. Since Naologic is operating multiple platforms, including Docker Swarm and Kubernetes, Traefik’s universal approach to configuration means they no longer have to maintain independent routing solutions for their various environments.</p><h2 id=\"bottom-line\">Bottom Line</h2><p>Implementing Traefik at Naologic saved them over a thousand hours of engineering time, and eliminated time-consuming manual configuration of NGINX. With this new combination, Naologic is ready and capable of meeting the high-projected growth that they envision for the future.</p><h2 id=\"what-s-next\">What’s Next?</h2><ul><li>Get started with <a href=\"https://containous.ghost.io/traefik/\" rel=\"noopener nofollow\">Traefik</a> today</li><li>Ready for production deployments? <a href=\"https://containous.ghost.io/traefikee/\">Discover Traefik Enterprise Edition</a>, and <a href=\"https://info.containo.us/request-demo-traefikee\" rel=\"noopener nofollow\">request your demo</a></li></ul>","url":"https://containous.ghost.io/blog/naologic-surpasses-scaling-demands-of-microservice-infrastructure-by-using-traefik/","canonical_url":null,"uuid":"6d83966e-8856-45c2-ace6-b750226d7ae5","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f29efcbaf4f3b0045f364ec","reading_time":2}},{"node":{"id":"Ghost__Post__5f1f638faf4f3b0045f363d9","title":"William & Mary uses Traefik to Streamline Complex Deployments Across Multiple Clouds","slug":"william-mary-uses-traefik-to-streamline-complex-deployments-across-multiple-clouds","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/08/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/734489a52f33e0d6290fb7981082dd0e/47498/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg","srcSet":"/static/734489a52f33e0d6290fb7981082dd0e/9dc27/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg 300w,\n/static/734489a52f33e0d6290fb7981082dd0e/4fe8c/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg 600w,\n/static/734489a52f33e0d6290fb7981082dd0e/47498/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg 1200w,\n/static/734489a52f33e0d6290fb7981082dd0e/52258/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg 1800w,\n/static/734489a52f33e0d6290fb7981082dd0e/a41d1/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Learn how William & Mary uses Traefik to streamline complex deployments across multiple clouds in a heterogenous ecosystem with Docker and Kubernetes. ","custom_excerpt":"Learn how William & Mary uses Traefik to streamline complex deployments across multiple clouds in a heterogenous ecosystem with Docker and Kubernetes. ","visibility":"public","created_at_pretty":"27 July, 2020","published_at_pretty":"August 10, 2020","updated_at_pretty":"17 September, 2020","created_at":"2020-07-27T23:30:23.000+00:00","published_at":"2020-08-10T23:02:00.000+00:00","updated_at":"2020-09-17T17:10:42.000+00:00","meta_title":"W&M uses Traefik to Streamline Complex Deployments Across Clouds ","meta_description":"Learn how William & Mary uses Traefik to streamline complex deployments across multiple clouds in a heterogenous ecosystem with Docker and Kubernetes. ","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/08/William---Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Twitter.png","twitter_title":"William & Mary uses Traefik to Streamline Complex Deployments Across Multiple Clouds","authors":[{"name":"Patricia Dugan ","slug":"patricia","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/01/me-looking-cute.JPG","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Patricia Dugan ","slug":"patricia","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/01/me-looking-cute.JPG","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Case Studies","slug":"case-studies","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic.","meta_title":"Case studies | Containous","visibility":"public"}],"plaintext":"About William & Mary\nWilliam & Mary [https://www.wm.edu/] is a top public research university and one\nof only eight “Public Ivy” schools in the United States, known for its rigorous\nacademic program. The W&M IT team manages the entire university’s technical\ninfrastructure, ensuring smooth operations for approximately 8,000 students and\n1,300 staff. The IT team of roughly 100 people administers campus networking,\ndesktop support, business and administrative faculty support, end-user client\nsupport, research, and high-performance computing.\n\nOverview\nAs a residential campus, W&M sees high application load and data volumes that\npeak at specific times in the academic calendar, especially during registration.\nThey operate within a heterogeneous technical infrastructure and host a wide\narray of technical integrations. Using proprietary software such as their ERP\nsystem, which requires updates that adhere to industry-specific regulations, are\ncentral to their infrastructure. The team selects open source software when\npossible, as it enables developer collaboration with industry and other colleges\nand universities.\n\nThe University’s technical infrastructure has successfully transformed from\nrunning primarily on legacy systems to boasting a diverse technical stack,\ninclusive of bare metal, containers, and the public cloud. It now supports a\nwide range of services from behind traditional load balancers and VMs, in\naddition to auto-scaling containerized distributed computing platforms, using\nTraefik and Kubernetes.\n\nChallenge\nPhil Fenstermacher, the Lead Linux Engineer, is part of the leadership team\nresponsible for building and managing the platforms used by the students and\nstaff at W&M. They are governed by a charter to provide functional solutions\nthat adhere to ever-changing, strict regulatory demands of industry-specific\nsoftware. There is an expectation to address these technological needs on a lean\nbudget. As innovation continues to change rapidly, and as their workload has\ngrown, the need to evolve from a virtualized environment to an environment\nfacilitating the use of containers and Kubernetes was a priority. \n\nAs an initial step towards transitioning to a container environment, they\nimplemented Docker Swarm and used the internal load balancer that ships with\nSwarm. Over time, the team at W&M needed a cloud-native reverse proxy as more\nworkloads were containerized and adopted into this new environment. These\nfeatures included the ability to use persistent sessions, while handling bursty,\nlarge workloads along with providing integrations with commercial software\nrequired for core business systems. The successful implementation of complex\nsystems such as ERP, CMS, and procurement software was critical. Docker Swarm\nwas easy to use, but these new requirements demanded a feature-rich and\nprotocol-aware load balancer to meet their needs.\n\nInspired by an upcoming ERP update, which would require managing hundreds of\nproduction and non-production virtual machines, Phil’s team sought to leverage\nthe inherent benefits of containers. Core requirements for this update forbade\nany rewrites of the commercial software, creating massive amounts of custom\nwrapper scripts, or changing the fundamental architecture of these applications.\nFinding a load balancer which seamlessly handled multiple integrations, and\nfunctioned well with Kubernetes and Docker Swarm, was the challenge.\n\nThey sought options to evaluate and came across Traefik.\n\nSolution\nTraefik checked many of the boxes: it is open source, highly cost-effective, has\na great user community [/community/], walks in close step with the expanding\nKubernetes community, but also works in the existing Docker Swarm environment.\nIn the spirit of academic rigor, though, Phil’s team wanted to test a variety of\nsolutions in the marketplace, such as NGINX, and HAproxy, making comparisons\nside by side with Traefik. \n\nPhil’s team observed that Traefik ran smoothly out-of-the-box and surpassed\nalternatives in the ways that mattered. The other solutions required large\namounts of manual configuration and lacked some service discovery capabilities.\nAlso, features one would expect from a modern cloud-native load balancer were\nsuspiciously absent. Traefik offered the functionality the team at W&M needed,\nincluding service discovery, persistent sessions, header modifications,\nPrometheus integration, a visually intuitive dashboard for monitoring, and easy\ndeployment and operation.\n\n> “The simplicity of using Traefik for persistent sessions, by simply copy and\npasting a line of code has been a game-changer.” - Phil Fenstermacher, Lead\nLinux Engineer\nThe University currently runs approximately 100 services through an on-premises\ndeployment of Traefik on Docker Swarm, and another 30 services on Kubernetes in\nthe cloud. A smaller on-premise  Kubernetes cluster hosts everything from\nacademic and enterprise applications. William & Mary’s small engineering team\ncan easily manage the 150+ services and 400+ containers because Traefik’s\nconfiguration is kept alongside application configurations using labels in\nDocker Swarm or an Ingress object in Kubernetes. A similar configuration scheme\nfor both orchestrators means the same engineers can support both without the\noverhead of another unique system.\n\nW&M has used Traefik since version 1.3 and has since migrated to Version 2.2 on\nKubernetes, which has support for native Ingress resource annotations. The\nlatest version of Traefik makes their engineering workflow more straightforward,\nnotably due to the flexibility of having both Ingress and Traefik's CRDs, which\nallow for less manual configuration and managing more complex settings with only\na single solution.\n\n> “It's like the Traefik load balancer is almost the boring piece. We don't spend\na lot of time talking about it. We use Traefik, it does what we need, what it's\nexpected to do, and reliably.”\nBottom line \nWilliam & Mary selects only high-performance, reliable, and budget-savvy\nsoftware solutions. They have chosen Traefik to manage the university's load\nbalancing needs, as the software is easy to implement, maintain, and trust.\nWithout Traefik, W&M faced the deployment of its new ERP system in a legacy\nenvironment using a traditional load balancer. Ultimately, this would have meant\nhigher costs for both operation and maintenance, all with less predictability,\nfunctionality, and consistency.\n\nWhat’s Next?\n * Get started with Traefik [/traefik/] today\n * Ready for production deployments? Discover Traefik Enterprise Edition\n   [/traefikee/], and request your demo\n   [https://info.containo.us/request-demo-traefikee]","html":"<figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/08/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog.jpg\" class=\"kg-image\" alt=\"William &amp; Mary uses Traefik to Streamline Complex Deployments Across Multiple Clouds\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/08/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/08/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/08/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog.jpg 1600w, https://containous.ghost.io/content/images/2020/08/William-Mary-uses-Traefik-to-Streamline-Complex-Deployments-Across-Multiple-Clouds---Blog.jpg 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><h2 id=\"about-william-mary\">About William &amp; Mary</h2><!--kg-card-begin: markdown--><p><a href=\"https://www.wm.edu/\" target=\"_blank\" rel=\"nofollow\">William &amp; Mary</a> is a top public research university and one of only eight “Public Ivy” schools in the United States, known for its rigorous academic program. The W&amp;M IT team manages the entire university’s technical infrastructure, ensuring smooth operations for approximately 8,000 students and 1,300 staff. The IT team of roughly 100 people administers campus networking, desktop support, business and administrative faculty support, end-user client support, research, and high-performance computing.</p>\n<!--kg-card-end: markdown--><h2 id=\"overview\">Overview</h2><p>As a residential campus, W&amp;M sees high application load and data volumes that peak at specific times in the academic calendar, especially during registration. They operate within a heterogeneous technical infrastructure and host a wide array of technical integrations. Using proprietary software such as their ERP system, which requires updates that adhere to industry-specific regulations, are central to their infrastructure. The team selects open source software when possible, as it enables developer collaboration with industry and other colleges and universities.</p><p>The University’s technical infrastructure has successfully transformed from running primarily on legacy systems to boasting a diverse technical stack, inclusive of bare metal, containers, and the public cloud. It now supports a wide range of services from behind traditional load balancers and VMs, in addition to auto-scaling containerized distributed computing platforms, using Traefik and Kubernetes.</p><h2 id=\"challenge\">Challenge</h2><p>Phil Fenstermacher, the Lead Linux Engineer, is part of the leadership team responsible for building and managing the platforms used by the students and staff at W&amp;M. They are governed by a charter to provide functional solutions that adhere to ever-changing, strict regulatory demands of industry-specific software. There is an expectation to address these technological needs on a lean budget. As innovation continues to change rapidly, and as their workload has grown, the need to evolve from a virtualized environment to an environment facilitating the use of containers and Kubernetes was a priority. </p><p>As an initial step towards transitioning to a container environment, they implemented Docker Swarm and used the internal load balancer that ships with Swarm. Over time, the team at W&amp;M needed a cloud-native reverse proxy as more workloads were containerized and adopted into this new environment. These features included the ability to use persistent sessions, while handling bursty, large workloads along with providing integrations with commercial software required for core business systems. The successful implementation of complex systems such as ERP, CMS, and procurement software was critical. Docker Swarm was easy to use, but these new requirements demanded a feature-rich and protocol-aware load balancer to meet their needs.</p><p>Inspired by an upcoming ERP update, which would require managing hundreds of production and non-production virtual machines, Phil’s team sought to leverage the inherent benefits of containers. Core requirements for this update forbade any rewrites of the commercial software, creating massive amounts of custom wrapper scripts, or changing the fundamental architecture of these applications. Finding a load balancer which seamlessly handled multiple integrations, and functioned well with Kubernetes and Docker Swarm, was the challenge.</p><p>They sought options to evaluate and came across Traefik.</p><h2 id=\"solution\">Solution</h2><p>Traefik checked many of the boxes: it is open source, highly cost-effective, has a <a href=\"https://containous.ghost.io/community/\">great user community</a>, walks in close step with the expanding Kubernetes community, but also works in the existing Docker Swarm environment. In the spirit of academic rigor, though, Phil’s team wanted to test a variety of solutions in the marketplace, such as NGINX, and HAproxy, making comparisons side by side with Traefik. </p><p>Phil’s team observed that Traefik ran smoothly out-of-the-box and surpassed alternatives in the ways that mattered. The other solutions required large amounts of manual configuration and lacked some service discovery capabilities. Also, features one would expect from a modern cloud-native load balancer were suspiciously absent. Traefik offered the functionality the team at W&amp;M needed, including service discovery, persistent sessions, header modifications, Prometheus integration, a visually intuitive dashboard for monitoring, and easy deployment and operation.</p><blockquote><em>“The simplicity of using Traefik for persistent sessions, by simply copy and pasting a line of code has been a game-changer.” - Phil Fenstermacher, Lead Linux Engineer</em></blockquote><p>The University currently runs approximately 100 services through an on-premises deployment of Traefik on Docker Swarm, and another 30 services on Kubernetes in the cloud. A smaller on-premise  Kubernetes cluster hosts everything from academic and enterprise applications. William &amp; Mary’s small engineering team can easily manage the 150+ services and 400+ containers because Traefik’s configuration is kept alongside application configurations using labels in Docker Swarm or an Ingress object in Kubernetes. A similar configuration scheme for both orchestrators means the same engineers can support both without the overhead of another unique system.</p><p>W&amp;M has used Traefik since version 1.3 and has since migrated to Version 2.2 on Kubernetes, which has support for native Ingress resource annotations. The latest version of Traefik makes their engineering workflow more straightforward, notably due to the flexibility of having both Ingress and Traefik's CRDs, which allow for less manual configuration and managing more complex settings with only a single solution.</p><blockquote><em>“It's like the Traefik load balancer is almost the boring piece. We don't spend a lot of time talking about it. We use Traefik, it does what we need, what it's expected to do, and reliably.</em>”</blockquote><h2 id=\"bottom-line\">Bottom line </h2><p>William &amp; Mary selects only high-performance, reliable, and budget-savvy software solutions. They have chosen Traefik to manage the university's load balancing needs, as the software is easy to implement, maintain, and trust. Without Traefik, W&amp;M faced the deployment of its new ERP system in a legacy environment using a traditional load balancer. Ultimately, this would have meant higher costs for both operation and maintenance, all with less predictability, functionality, and consistency.</p><h2 id=\"what-s-next\">What’s Next?</h2><ul><li>Get started with <a href=\"https://containous.ghost.io/traefik/\" rel=\"noopener nofollow\">Traefik</a> today</li><li>Ready for production deployments? <a href=\"https://containous.ghost.io/traefikee/\">Discover Traefik Enterprise Edition</a>, and <a href=\"https://info.containo.us/request-demo-traefikee\" rel=\"noopener nofollow\">request your demo</a></li></ul>","url":"https://containous.ghost.io/blog/william-mary-uses-traefik-to-streamline-complex-deployments-across-multiple-clouds/","canonical_url":null,"uuid":"974a28c8-dadf-4a34-8dfa-af19016186b3","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f1f638faf4f3b0045f363d9","reading_time":4}},{"node":{"id":"Ghost__Post__5e70260319908e0038512ce1","title":"Leading travel platform simplifies network management by deploying Traefik as preferred reverse proxy","slug":"leading-travel-platform-simplifies-network-management-by-deploying-traefik-as-preferred-reverse-proxy","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/04/LeadingTravelPlatformCaseStudy-Blog.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/64ef30f3fcc8e53d0d327951d52c5241/f3583/LeadingTravelPlatformCaseStudy-Blog.png","srcSet":"/static/64ef30f3fcc8e53d0d327951d52c5241/630fb/LeadingTravelPlatformCaseStudy-Blog.png 300w,\n/static/64ef30f3fcc8e53d0d327951d52c5241/2a4de/LeadingTravelPlatformCaseStudy-Blog.png 600w,\n/static/64ef30f3fcc8e53d0d327951d52c5241/f3583/LeadingTravelPlatformCaseStudy-Blog.png 1200w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Covering all aspects of traveling, hotels, flights, car rental, and vacation homes, this world leading travel company’s platform is managed by an infrastructure team that counts over one thousand engineers. ","custom_excerpt":"Covering all aspects of traveling, hotels, flights, car rental, and vacation homes, this world leading travel company’s platform is managed by an infrastructure team that counts over one thousand engineers. ","visibility":"public","created_at_pretty":"17 March, 2020","published_at_pretty":"March 18, 2020","updated_at_pretty":"27 July, 2020","created_at":"2020-03-17T01:21:07.000+00:00","published_at":"2020-03-18T14:49:14.000+00:00","updated_at":"2020-07-27T23:42:19.000+00:00","meta_title":"Leading travel platform eases network management with Traefik","meta_description":"The team needed a single reverse proxy solution to standardize and consolidate the existing disparate solutions and simplify new deployments.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/03/Twitter-Leading-travel-platform-simplifies-network-management-by-deploying-Traefik-as-preferred-reverse-proxy.png","twitter_title":null,"authors":[{"name":"Marie Ponseel","slug":"marie","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/12/profile-picture.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Marie Ponseel","slug":"marie","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/12/profile-picture.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Case Studies","slug":"case-studies","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic.","meta_title":"Case studies | Containous","visibility":"public"}],"plaintext":"Overview\nCovering all aspects of traveling, hotels, flights, car rental, and vacation\nhomes, this world leading travel company’s platform is managed by an\ninfrastructure team that counts over one thousand engineers. This infrastructure\nengineering team supports an expansive brand portfolio, ensuring transactions\nare always up and running smoothly, a monumental task given the sheer scale of\ntheir business. Given the diversity of applications across their brands, the\ngroup delicately supports a wide range of networking solutions and programming\nlanguages throughout the organization.\n\nChallenge \nLike many other large companies, this leading travel company’s broad range of\napplications had requirements for specific tools and platforms, such as various\ncontainerization solutions. As a result, the team managed a multitude of\ncontainer platforms, each having a unique networking configuration and runtime\nto operate. This made management of these environments very difficult and time\nconsuming because each network change needed to be applied one-by-one for each\nand every environment (i.e. Amazon ECS and Kubernetes, Mesos and Marathon, etc). \n\n\nThe team set out to find a proxy solution flexible enough to work across\nmultiple platforms such as Consul, Mesos, and Kubernetes, while integrating\nnatively with each platform’s unique discovery mechanisms and information\nmodels. What they needed was a single reverse proxy solution to standardize and\nconsolidate the existing disparate solutions to reduce operational overhead, s\nimplify new deployments, and minimize human errors during configuration changes.\nGiven the company’s size, the “perfect” solution would need to meet specific\nrequirements around massive scalability, ease and speed of deployment, and\nfunction efficiently in highly-dynamic containerized environments.\n\n\nSolution\nThe leading travel company’s infrastructure team stumbled onto Traefik while\nevaluating and testing different solutions in the networking landscape of the\ncontainerized world. \n\n\nTraefik offers the ability for engineering teams to plug in multiple data\nsources, such as Mesos, Marathon, Consul, etc, all with the use of a single\ntool. Traefik’s wide array of pluggable providers connects to any compatible\ndata source, presenting a unified and consistent platform for traffic routing.\nThis feature appealed greatly to the engineering team and encouraged a closer\nlook.\n\n\nTraefik is a lean implementation, written in Go, and a single binary which makes\nit easy to deploy. Traefik offers extensive configuration options, suitable for\nany application scenario and scale. With advanced routing capabilities, Traefik\nwas one of the only solutions capable of easily configuring multiple advanced\nroutes per service and running custom configuration templates. Ultimately, the\nengineering team chose Traefik for its simplicity and ease of maintenance and\nconfiguration.\n\n\nBy standardizing on Traefik as their reverse proxy of choice across all\nenvironments, the engineering team saved countless hours by simplifying network\noperation management.\n\n\nThe company is also committed to the values of open source, supporting and\nencouraging open source throughout the organization. As an open source project,\nTraefik bolsters their commitment to consume and contribute to open source\nsoftware as part of the greater community. They found engagement with the\nTraefik developer community to be responsive, receptive and collaborative,\nsomething important to them as well.\n\n\nBottom Line\nThis leading travel company’s selection of Traefik as their preferred reverse\nproxy solution, enables them to achieve increased delivery speed at scale, even\nin the rapidly and ever-evolving container ecosystem.\n\n\nIn spite of their vigorous requirements tested throughout the evaluation\nprocess, Traefik easily passed with flying colors, proving its ability to handle\nthe most demanding workloads in high traffic environments. The team is\nexperiencing greater simplicity managing large scale containerized\ninfrastructure while enhancing ease of maintenance by delivering features\ncritical to this unique environment.\n\n\nThe engineering team happily recommends Traefik to other organizations facing\nthe same challenges.\n\n\n> “Traefik pretty much supports itself. There isn’t much support that we require\nfrom outside. Things just work. I absolutely recommend Traefik.”\n\nWhat’s Next?\n * Get started with Traefik [/traefik/] today\n * Ready for production deployments? Discover Traefik Enterprise Edition\n   [/traefikee/], and request your demo\n   [https://info.containo.us/request-demo-traefikee]","html":"<figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/03/Leading-Travel-Platform-Simplifies-Network-Management-by-Deploying-Traefik-as-Preferred-Reverse-Proxy.png\" class=\"kg-image\"></figure><h2 id=\"overview\">Overview</h2><p>Covering all aspects of traveling, hotels, flights, car rental, and vacation homes, this world leading travel company’s platform is managed by an infrastructure team that counts over one thousand engineers. This infrastructure engineering team supports an expansive brand portfolio, ensuring transactions are always up and running smoothly, a monumental task given the sheer scale of their business. Given the diversity of applications across their brands, the group delicately supports a wide range of networking solutions and programming languages throughout the organization.</p><h2 id=\"challenge\">Challenge </h2><p>Like many other large companies, this leading travel company’s broad range of applications had requirements for specific tools and platforms, such as various containerization solutions. As a result, the team managed a multitude of container platforms, each having a unique networking configuration and runtime to operate. This made management of these environments very difficult and time consuming because each network change needed to be applied one-by-one for each and every environment (i.e. Amazon ECS and Kubernetes, Mesos and Marathon, etc). <br></p><p>The team set out to find a proxy solution flexible enough to work across multiple platforms such as Consul, Mesos, and Kubernetes, while integrating natively with each platform’s unique discovery mechanisms and information models. What they needed was a single reverse proxy solution to standardize and consolidate the existing disparate solutions to reduce operational overhead<em>, s</em>implify new deployments, and minimize human errors during configuration changes. Given the company’s size, the “perfect” solution would need to meet specific requirements around massive scalability, ease and speed of deployment, and function efficiently in highly-dynamic containerized environments.<br></p><h2 id=\"solution\">Solution</h2><p>The leading travel company’s infrastructure team stumbled onto Traefik while evaluating and testing different solutions in the networking landscape of the containerized world. <br></p><p>Traefik offers the ability for engineering teams to plug in multiple data sources, such as Mesos, Marathon, Consul, etc, all with the use of a single tool. Traefik’s wide array of pluggable providers connects to any compatible data source, presenting a unified and consistent platform for traffic routing. This feature appealed greatly to the engineering team and encouraged a closer look.<br></p><p>Traefik is a lean implementation, written in Go, and a single binary which makes it easy to deploy. Traefik offers extensive configuration options, suitable for any application scenario and scale. With advanced routing capabilities, Traefik was one of the only solutions capable of easily configuring multiple advanced routes per service and running custom configuration templates. Ultimately, the engineering team chose Traefik for its simplicity and ease of maintenance and configuration.<br></p><p>By standardizing on Traefik as their reverse proxy of choice across all environments, the engineering team saved countless hours by simplifying network operation management.<br></p><p>The company is also committed to the values of open source, supporting and encouraging open source throughout the organization. As an open source project, Traefik bolsters their commitment to consume and contribute to open source software as part of the greater community. They found engagement with the Traefik developer community to be responsive, receptive and collaborative, something important to them as well.<br></p><h2 id=\"bottom-line\">Bottom Line</h2><p>This leading travel company’s selection of Traefik as their preferred reverse proxy solution, enables them to achieve increased delivery speed at scale, even in the rapidly and ever-evolving container ecosystem.<br></p><p>In spite of their vigorous requirements tested throughout the evaluation process, Traefik easily passed with flying colors, proving its ability to handle the most demanding workloads in high traffic environments. The team is experiencing greater simplicity managing large scale containerized infrastructure while enhancing ease of maintenance by delivering features critical to this unique environment.<br></p><p>The engineering team happily recommends Traefik to other organizations facing the same challenges.<br></p><blockquote><em>“Traefik pretty much supports itself. There isn’t much support that we require from outside. Things just work. I absolutely recommend Traefik.”</em></blockquote><h2 id=\"what-s-next\"><br>What’s Next?</h2><ul><li>Get started with <a href=\"https://containous.ghost.io/traefik/\" rel=\"noopener nofollow\">Traefik</a> today</li><li>Ready for production deployments? <a href=\"https://containous.ghost.io/traefikee/\">Discover Traefik Enterprise Edition</a>, and <a href=\"https://info.containo.us/request-demo-traefikee\" rel=\"noopener nofollow\">request your demo</a></li></ul>","url":"https://containous.ghost.io/blog/leading-travel-platform-simplifies-network-management-by-deploying-traefik-as-preferred-reverse-proxy/","canonical_url":null,"uuid":"45763dd7-bd70-4ddd-88cb-c7e371776dd1","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e70260319908e0038512ce1","reading_time":3}},{"node":{"id":"Ghost__Post__5dcdfe132345360038abe28c","title":"eBay Classifieds Group chooses Traefik to achieve load balancing at scale","slug":"ebay-classifieds-group-chooses-traefik-to-achieve-load-balancing-at-scale-f1332fcc9fbb","featured":false,"feature_image":"https://containous.ghost.io/content/images/2019/11/Blog-Post_eBay-Study@2x-1.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/7e53eb7a624b40c11d05d6df456fa2dd/f3583/Blog-Post_eBay-Study%402x-1.png","srcSet":"/static/7e53eb7a624b40c11d05d6df456fa2dd/630fb/Blog-Post_eBay-Study%402x-1.png 300w,\n/static/7e53eb7a624b40c11d05d6df456fa2dd/2a4de/Blog-Post_eBay-Study%402x-1.png 600w,\n/static/7e53eb7a624b40c11d05d6df456fa2dd/f3583/Blog-Post_eBay-Study%402x-1.png 1200w,\n/static/7e53eb7a624b40c11d05d6df456fa2dd/bbee5/Blog-Post_eBay-Study%402x-1.png 1800w,\n/static/7e53eb7a624b40c11d05d6df456fa2dd/0ef64/Blog-Post_eBay-Study%402x-1.png 2400w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"eBay Classifieds Group is a global collection of local brands that aim to create connected commerce, enabled by people, supported by technology and open for everyone. ","custom_excerpt":"eBay Classifieds Group is a global collection of local brands that aim to create connected commerce, enabled by people, supported by technology and open for everyone. ","visibility":"public","created_at_pretty":"15 November, 2019","published_at_pretty":"November 13, 2019","updated_at_pretty":"21 May, 2020","created_at":"2019-11-15T01:23:31.000+00:00","published_at":"2019-11-13T08:23:00.000+00:00","updated_at":"2020-05-21T22:18:49.000+00:00","meta_title":"eBay chooses Traefik to achieve load balancing at scale","meta_description":"eBay Classified Group needed a solution that could easily handle routing external and internal traffic flow with no bottlenecks or scalability issues.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Marie Ponseel","slug":"marie","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/12/profile-picture.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Marie Ponseel","slug":"marie","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/12/profile-picture.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Case Studies","slug":"case-studies","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic.","meta_title":"Case studies | Containous","visibility":"public"},{"name":"#traefik-related-resource","slug":"hash-traefik-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"About eBay Classifieds Group\neBay Classifieds Group is a global collection of local brands that aim to create\nconnected commerce, enabled by people, supported by technology and open for\neveryone. Our sites in 14 countries help people find whatever they’re looking\nfor in their local communities — whether it’s a job, an apartment, a sofa, a\ncar, a concert ticket, financial services or new friends. Every connection made\nor item found makes a difference by creating a world where people share more and\nwaste less. People who want to trade visit our sites because they’re fun, easy\nto use and built on trust.\n\nOverview\nWim Fournier, Site Reliability Engineer at eBay Classifieds Group (eCG), is part\nof a team who manages the infrastructure platform for the classifieds platforms.\neCG Benelux’s platform supports over 12 million unique monthly users, and 15\nmillion live listings, with unique requirements to handle peak traffic daily.\nThere is no “off-peak” day for eBay Classifieds Group’s Benelux platforms — 100%\nuptime is a must. On a weekly basis hundreds of improvements are released to\nconstantly make trading on the platform easier, effortless and most of all fun.\n\nWim’s team’s mission is to help development teams become self sufficient and\nmake their jobs easier. They create tools to simplify infrastructure\nprovisioning, deploy applications seamlessly, and manage configurations easily.\nUltimately, they are in charge of building and maintaining all internal\ninfrastructure platforms in order to offer end-users a good and consistent\nexperience.\n\nChallenge\nThe challenge is to provide excellent online service accessible by anyone from\nanywhere, with the best trading experience for each and every customer. Wim’s\nteam specifically is chartered to deliver a platform that is capable of handling\ntraffic peaks and scale according to demand, ensuring that the marketplace is\nalways available when anybody wants to buy or sell anything.\n\nThe platform is a containerized set of microservices, deployed to the cloud, to\ntake advantage of the scalability and availability offered by cloud resources.\nThis platform is quite large, hosting and managing hundreds of microservices.\n\nRouting and load balancing in a dynamic and complex environment was a real\nchallenge for Wim’s team. Their original approach consisted of Fabio as a\ntraditional load balancer, in conjunction with a hardware load balancer, and\nNomad as their orchestrator. This setup did not scale anymore to meet the\nrouting and configuration flexibility they needed, leading them to explore other\nedge routing solutions.\n\nWim’s team needed a solution that could easily handle routing external and\ninternal traffic flow with no bottlenecks or scalability issues, while enabling\nthem to easily configure multiple advanced routes per service.\n\n> “We needed an advanced load balancer and an API Gateway for advanced routing to\ncontrol traffic flow with flexible configuration and automation capabilities.\nThis complexity makes it difficult to find a good load balancer. A load balancer\nper domain was not enough for us.”\nSolution\nWim’s teams platform strategy is to make things as simple as possible and to\nhave as few components as possible.\n\nThe team researched and conducted an extensive evaluation across a wide range of\ncompetitive software-based products in the market. Traditional solutions for\nrouting and load balancing are very configuration based, and lacked the ability\nto handle the complexity of a dynamic and advanced configuration system.\nMeanwhile, many of the new, modern alternative products are either great at load\nbalancing (TLS management, Websocket, HTTP2…), or as an API gateway (Advanced\nHTTP routing, canary, observability…), but rarely do both effectively.\n\neCG found Traefik was very well suited to natively support its requirements.\nTraefik offers an all-in-one product that is easy to use, configure and scales\nperfectly for the volume of traffic eCG Benelux sees on a daily basis. Traefik\nalso integrates with core technologies eCG is using across the company, such as\nDocker for containers, Nomad for orchestration, and Consul for service\nconfiguration management.\n\n> “We were looking for both a load balancer and an API Gateway that is easy to\nconfigure, scale, and secure.”\neCG uses Traefik for load balancing and as an API Gateway to route external and\ninternal traffic. Traefik is today deployed across various platforms.\n\nWim’s team has hundreds of services running behind the API Gateway. Since\ndeploying Traefik nearly a year ago, they have achieved zero downtime while\nhandling traffic peak of 22k requests per second. In terms of configuration,\nTraefik’s ability to react to their dynamic environment by automatically\nconfiguring itself accelerates and simplifies deployments without having\nmanually touch or configure anything.\n\neCG favors open source software for its infrastructure because it gives them the\nability to change the product if needed. The fact that they are not locked-in\nwith any vendor and can contribute to open source software is very important for\nWim’s team. Traefik open source software gives eCG full access to the source\ncode and the opportunity to implement changes if needed.\n\n> “Traefik gives us flexibility and avoid any vendor lock-in.”\nBottom Line\nWim’s team has been able to improve development velocity and operational\nefficiency with Traefik by saving their team hours of work on configuration\ntasks, while achieving 24x7 availability across the entire Benelux.\n\nWhat’s Next?\n * Get started with Traefik [/traefik/] today\n * Ready for production deployments? Discover TraefikEE [/traefikee/], and \n   request your demo [https://info.containo.us/request-demo-traefikee]","html":"<figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2019/11/image-104.png\" class=\"kg-image\"></figure><h2 id=\"about-ebay-classifieds-group\">About eBay Classifieds Group</h2><p>eBay Classifieds Group is a global collection of local brands that aim to create connected commerce, enabled by people, supported by technology and open for everyone. Our sites in 14 countries help people find whatever they’re looking for in their local communities — whether it’s a job, an apartment, a sofa, a car, a concert ticket, financial services or new friends. Every connection made or item found makes a difference by creating a world where people share more and waste less. People who want to trade visit our sites because they’re fun, easy to use and built on trust.</p><h2 id=\"overview\">Overview</h2><p>Wim Fournier, Site Reliability Engineer at eBay Classifieds Group (eCG), is part of a team who manages the infrastructure platform for the classifieds platforms. eCG Benelux’s platform supports over 12 million unique monthly users, and 15 million live listings, with unique requirements to handle peak traffic daily. There is no “off-peak” day for eBay Classifieds Group’s Benelux platforms — 100% uptime is a must. On a weekly basis hundreds of improvements are released to constantly make trading on the platform easier, effortless and most of all fun.</p><p>Wim’s team’s mission is to help development teams become self sufficient and make their jobs easier. They create tools to simplify infrastructure provisioning, deploy applications seamlessly, and manage configurations easily. Ultimately, they are in charge of building and maintaining all internal infrastructure platforms in order to offer end-users a good and consistent experience.</p><h2 id=\"challenge\">Challenge</h2><p>The challenge is to provide excellent online service accessible by anyone from anywhere, with the best trading experience for each and every customer. Wim’s team specifically is chartered to deliver a platform that is capable of handling traffic peaks and scale according to demand, ensuring that the marketplace is always available when anybody wants to buy or sell anything.</p><p>The platform is a containerized set of microservices, deployed to the cloud, to take advantage of the scalability and availability offered by cloud resources. This platform is quite large, hosting and managing hundreds of microservices.</p><p>Routing and load balancing in a dynamic and complex environment was a real challenge for Wim’s team. Their original approach consisted of Fabio as a traditional load balancer, in conjunction with a hardware load balancer, and Nomad as their orchestrator. This setup did not scale anymore to meet the routing and configuration flexibility they needed, leading them to explore other edge routing solutions.</p><p>Wim’s team needed a solution that could easily handle routing external and internal traffic flow with no bottlenecks or scalability issues, while enabling them to easily configure multiple advanced routes per service.</p><blockquote><em><em>“We needed an advanced load balancer and an API Gateway for advanced routing to control traffic flow with flexible configuration and automation capabilities. This complexity makes it difficult to find a good load balancer. A load balancer per domain was not enough for us.”</em></em></blockquote><h2 id=\"solution\">Solution</h2><p>Wim’s teams platform strategy is to make things as simple as possible and to have as few components as possible.</p><p>The team researched and conducted an extensive evaluation across a wide range of competitive software-based products in the market. Traditional solutions for routing and load balancing are very configuration based, and lacked the ability to handle the complexity of a dynamic and advanced configuration system. Meanwhile, many of the new, modern alternative products are either great at load balancing (TLS management, Websocket, HTTP2…), or as an API gateway (Advanced HTTP routing, canary, observability…), but rarely do both effectively.</p><p>eCG found Traefik was very well suited to natively support its requirements. Traefik offers an all-in-one product that is easy to use, configure and scales perfectly for the volume of traffic eCG Benelux sees on a daily basis. Traefik also integrates with core technologies eCG is using across the company, such as Docker for containers, Nomad for orchestration, and Consul for service configuration management.</p><blockquote><em><em>“We were looking for both a load balancer and an API Gateway that is easy to configure, scale, and secure.”</em></em></blockquote><p>eCG uses Traefik for load balancing and as an API Gateway to route external and internal traffic. Traefik is today deployed across various platforms.</p><p>Wim’s team has hundreds of services running behind the API Gateway. Since deploying Traefik nearly a year ago, they have achieved zero downtime while handling traffic peak of 22k requests per second. In terms of configuration, Traefik’s ability to react to their dynamic environment by automatically configuring itself accelerates and simplifies deployments without having manually touch or configure anything.</p><p>eCG favors open source software for its infrastructure because it gives them the ability to change the product if needed. The fact that they are not locked-in with any vendor and can contribute to open source software is very important for Wim’s team. Traefik open source software gives eCG full access to the source code and the opportunity to implement changes if needed.</p><blockquote><em><em>“Traefik gives us flexibility and avoid any vendor lock-in.”</em></em></blockquote><h2 id=\"bottom-line\">Bottom Line</h2><p>Wim’s team has been able to improve development velocity and operational efficiency with Traefik by saving their team hours of work on configuration tasks, while achieving 24x7 availability across the entire Benelux.</p><h2 id=\"what-s-next\">What’s Next?</h2><ul><li>Get started with <a href=\"https://containous.ghost.io/traefik/\" rel=\"noopener nofollow\">Traefik</a> today</li><li>Ready for production deployments? <a href=\"https://containous.ghost.io/traefikee/\" rel=\"noopener nofollow\">Discover TraefikEE</a>, and <a href=\"https://info.containo.us/request-demo-traefikee\" rel=\"noopener nofollow\">request your demo</a></li></ul>","url":"https://containous.ghost.io/blog/ebay-classifieds-group-chooses-traefik-to-achieve-load-balancing-at-scale-f1332fcc9fbb/","canonical_url":null,"uuid":"58103d5b-40a5-4e1e-a204-07281e83ea90","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5dcdfe132345360038abe28c","reading_time":4}},{"node":{"id":"Ghost__Post__5dd6a3a8b6de2b00381d3fbf","title":"Canary Releases with Traefik on GKE at HolidayCheck","slug":"canary-releases-with-traefik-on-gke-at-holidaycheck-d3c0928f1e02","featured":false,"feature_image":"https://containous.ghost.io/content/images/2019/12/canary.jpeg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/4c2bbcade8901a28828ba71afaa01bc5/619a6/canary.jpg","srcSet":"/static/4c2bbcade8901a28828ba71afaa01bc5/9dc27/canary.jpg 300w,\n/static/4c2bbcade8901a28828ba71afaa01bc5/4fe8c/canary.jpg 600w,\n/static/4c2bbcade8901a28828ba71afaa01bc5/619a6/canary.jpg 1068w","sizes":"(max-width: 1068px) 100vw, 1068px"}}},"excerpt":"In this post, I would like to introduce you into how Traefik helped us shape our cloud ecosystem at HolidayCheck...","custom_excerpt":"In this post, I would like to introduce you into how Traefik helped us shape our cloud ecosystem at HolidayCheck...","visibility":"public","created_at_pretty":"21 November, 2019","published_at_pretty":"May 21, 2019","updated_at_pretty":"22 May, 2020","created_at":"2019-11-21T14:48:08.000+00:00","published_at":"2019-05-21T14:47:00.000+00:00","updated_at":"2020-05-22T00:09:11.000+00:00","meta_title":"Canary Releases with Traefik on GKE at HolidayCheck","meta_description":"In this post, I would like to introduce you into how Traefik helped us shape our cloud ecosystem at HolidayCheck...","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Traefik Labs","slug":"traefiklabs","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/09/TraefikLabs-symbol-transparent-bg@3x.png","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Traefik Labs","slug":"traefiklabs","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/09/TraefikLabs-symbol-transparent-bg@3x.png","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"Case Studies","slug":"case-studies","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":"Learn from our users and customers why they choose Traefik and TraefikEE as a modern load balancer to manage network traffic.","meta_title":"Case studies | Containous","visibility":"public"}],"plaintext":"In this post, I would like to introduce you into how Traefik [/traefik/] helped\nus shape our cloud ecosystem at HolidayCheck\n[https://www.holidaycheckgroup.com/?lang=en]. In particular, I will give a brief\nin-depth introduction on how we implemented our canary release process for our\nmicroservice architecture with Traefik on Google Kubernetes Engine (GKE).\n\nAbout HolidayCheck\nHolidayCheck AG operates the biggest independent hotel review and booking portal\nin the German-speaking area. Our vision is to become the most Urlauber*-friendly\ncompany in the world! Our business portfolio has full package (flight, hotel,\ninsurance), hotel-only, and cruise offerings. In addition to that, we are a\nplatform which shares hotel reviews and pictures.\n\n * Urlauber: German term for holidaymaker, vacationer\n\nBackground\nOur teams strive to keep a high level of urgency for delivery. Therefore they\nmaintain their delivery pipelines themselves. An inquiry across our continuous\ndelivery (CD) pipelines showed that our teams use one of the following designs:\n\n * Production follows Staging: This is the most classic design among all. It\n   prevails in services with older staged workflows where changes are tested in\n   an isolated staging environment without real user traffic.\n * Production with Feature Flags: This workflow is in place for a constant high\n   pace of changes, especially with UX impact.\n * Production with A/B Tests: Another variation of the last design is to keep\n   multiple versions of the system online (e.g., A and B version) and split user\n   traffic manually by an operator.\n\nAlthough all three designs have a positive impact on our release quality\nalready, they are still very tedious to operate or widen the human error vector.\nTo minimize toil and human errors, we introduced another complementary release\nstrategy — canary releases.\n\nCanary Releases: Our Design\nIn short canary releases is an automation extension for our CD pipelines to\ncompare a new release (the canary group) against the previous version. Ideally,\nthe old deployment (the main group) is not touched by this operation. Instead, a\nnew deployment with the old configuration, the control group, is created at the\nsame time as the canary.\n\nOur design is based upon a strict set of decisions:\n\n 1. User traffic needs to be split across the main deployment and the other two\n    groups, whereas canary and control need an equal traffic share to keep\n    comparisons sane.\n 2. The CD pipeline needs a data source (e.g., metrics, logs, etc.) to evaluate\n    the canary soundness in comparison to the control instance. The decisions\n    can vary from shifting more traffic to the canary/control group, take canary\n    down or replace the current main with the canary.\n 3. The three instance groups need to operate independently from each other in\n    isolation.\n\nEnter Traefik Splitting\nOne of the significant benefits to using Traefik is that we can rely on building\non low-entry barrier features. Although our platform is hosted on GKE, we still\nneed to tailor features according to our use cases. Canary releases being one of\nthem requires us to split traffic across deployments.\n\nTraefik being our single proxy to route traffic to our deployments, has a\nbuilt-in feature to split traffic across deployment groups through a single\nIngress. Therefore a canary deployment can be accomplished with the following\nIngress specification:\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    traefik.ingress.kubernetes.io/service-weights: |\n      my-service: 60%\n      my-service-canary: 20%\n      my-service-control: 20%\n  name: my-service\nspec:\n  rules:\n  - http:\n      paths:\n      - backend:\n          serviceName: my-service\n          servicePort: 80\n        path: /\n      - backend:\n          serviceName: my-service-canary\n          servicePort: 80\n        path: /\n      - backend:\n          serviceName: my-service-control\n          servicePort: 80\n        path: /\n\nOur Canary Workflow\nDespite that traffic splitting is a cornerstone to enable canary releases, it is\nnot sufficient. We still need to handle our canary deployments on GKE\nautomatically. Our CDs should be able to automatically make one of the following\ndecisions by comparing the canary with the control group:\n\n 1. Split more traffic from the main group to the canary and control groups.\n 2. Demote the canary and control groups because of an unacceptable error rate\n    and shift full traffic back to the main group.\n 3. Promote the canary group to become the new main group and remove the control\n    and old main groups.\n\nFurthermore, before traffic splitting we need to provide resources for our\ncanary and control deployments. On the one hand, this ensures that an\nappropriate replica count exists to handle the traffic. On the other hand,\ntraffic splitting can only happen from a third-party inside Kubernetes that can\nobserve the replica count of the canary and control deployments.\n\nIn short, the above CD decisions are accomplished by sending updates for the\ncanary and control deployments to the Kubernetes API server. A separate canary\ncontroller handles the rest.\n\nThe Canary Controller\nAfter sending the updates to Kubernetes the deployments of the canary and\ncontrol groups, as well as the Ingress object, will be reconciled by a canary\ncontroller. The controller is responsible for the following actions:\n\n * Scale the canary and control deployments:\n   The number of replicas for the canary and control deployments is based on the\n   traffic share\n\ncanaryReplicas = controlGroupReplicas =\n  ceil(appReplicas * canaryTrafficPercent / 100)\n\n * Enable the canary and control deployments: This means to identify the Ingress\n   object of the main deployment and add the service weights annotation for each\n   deployment.\n * Disable the canary and control deployments: In case of promotion/demotion of\n   the canary release, the controller removes the service weights from the\n   Ingress object.\n\nA Canary Release from Kubernetes Perspective\nIf you are using Kubernetes, a simple deployment can contain multiple\nannotations to express use case specific information. Thus, our CD pipelines\ncommunicate each action by updating the annotations of the required deployment\nspecifications. These annotations declare the requested state of our canary\nrelease, which in turn is reconciled by the canary controller.\n\nOur canary release implementation requires the following annotations to express\nthe state, as well as the Traefik service weight per deployment:\n\n * holidaycheck.com/canary-active: bool: Represents the current state of the\n   canary release in each canary and control deployment.\n * holidaycheck.com/canary-percent: float: Represents the service weight which\n   should be applied for each the canary and control deployment.\n\nLet’s say we have a service my-service at version v1.6:\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: my-service\n  namespace: my-namespace\nspec:\n  replicas: 10\n  template:\n      name: my-service\n    spec:\n      automountServiceAccountToken: false\n      containers:\n      - image: our-registry/my-service:v1.6\n        imagePullPolicy: IfNotPresent\n\nWe want to evaluate a newer version v1.7 of this service with a canary release,\ne.g.:\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  annotations:\n    holidaycheck.com/canary-active: \"false\"\n    holidaycheck.com/canary-percent: \"20.0\"\n  name: my-service-canary\n  namespace: my-namespace\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: my-service-canary\n    spec:\n      containers:\n      - image: our-registry/my-service:v1.7\n\nAccordingly, a control deployment will be an almost identical copy of the main\ndeployment specification. The only addition here is the extra annotations, e.g.:\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  annotations:\n    holidaycheck.com/canary-active: \"false\"\n    holidaycheck.com/canary-percent: \"20.0\"\n  name: my-service-control\n  namespace: my-namespace\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: my-service-control\n    spec:\n      containers:\n      - image: our-registry/my-service:v1.6\n\nNext, the canary controller will reconcile the state of our three deployments to\nadhere to our replica count specification. Therefore splitting 20% of our\ntraffic from a deployment with ten replicas results in canary and control\ndeployments with two replicas each.\n\nFinally, the controller will translate the canary annotation canary-percent for\neach deployment to the appropriate Traefik service weights annotation in the\nIngress object. Also the canary-active will be set to true for the canary and\ncontrol deployments:\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    traefik.ingress.kubernetes.io/service-weights: |\n      my-service: 60%\n      my-service-control: 20%\n      my-service-canary: 20%\n  name: my-service\n\nNote: To minimize toil creating the above specifications, our teams use a small\nCLI tool that generates and applies those for them to Kubernetes.\n\nChallenges\nOne challenge remains, namely how to separate Traefik backend metrics per\nendpoint. The current Traefik v1.7implementation does not provide a distinction\nof metrics per backend endpoint. However, you can circumvent this issue by\nrelying on application level metrics, which can be separated by custom labels\nfor the canary, control, and main group accordingly.\n\nConclusion\nI hope this article has been helpful and will help you to tailor your canary\nrelease workflow for your platform based on Traefik’s excellent features.\n\nIn summary, we met our main goal to build a slim solution for canary releases\nwith Traefik without introducing the complexity of a full service mesh.\n\nThe above implementation is based on:\n\n * Traefik v1.7\n * Kubernetes v1.12","html":"<p>In this post, I would like to introduce you into how <a href=\"https://containous.ghost.io/traefik/\">Traefik</a> helped us shape our cloud ecosystem at <a href=\"https://www.holidaycheckgroup.com/?lang=en\" rel=\"noopener\">HolidayCheck</a>. In particular, I will give a brief in-depth introduction on how we implemented our canary release process for our microservice architecture with Traefik on Google Kubernetes Engine (GKE).</p><h2 id=\"about-holidaycheck\">About HolidayCheck</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2019/11/image-22.png\" class=\"kg-image\"></figure><p>HolidayCheck AG operates the biggest independent hotel review and booking portal in the German-speaking area. Our vision is to become the most Urlauber*-friendly company in the world! Our business portfolio has full package (flight, hotel, insurance), hotel-only, and cruise offerings. In addition to that, we are a platform which shares hotel reviews and pictures.</p><ul><li><em><em>Urlauber: German term for holidaymaker, vacationer</em></em></li></ul><h2 id=\"background\">Background</h2><p>Our teams strive to keep a high level of urgency for delivery. Therefore they maintain their delivery pipelines themselves. An inquiry across our continuous delivery (CD) pipelines showed that our teams use one of the following designs:</p><ul><li><em><em>Production follows Staging</em></em>: This is the most classic design among all. It prevails in services with older staged workflows where changes are tested in an isolated staging environment without real user traffic.</li><li><em><em>Production with Feature Flags</em></em>: This workflow is in place for a constant high pace of changes, especially with UX impact.</li><li><em><em>Production with A/B Tests</em></em>: Another variation of the last design is to keep multiple versions of the system online (e.g., A and B version) and split user traffic manually by an operator.</li></ul><p>Although all three designs have a positive impact on our release quality already, they are still very tedious to operate or widen the human error vector. To minimize toil and human errors, we introduced another complementary release strategy — canary releases.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2019/11/image-23.png\" class=\"kg-image\"></figure><h2 id=\"canary-releases-our-design\">Canary Releases: Our Design</h2><p>In short canary releases is an automation extension for our CD pipelines to compare a new release (<em><em>the canary group</em></em>) against the previous version. Ideally, the old deployment (<em><em>the main group</em></em>) is not touched by this operation. Instead, a new deployment with the old configuration, <em><em>the control group</em></em>, is created at the same time as the canary.</p><p>Our design is based upon a strict set of decisions:</p><ol><li>User traffic needs to be split across the main deployment and the other two groups, whereas canary and control need an equal traffic share to keep comparisons sane.</li><li>The CD pipeline needs a data source (e.g., metrics, logs, etc.) to evaluate the canary soundness in comparison to the control instance. The decisions can vary from shifting more traffic to the canary/control group, take canary down or replace the current main with the canary.</li><li>The three instance groups need to operate independently from each other in isolation.</li></ol><h2 id=\"enter-traefik-splitting\">Enter Traefik Splitting</h2><p>One of the significant benefits to using Traefik is that we can rely on building on low-entry barrier features. Although our platform is hosted on GKE, we still need to tailor features according to our use cases. Canary releases being one of them requires us to split traffic across deployments.</p><p>Traefik being our single proxy to route traffic to our deployments, has a built-in feature to split traffic across deployment groups through a single Ingress. Therefore a canary deployment can be accomplished with the following Ingress specification:</p><pre><code class=\"language-yaml\">apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    traefik.ingress.kubernetes.io/service-weights: |\n      my-service: 60%\n      my-service-canary: 20%\n      my-service-control: 20%\n  name: my-service\nspec:\n  rules:\n  - http:\n      paths:\n      - backend:\n          serviceName: my-service\n          servicePort: 80\n        path: /\n      - backend:\n          serviceName: my-service-canary\n          servicePort: 80\n        path: /\n      - backend:\n          serviceName: my-service-control\n          servicePort: 80\n        path: /</code></pre><h2 id=\"our-canary-workflow\">Our Canary Workflow</h2><p>Despite that traffic splitting is a cornerstone to enable canary releases, it is not sufficient. We still need to handle our canary deployments on GKE automatically. Our CDs should be able to automatically make one of the following decisions by comparing the canary with the control group:</p><ol><li>Split more traffic from the main group to the canary and control groups.</li><li>Demote the canary and control groups because of an unacceptable error rate and shift full traffic back to the main group.</li><li>Promote the canary group to become the new main group and remove the control and old main groups.</li></ol><p>Furthermore, before traffic splitting we need to provide resources for our canary and control deployments. On the one hand, this ensures that an appropriate replica count exists to handle the traffic. On the other hand, traffic splitting can only happen from a third-party inside Kubernetes that can observe the replica count of the canary and control deployments.</p><p>In short, the above CD decisions are accomplished by sending updates for the canary and control deployments to the Kubernetes API server. A separate canary controller handles the rest.</p><h2 id=\"the-canary-controller\">The Canary Controller</h2><p>After sending the updates to Kubernetes the deployments of the canary and control groups, as well as the Ingress object, will be reconciled by a canary controller. The controller is responsible for the following actions:</p><ul><li><em><em>Scale the canary and control deployments</em></em>:<br>The number of replicas for the canary and control deployments is based on the traffic share</li></ul><pre><code>canaryReplicas = controlGroupReplicas =\n  ceil(appReplicas * canaryTrafficPercent / 100)</code></pre><ul><li><em><em>Enable the canary and control deployments:</em></em> This means to identify the Ingress object of the main deployment and add the service weights annotation for each deployment.</li><li><em><em>Disable the canary and control deployments:</em></em> In case of promotion/demotion of the canary release, the controller removes the service weights from the Ingress object.</li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2019/11/image-24.png\" class=\"kg-image\"></figure><h2 id=\"a-canary-release-from-kubernetes-perspective\">A Canary Release from Kubernetes Perspective</h2><p>If you are using Kubernetes, a simple deployment can contain multiple annotations to express use case specific information. Thus, our CD pipelines communicate each action by updating the annotations of the required deployment specifications. These annotations declare the requested state of our canary release, which in turn is reconciled by the canary controller.</p><p>Our canary release implementation requires the following annotations to express the state, as well as the Traefik service weight per deployment:</p><ul><li><code>holidaycheck.com/canary-active: bool</code>: Represents the current state of the canary release in each canary and control deployment.</li><li><code>holidaycheck.com/canary-percent: float</code>: Represents the service weight which should be applied for each the canary and control deployment.</li></ul><p>Let’s say we have a service <code>my-service</code> at version <code>v1.6</code>:</p><pre><code class=\"language-yaml\">apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: my-service\n  namespace: my-namespace\nspec:\n  replicas: 10\n  template:\n      name: my-service\n    spec:\n      automountServiceAccountToken: false\n      containers:\n      - image: our-registry/my-service:v1.6\n        imagePullPolicy: IfNotPresent</code></pre><p>We want to evaluate a newer version <code>v1.7</code> of this service with a canary release, e.g.:</p><pre><code class=\"language-yaml\">apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  annotations:\n    holidaycheck.com/canary-active: \"false\"\n    holidaycheck.com/canary-percent: \"20.0\"\n  name: my-service-canary\n  namespace: my-namespace\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: my-service-canary\n    spec:\n      containers:\n      - image: our-registry/my-service:v1.7</code></pre><p>Accordingly, a control deployment will be an almost identical copy of the main deployment specification. The only addition here is the extra annotations, e.g.:</p><pre><code class=\"language-yaml\">apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  annotations:\n    holidaycheck.com/canary-active: \"false\"\n    holidaycheck.com/canary-percent: \"20.0\"\n  name: my-service-control\n  namespace: my-namespace\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: my-service-control\n    spec:\n      containers:\n      - image: our-registry/my-service:v1.6</code></pre><p>Next, the canary controller will reconcile the state of our three deployments to adhere to our replica count specification. Therefore splitting 20% of our traffic from a deployment with ten replicas results in canary and control deployments with two replicas each.</p><p>Finally, the controller will translate the canary annotation <code>canary-percent</code> for each deployment to the appropriate Traefik service weights annotation in the Ingress object. Also the <code>canary-active</code> will be set to <code>true</code> for the canary and control deployments:</p><pre><code class=\"language-yaml\">apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    traefik.ingress.kubernetes.io/service-weights: |\n      my-service: 60%\n      my-service-control: 20%\n      my-service-canary: 20%\n  name: my-service</code></pre><p><em><em>Note: To minimize toil creating the above specifications, our teams use a small CLI tool that generates and applies those for them to Kubernetes.</em></em></p><h2 id=\"challenges\">Challenges</h2><p>One challenge remains, namely how to separate Traefik backend metrics per endpoint. The current Traefik <code>v1.7</code>implementation does not provide a distinction of metrics per backend endpoint. However, you can circumvent this issue by relying on application level metrics, which can be separated by custom labels for the canary, control, and main group accordingly.</p><h2 id=\"conclusion\">Conclusion</h2><p>I hope this article has been helpful and will help you to tailor your canary release workflow for your platform based on Traefik’s excellent features.</p><p>In summary, we met our main goal to build a slim solution for canary releases with Traefik without introducing the complexity of a full service mesh.</p><p>The above implementation is based on:</p><ul><li>Traefik v1.7</li><li>Kubernetes v1.12</li></ul>","url":"https://containous.ghost.io/blog/canary-releases-with-traefik-on-gke-at-holidaycheck-d3c0928f1e02/","canonical_url":null,"uuid":"f2a7086b-dc30-4f82-8a20-d90968a1285f","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5dd6a3a8b6de2b00381d3fbf","reading_time":6}}]}},"pageContext":{"slug":"case-studies","limit":9,"skip":0,"numberOfPages":1,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":null,"previousPagePath":null,"nextPagePath":null}},"staticQueryHashes":["1274566015","2561578252","2731221146","394248586","4145280475","749840385"]}