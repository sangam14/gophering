{"componentChunkName":"component---src-templates-tag-tsx","path":"/tag/how-to/","result":{"data":{"ghostTag":{"slug":"how-to","name":"How To","visibility":"public","feature_image":null,"featureImageSharp":null,"description":null,"meta_title":null,"meta_description":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5fd818d9255eda00390e23b8","title":"Unleash the Power of Traefik for High Availability Load Balancing","slug":"unleash-the-power-of-traefik-for-high-availability-load-balancing","featured":true,"feature_image":"https://containous.ghost.io/content/images/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/fd6eab4e395f0b7b79b73f0551450d37/47498/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg","srcSet":"/static/fd6eab4e395f0b7b79b73f0551450d37/9dc27/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg 300w,\n/static/fd6eab4e395f0b7b79b73f0551450d37/4fe8c/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg 600w,\n/static/fd6eab4e395f0b7b79b73f0551450d37/47498/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg 1200w,\n/static/fd6eab4e395f0b7b79b73f0551450d37/52258/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg 1800w,\n/static/fd6eab4e395f0b7b79b73f0551450d37/a41d1/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"What if it was possible to achieve true high availability using only Traefik Proxy, Traefik Enterprise, and a few other, easy-to-deploy open-source networking tools?","custom_excerpt":"What if it was possible to achieve true high availability using only Traefik Proxy, Traefik Enterprise, and a few other, easy-to-deploy open-source networking tools?","visibility":"public","created_at_pretty":"15 December, 2020","published_at_pretty":"December 15, 2020","updated_at_pretty":"15 December, 2020","created_at":"2020-12-15T02:00:57.000+00:00","published_at":"2020-12-15T06:42:35.000+00:00","updated_at":"2020-12-15T06:42:35.000+00:00","meta_title":"Unleash the Power of Traefik for High Availability Load Balancing","meta_description":"What if it was possible to achieve true high availability using only Traefik and a few other, easy-to-deploy open-source networking tools?","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing---Twitter.png","twitter_title":null,"authors":[{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Every Traefik user knows that it makes the job of application networking easier.\nAt Traefik Labs, we like to say Traefik “makes networking boring.” And yet,\nbecause Traefik is so easy to use, it’s also easy to overlook how powerful it\nis.\n\nTraefik has earned a strong following among organizations that develop\ncloud-native applications, due to how effortlessly it integrates with\ntechnologies like Docker and Kubernetes. But the same capabilities that allow it\nto network containers can also help solve bigger networking challenges.\n\nOne use case for which there is growing demand is high availability (HA). With\nthe proliferation of the managed SaaS application delivery model, ensuring\nmaximum uptime and consistent quality of service is more important than ever.\nAchieving this for a global market remains a challenge.\n\nHome-Grown HA\nFor organizations that want to achieve true cloud-scale high availability, the\nsolution is often to turn to proprietary cloud-based solutions or to deploy\ndedicated hardware load balancers. Yet these approaches don't mesh well with\nmodern, cloud-native application development methods. Not only does it increase\ncosts and time-to-delivery, but it takes network configuration out of the hands\nof developers, making it harder to employ practices like agile development,\nDevOps, and site reliability engineering (SRE).\n\nBut what if there was a different approach? What if it was possible to achieve\ntrue high availability using only Traefik Proxy, Traefik Enterprise, and a few\nother, easy-to-deploy open-source networking tools? We recently published a new \nExpert Guide [https://info.traefik.io/request-technical-paper-traefik-ha] that\nexplains how to do just that.\n\nIn the paper, you’ll explore three scenarios designed to increase total traffic\ncapacity and uptime without resorting to complex or proprietary systems:\n\nCase 1: Active/Passive Nodes\nIn this first case, you’ll learn how to set up a two-node cluster of Traefik\ninstances, where one of them is active at any given time. Should the active\ninstance fail, the other instance automatically takes over.\n\nCase 2: Kubernetes Ingress\nBuilding on the first case, you’ll see how to use Traefik Enterprise as a\nmulti-node Kubernetes Ingress controller, complete with SSL termination and a\nrate-limiting feature to prevent network congestion from excessive requests.\n\nCase 3: Cloud-Scale Load Balancing\nFinally, you’ll use Traefik Enterprise and additional open source tools to build\na truly enterprise-grade network environment that’s capable of scaling to handle\nmassive amounts of requests.\n\nSounds interesting, how can I learn more?\nIf any of this sounds like an itch you’ve been eager to scratch within your own\norganization, download the paper\n[https://info.traefik.io/request-technical-paper-traefik-ha] and dive right in.\nYou’ll receive a link to the Expert Guide, which includes instructions on how to\ndownload the accompanying configuration files for the walk-through.Also, if you\nwant to begin building hands-on experience with Traefik Enterprise, there are\ntwo great ways to explore the high availability features it has to offer. The\nfirst is to contact Traefik Labs and request a guided demo\n[https://info.traefik.io/en/request-demo-traefik-enterprise] that will help you\nunderstand how Traefik Enterprise can benefit your organization. Or, if you’re\nready to roll up your sleeves, sign up for a 30-day free trial\n[https://info.traefik.io/get-traefik-enterprise-free-for-30-days] and see for\nyourself how easy it is to get started.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing.jpg\" class=\"kg-image\" alt=\"Unleash the Power of Traefik for High Availability Load Balancing\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing.jpg 1600w, https://containous.ghost.io/content/images/2020/12/Unleash-the-Power-of-Traefik-for-High-Availability-Load-Balancing.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Every Traefik user knows that it makes the job of application networking easier. At Traefik Labs, we like to say Traefik “makes networking boring.” And yet, because Traefik is so easy to use, it’s also easy to overlook how powerful it is.</p><p>Traefik has earned a strong following among organizations that develop cloud-native applications, due to how effortlessly it integrates with technologies like Docker and Kubernetes. But the same capabilities that allow it to network containers can also help solve bigger networking challenges.</p><p>One use case for which there is growing demand is high availability (HA). With the proliferation of the managed SaaS application delivery model, ensuring maximum uptime and consistent quality of service is more important than ever. Achieving this for a global market remains a challenge.</p><h2 id=\"home-grown-ha\"><strong>Home-Grown HA</strong></h2><p>For organizations that want to achieve true cloud-scale high availability, the solution is often to turn to proprietary cloud-based solutions or to deploy dedicated hardware load balancers. Yet these approaches don't mesh well with modern, cloud-native application development methods. Not only does it increase costs and time-to-delivery, but it takes network configuration out of the hands of developers, making it harder to employ practices like agile development, DevOps, and site reliability engineering (SRE).</p><p>But what if there was a different approach? What if it was possible to achieve true high availability using only Traefik Proxy, Traefik Enterprise, and a few other, easy-to-deploy open-source networking tools? We recently published a new <a href=\"https://info.traefik.io/request-technical-paper-traefik-ha\">Expert Guide</a> that explains how to do just that.</p><p>In the paper, you’ll explore three scenarios designed to increase total traffic capacity and uptime without resorting to complex or proprietary systems:</p><h2 id=\"case-1-active-passive-nodes\"><strong>Case 1: Active/Passive Nodes</strong></h2><p>In this first case, you’ll learn how to set up a two-node cluster of Traefik instances, where one of them is active at any given time. Should the active instance fail, the other instance automatically takes over.</p><h2 id=\"case-2-kubernetes-ingress\"><strong>Case 2: Kubernetes Ingress</strong></h2><p>Building on the first case, you’ll see how to use Traefik Enterprise as a multi-node Kubernetes Ingress controller, complete with SSL termination and a rate-limiting feature to prevent network congestion from excessive requests.</p><h2 id=\"case-3-cloud-scale-load-balancing\"><strong>Case 3: Cloud-Scale Load Balancing</strong></h2><p>Finally, you’ll use Traefik Enterprise and additional open source tools to build a truly enterprise-grade network environment that’s capable of scaling to handle massive amounts of requests.</p><h2 id=\"sounds-interesting-how-can-i-learn-more\">Sounds interesting, how can I learn more?</h2><p>If any of this sounds like an itch you’ve been eager to scratch within your own organization, <a href=\"https://info.traefik.io/request-technical-paper-traefik-ha\">download the paper</a> and dive right in. You’ll receive a link to the Expert Guide, which includes instructions on how to download the accompanying configuration files for the walk-through.Also, if you want to begin building hands-on experience with Traefik Enterprise, there are two great ways to explore the high availability features it has to offer. The first is to contact Traefik Labs and<a href=\"https://info.traefik.io/en/request-demo-traefik-enterprise\"> request a guided demo</a> that will help you understand how Traefik Enterprise can benefit your organization. Or, if you’re ready to roll up your sleeves, sign up for a<a href=\"https://info.traefik.io/get-traefik-enterprise-free-for-30-days\"> 30-day free trial</a> and see for yourself how easy it is to get started.</p>","url":"https://containous.ghost.io/blog/unleash-the-power-of-traefik-for-high-availability-load-balancing/","canonical_url":null,"uuid":"fabc68fa-2cb9-48c4-a81e-09eca13390ff","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5fd818d9255eda00390e23b8","reading_time":2}},{"node":{"id":"Ghost__Post__5fce60e016db8f0039b4334b","title":"From Zero to Hero: Getting Started with k0s and Traefik","slug":"from-zero-to-hero-getting-started-with-k0s-and-traefik","featured":true,"feature_image":"https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik-2.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/e5e000f515b518b83b527146af938a46/f3583/Getting-Started-with-k0s-and-Traefik-2.png","srcSet":"/static/e5e000f515b518b83b527146af938a46/630fb/Getting-Started-with-k0s-and-Traefik-2.png 300w,\n/static/e5e000f515b518b83b527146af938a46/2a4de/Getting-Started-with-k0s-and-Traefik-2.png 600w,\n/static/e5e000f515b518b83b527146af938a46/f3583/Getting-Started-with-k0s-and-Traefik-2.png 1200w,\n/static/e5e000f515b518b83b527146af938a46/bbee5/Getting-Started-with-k0s-and-Traefik-2.png 1800w,\n/static/e5e000f515b518b83b527146af938a46/0ef64/Getting-Started-with-k0s-and-Traefik-2.png 2400w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"K0s is a new Kubernetes distribution from Mirantis. It's similar to Rancher Labs' K3s, yet it ships only the bare minimum of extensions. K0s is a new Kubernetes distribution from Mirantis. This post covers how to configure k0s to include Traefik and begin routing your applications with CRDs.","custom_excerpt":"K0s is a new Kubernetes distribution from Mirantis. It's similar to Rancher Labs' K3s, yet it ships only the bare minimum of extensions. K0s is a new Kubernetes distribution from Mirantis. This post covers how to configure k0s to include Traefik and begin routing your applications with CRDs.","visibility":"public","created_at_pretty":"07 December, 2020","published_at_pretty":"December 8, 2020","updated_at_pretty":"09 December, 2020","created_at":"2020-12-07T17:05:36.000+00:00","published_at":"2020-12-08T16:10:36.000+00:00","updated_at":"2020-12-09T14:14:33.000+00:00","meta_title":"From Zero to Hero: Getting Started with k0s and Traefik","meta_description":"K0s is a new Kubernetes distribution from Mirantis. This post covers how to configure k0s to include Traefik and begin routing your applications with CRDs.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik---Twitter.png","twitter_title":null,"authors":[{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"}],"primary_author":{"name":"Kevin Crawley","slug":"kevincrawley","bio":"Kevin is a Developer Advocate at Containous, where he contributes to the team by bringing his passion and experience for developer productivity and automation.","profile_image":"https://containous.ghost.io/content/images/2020/04/2020-03-24_14-04-57.png","twitter":"@notsureifkevin","facebook":null,"website":"https://containo.us"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#homepage-featured-post-1","slug":"hash-homepage-featured-post-1","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"K0s [https://k0sproject.io/] is a new Kubernetes distribution from Mirantis.\nIt's similar to Rancher Labs' K3s, yet it ships with only the bare minimum of\nextensions. This allows flexibility for users who want to customize it to their\nneeds by defining their own ingress, storage, and other controllers in the CRD\nmanifest, configuring the cluster during bootstrap.\n\nIn the examples below, I’ll guide you through how to accomplish getting a\nfunctioning Kubernetes cluster by:\n\n 1. Installing k0s on a clean Linux VM\n 2. Configuring Traefik and MetalLB as an extension\n 3. Starting k0s\n 4. Deploying the Traefik Dashboard IngressRoute and an example service\n\nStep 1\nBefore we start, you should plan to do this on a clean install of Linux,\nprobably in a VM. You will be running k0s as a server/worker, and the worker\ninstalls components into the /var/lib filesystem as root (so root access is a\nrequirement). My understanding is there are plans to allow non-root workers in\nthe future. Hopefully, in addition to non-root, the k0s binary will allow worker\ninstallations in a configurable location.\n\n> Note: Cleanly shutting down and wiping the cluster is not a feature yet in the\nk0s binary. For now, rebooting the system and wiping /var/lib/k0s is the easiest\noption.\nOnce you have a clean Linux VM (I’m using Ubuntu 20.04.1), you’ll want to\ninstall the Helm and kubectl binaries.\n\ncurl -O https://get.helm.sh/helm-v3.4.1-linux-amd64.tar.gz\ntar xvzf helm-v3.4.1-linux-amd64.tar.gz\nsudo mv linux-amd64/helm /usr/local/bin\n\ncurl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin\n\nOnce those are installed, install the k0s binary, create the working directory\nfor k0s, and create a default config.\n\n> Note: The installer and running k0s itself both require root\n# make sure you're running as root\ncurl -sSLf get.k0s.sh | sh\n# create the working directory and set the permissions\nmkdir -p /var/lib/k0s && chmod 755 /var/lib/k0s\n# create the default config\nk0s default-config > /var/lib/k0s/k0s.yaml\n\nStep 2\nIn this step, you’ll configure Traefik and MetalLB\n[https://metallb.universe.tf/] as extensions that will be installed during the\ncluster's bootstrap. Traefik will function as an ingress controller and MetalLB\nwill allow you to access services from a logical IP address deployed as a \nservice load balancer\n[https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer].\nYou will want to have a small range of IP addresses that are addressable on your\nnetwork, preferably outside the range of your DHCP server.\n\nModify the newly created k0s.yaml file in /var/lib/k0s/k0s.yaml:\n\napiVersion: k0s.k0sproject.io/v1beta1\nkind: Cluster\nmetadata:\n  name: k0s\n...\nextensions:\n  helm:\n    repositories:\n    - name: traefik\n      url: https://helm.traefik.io/traefik\n    - name: bitnami\n      url: https://charts.bitnami.com/bitnami\n    charts:\n    - name: traefik\n      chartname: traefik/traefik\n      version: \"9.11.0\"\n      namespace: default\n    - name: metallb\n      chartname: bitnami/metallb\n      version: \"1.0.1\"\n      namespace: default\n      values: |2\n        configInline:\n          address-pools:\n          - name: generic-cluster-pool\n            protocol: layer2\n            addresses:\n            - 172.16.100.215-172.16.100.220\n\nAgain, be sure to provide a range of IPs for MetalLB that are addressable on\nyour network if you want to access the LoadBalancer and Ingress services from\noutside this machine.\n\nStep 3\nNow it's time to run k0s and let it automatically set up the server and worker,\nand deploy and configure Traefik and MetalLB:\n\ncd /var/lib/k0s\nk0s server --enable-worker </dev/null &>/dev/null &\n\nAfter a minute or two, you should be able to access the cluster using the\ncertificate generated by k0s, located in /var/lib/k0s/pki/admin.conf, and see\nthat MetalLB was deployed along with the Traefik Ingress Controller.\n\nroot@k0s-host ➜ export KUBECONFIG=/var/lib/k0s/pki/admin.conf\nroot@k0s-host ➜ kubectl get all\nNAME                                                 READY   STATUS    RESTARTS   AGE\npod/metallb-1607085578-controller-864c9757f6-bpx6r   1/1     Running   0          81s\npod/metallb-1607085578-speaker-245c2                 1/1     Running   0          60s\npod/traefik-1607085579-77bbc57699-b2f2t              1/1     Running   0          81s\n\nNAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/kubernetes           ClusterIP      10.96.0.1        <none>           443/TCP                      96s\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s\n\nNAME                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/metallb-1607085578-speaker   1         1         1       1            1           kubernetes.io/os=linux   87s\n\nNAME                                            READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/metallb-1607085578-controller   1/1     1            1           87s\ndeployment.apps/traefik-1607085579              1/1     1            1           84s\n\nNAME                                                       DESIRED   CURRENT   READY   AGE\nreplicaset.apps/metallb-1607085578-controller-864c9757f6   1         1         1       81s\nreplicaset.apps/traefik-1607085579-77bbc57699              1         1         1       81s\n\nTake note of the IP address assigned to the Traefik Load Balancer here:\n\nNAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s\n\nYou will need the EXTERNAL-IP (in this case, 172.16.100.215) later, when\naccessing Ingress resources on your cluster.\n\nStep 4\n * Deploy the Traefik dashboard\n * Deploy the sample “whoami” service\n\nNow that you have a functional and addressable load balancer on your cluster,\nyou can easily deploy the Traefik dashboard and access it from anywhere on your\nlocal network (provided that you configured MetalLB with an addressable range).\n\nCreate the Traefik Dashboard IngressRoute\n[https://doc.traefik.io/traefik/providers/kubernetes-crd/] in a YAML file:\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: PathPrefix(`/dashboard`) || PathPrefix(`/api`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService\n\nAnd deploy it:\n\nroot@k0s-host ➜ kubectl apply -f traefik-dashboard.yaml\ningressroute.traefik.containo.us/dashboard created\n\nYou can now access it from your browser by visiting \nhttp://172.16.100.215/dashboard/:\n\nGreat, now let’s deploy a simple “whoami” service.\n\nCreate the whoami Deployment, Service, and Kubernetes Ingress\n[https://kubernetes.io/docs/concepts/services-networking/ingress/] manifest:\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whoami-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: whoami\n  template:\n    metadata:\n      labels:\n        app: whoami\n    spec:\n      containers:\n      - name: whoami-container\n        image: containous/whoami\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: whoami-service\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: whoami\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: whoami-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /whoami\n        pathType: Exact\n        backend:\n          service:\n            name: whoami-service\n            port:\n              number: 80\n\nAnd now, deploy and test it…\n\nroot@k0s-host ➜ kubectl apply -f whoami.yaml\ndeployment.apps/whoami-deployment created\nservice/whoami-service created\ningress.networking.k8s.io/whoami-ingress created\n# test the route\nroot@k0s-host ➜ curl http://172.16.100.215/whoami\nHostname: whoami-deployment-85bfbd48f-7l77c\nIP: 127.0.0.1\nIP: ::1\nIP: 10.244.214.198\nIP: fe80::b049:f8ff:fe77:3e64\nRemoteAddr: 10.244.214.196:34858\nGET /whoami HTTP/1.1\nHost: 172.16.100.215\nUser-Agent: curl/7.68.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.16.100.77\nX-Forwarded-Host: 172.16.100.215\nX-Forwarded-Port: 80\nX-Forwarded-Proto: http\nX-Forwarded-Server: traefik-1607085579-77bbc57699-b2f2t\nX-Real-Ip: 172.16.100.77\n\nSummary\nThis post covered installing k0s, setting up a fully functional Load Balancer\nand Ingress controller for use in your local environment. From here, you could\nuse a tool such as ngrok [https://ngrok.io] to expose your Load Balancer to the\nworld and set up Let’s Encrypt\n[https://doc.traefik.io/traefik/v2.0/user-guides/crd-acme/] so you can provision\nyour own SSL certificates.\n\nThe design of k0s as a single binary installer that allows modular\ncustomizability makes it a unique offering in the Kubernetes community. You can\nlearn more about how to leverage Kubernetes Ingress with Traefik on our site. In\naddition, you can learn more about installing k0s on Mirantis' blog\n[https://www.mirantis.com/blog/how-to-set-up-k0s-kubernetes-a-quick-and-dirty-guide/]\n. While k0s is still relatively new to the scene, I hope this post gives you an\nidea of what it’s capable of and how you can start experimenting with your own\ncustomized Kubernetes setup.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik-1.png\" class=\"kg-image\" alt=\"Getting Started with k0s and Traefik\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 1600w, https://containous.ghost.io/content/images/2020/12/Getting-Started-with-k0s-and-Traefik-1.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: markdown--><p><a href=\"https://k0sproject.io/\" target=\"_blank\" rel=\"nofollow\">K0s</a> is a new Kubernetes distribution from Mirantis. It's similar to Rancher Labs' K3s, yet it ships with only the bare minimum of extensions. This allows flexibility for users who want to customize it to their needs by defining their own ingress, storage, and other controllers in the CRD manifest, configuring the cluster during bootstrap.</p>\n<!--kg-card-end: markdown--><p>In the examples below, I’ll guide you through how to accomplish getting a functioning Kubernetes cluster by:</p><ol><li>Installing k0s on a clean Linux VM</li><li>Configuring Traefik and MetalLB as an extension</li><li>Starting k0s</li><li>Deploying the Traefik Dashboard IngressRoute and an example service</li></ol><h2 id=\"step-1\">Step 1</h2><p>Before we start, you should plan to do this on a clean install of Linux, probably in a VM. You will be running k0s as a server/worker, and the worker installs components into the <code>/var/lib</code> filesystem as root (so root access is a requirement). My understanding is there are plans to allow non-root workers in the future. Hopefully, in addition to non-root, the k0s binary will allow worker installations in a configurable location.</p><blockquote>Note: Cleanly shutting down and wiping the cluster is not a feature yet in the k0s binary. For now, rebooting the system and wiping <code>/var/lib/k0s</code> is the easiest option.</blockquote><p>Once you have a clean Linux VM (I’m using Ubuntu 20.04.1), you’ll want to install the Helm and <code>kubectl</code> binaries.</p><pre><code class=\"language-bash\">curl -O https://get.helm.sh/helm-v3.4.1-linux-amd64.tar.gz\ntar xvzf helm-v3.4.1-linux-amd64.tar.gz\nsudo mv linux-amd64/helm /usr/local/bin\n\ncurl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin</code></pre><p>Once those are installed, install the k0s binary, create the working directory for k0s, and create a default config.</p><blockquote>Note: The installer and running k0s itself both require root</blockquote><pre><code class=\"language-bash\"># make sure you're running as root\ncurl -sSLf get.k0s.sh | sh\n# create the working directory and set the permissions\nmkdir -p /var/lib/k0s &amp;&amp; chmod 755 /var/lib/k0s\n# create the default config\nk0s default-config &gt; /var/lib/k0s/k0s.yaml</code></pre><h2 id=\"step-2\">Step 2</h2><!--kg-card-begin: markdown--><p>In this step, you’ll configure Traefik and <a href=\"https://metallb.universe.tf/\" rel=\"nofollow\">MetalLB</a> as extensions that will be installed during the cluster's bootstrap. Traefik will function as an ingress controller and MetalLB will allow you to access services from a logical IP address deployed as a <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer\" rel=\"nofollow\">service load balancer</a>. You will want to have a small range of IP addresses that are addressable on your network, preferably outside the range of your DHCP server.</p>\n<!--kg-card-end: markdown--><p>Modify the newly created k0s.yaml file in <code>/var/lib/k0s/k0s.yaml</code>:</p><pre><code class=\"language-yaml\">apiVersion: k0s.k0sproject.io/v1beta1\nkind: Cluster\nmetadata:\n  name: k0s\n...\nextensions:\n  helm:\n    repositories:\n    - name: traefik\n      url: https://helm.traefik.io/traefik\n    - name: bitnami\n      url: https://charts.bitnami.com/bitnami\n    charts:\n    - name: traefik\n      chartname: traefik/traefik\n      version: \"9.11.0\"\n      namespace: default\n    - name: metallb\n      chartname: bitnami/metallb\n      version: \"1.0.1\"\n      namespace: default\n      values: |2\n        configInline:\n          address-pools:\n          - name: generic-cluster-pool\n            protocol: layer2\n            addresses:\n            - 172.16.100.215-172.16.100.220</code></pre><p>Again, be sure to provide a range of IPs for MetalLB that are addressable on your network if you want to access the LoadBalancer and Ingress services from outside this machine.</p><h2 id=\"step-3\">Step 3</h2><p>Now it's time to run k0s and let it automatically set up the server and worker, and deploy and configure Traefik and MetalLB:</p><pre><code class=\"language-bash\">cd /var/lib/k0s\nk0s server --enable-worker &lt;/dev/null &amp;&gt;/dev/null &amp;</code></pre><p>After a minute or two, you should be able to access the cluster using the certificate generated by k0s, located in <code>/var/lib/k0s/pki/admin.conf</code>, and see that MetalLB was deployed along with the Traefik Ingress Controller.</p><pre><code class=\"language-bash\">root@k0s-host ➜ export KUBECONFIG=/var/lib/k0s/pki/admin.conf\nroot@k0s-host ➜ kubectl get all\nNAME                                                 READY   STATUS    RESTARTS   AGE\npod/metallb-1607085578-controller-864c9757f6-bpx6r   1/1     Running   0          81s\npod/metallb-1607085578-speaker-245c2                 1/1     Running   0          60s\npod/traefik-1607085579-77bbc57699-b2f2t              1/1     Running   0          81s\n\nNAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/kubernetes           ClusterIP      10.96.0.1        &lt;none&gt;           443/TCP                      96s\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s\n\nNAME                                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ndaemonset.apps/metallb-1607085578-speaker   1         1         1       1            1           kubernetes.io/os=linux   87s\n\nNAME                                            READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/metallb-1607085578-controller   1/1     1            1           87s\ndeployment.apps/traefik-1607085579              1/1     1            1           84s\n\nNAME                                                       DESIRED   CURRENT   READY   AGE\nreplicaset.apps/metallb-1607085578-controller-864c9757f6   1         1         1       81s\nreplicaset.apps/traefik-1607085579-77bbc57699              1         1         1       81s</code></pre><p>Take note of the IP address assigned to the Traefik Load Balancer here:</p><pre><code>NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP      PORT(S)                      AGE\nservice/traefik-1607085579   LoadBalancer   10.105.119.102   172.16.100.215   80:32153/TCP,443:30791/TCP   84s</code></pre><p>You will need the <code>EXTERNAL-IP</code> (in this case, <code>172.16.100.215</code>) later, when accessing Ingress resources on your cluster.</p><h2 id=\"step-4\">Step 4</h2><ul><li>Deploy the Traefik dashboard</li><li>Deploy the sample “whoami” service</li></ul><p>Now that you have a functional and addressable load balancer on your cluster, you can easily deploy the Traefik dashboard and access it from anywhere on your local network (provided that you configured MetalLB with an addressable range).</p><p>Create the Traefik Dashboard <a href=\"https://doc.traefik.io/traefik/providers/kubernetes-crd/\">IngressRoute</a> in a YAML file:</p><pre><code class=\"language-yaml\">apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: PathPrefix(`/dashboard`) || PathPrefix(`/api`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService</code></pre><p>And deploy it:</p><pre><code class=\"language-bash\">root@k0s-host ➜ kubectl apply -f traefik-dashboard.yaml\ningressroute.traefik.containo.us/dashboard created</code></pre><p>You can now access it from your browser by visiting <code>http://172.16.100.215/dashboard/</code>:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/12/image.png\" class=\"kg-image\" alt srcset=\"https://containous.ghost.io/content/images/size/w600/2020/12/image.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/12/image.png 1000w, https://containous.ghost.io/content/images/size/w1600/2020/12/image.png 1600w, https://containous.ghost.io/content/images/2020/12/image.png 1743w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Great, now let’s deploy a simple “whoami” service.</p><!--kg-card-begin: markdown--><p>Create the <code>whoami</code> Deployment, Service, and <a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\" rel=\"nofollow\">Kubernetes Ingress</a> manifest:</p>\n<!--kg-card-end: markdown--><pre><code class=\"language-yaml\">apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: whoami-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: whoami\n  template:\n    metadata:\n      labels:\n        app: whoami\n    spec:\n      containers:\n      - name: whoami-container\n        image: containous/whoami\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: whoami-service\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: whoami\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: whoami-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /whoami\n        pathType: Exact\n        backend:\n          service:\n            name: whoami-service\n            port:\n              number: 80</code></pre><p>And now, deploy and test it…</p><pre><code class=\"language-bash\">root@k0s-host ➜ kubectl apply -f whoami.yaml\ndeployment.apps/whoami-deployment created\nservice/whoami-service created\ningress.networking.k8s.io/whoami-ingress created\n# test the route\nroot@k0s-host ➜ curl http://172.16.100.215/whoami\nHostname: whoami-deployment-85bfbd48f-7l77c\nIP: 127.0.0.1\nIP: ::1\nIP: 10.244.214.198\nIP: fe80::b049:f8ff:fe77:3e64\nRemoteAddr: 10.244.214.196:34858\nGET /whoami HTTP/1.1\nHost: 172.16.100.215\nUser-Agent: curl/7.68.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.16.100.77\nX-Forwarded-Host: 172.16.100.215\nX-Forwarded-Port: 80\nX-Forwarded-Proto: http\nX-Forwarded-Server: traefik-1607085579-77bbc57699-b2f2t\nX-Real-Ip: 172.16.100.77</code></pre><h2 id=\"summary\">Summary</h2><!--kg-card-begin: markdown--><p>This post covered installing k0s, setting up a fully functional Load Balancer and Ingress controller for use in your local environment. From here, you could use a tool such as <a href=\"https://ngrok.io\" target=\"_blank\" rel=\"nofollow\">ngrok</a> to expose your Load Balancer to the world and <a href=\"https://doc.traefik.io/traefik/v2.0/user-guides/crd-acme/\">set up Let’s Encrypt</a> so you can provision your own SSL certificates.</p>\n<p>The design of k0s as a single binary installer that allows modular customizability makes it a unique offering in the Kubernetes community. You can learn more about how to leverage Kubernetes Ingress with Traefik on <a h ref=\"https://traefik.io/solutions/kubernetes-ingress/\">our site</a>. In addition, you can learn more about installing k0s on <a href=\"https://www.mirantis.com/blog/how-to-set-up-k0s-kubernetes-a-quick-and-dirty-guide/\" rel=\"nofollow\">Mirantis' blog</a>. While k0s is still relatively new to the scene, I hope this post gives you an idea of what it’s capable of and how you can start experimenting with your own customized Kubernetes setup.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/from-zero-to-hero-getting-started-with-k0s-and-traefik/","canonical_url":null,"uuid":"52748163-308e-42aa-8993-8a805ee3500e","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5fce60e016db8f0039b4334b","reading_time":5}},{"node":{"id":"Ghost__Post__5f5fc262a72a090039800e87","title":"Install And Configure Traefik with Helm","slug":"install-and-configure-traefik-with-helm","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/09/Kubernetes-and-Helm-blog-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/3c8465819333c37d5dc14524c7ba4332/47498/Kubernetes-and-Helm-blog-1.jpg","srcSet":"/static/3c8465819333c37d5dc14524c7ba4332/9dc27/Kubernetes-and-Helm-blog-1.jpg 300w,\n/static/3c8465819333c37d5dc14524c7ba4332/4fe8c/Kubernetes-and-Helm-blog-1.jpg 600w,\n/static/3c8465819333c37d5dc14524c7ba4332/47498/Kubernetes-and-Helm-blog-1.jpg 1200w,\n/static/3c8465819333c37d5dc14524c7ba4332/52258/Kubernetes-and-Helm-blog-1.jpg 1800w,\n/static/3c8465819333c37d5dc14524c7ba4332/a41d1/Kubernetes-and-Helm-blog-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Install And Configure Traefik with Helm by Robin Sherrer and Daniele Di Rosa. Learn how they went from Traefik 1.x to 2.0, installing and configuring Helm. ","custom_excerpt":"Install And Configure Traefik with Helm by Robin Sherrer and Daniele Di Rosa. Learn how they went from Traefik 1.x to 2.0, installing and configuring Helm. ","visibility":"public","created_at_pretty":"14 September, 2020","published_at_pretty":"October 6, 2020","updated_at_pretty":"27 October, 2020","created_at":"2020-09-14T19:20:02.000+00:00","published_at":"2020-10-06T14:00:00.000+00:00","updated_at":"2020-10-27T06:10:33.000+00:00","meta_title":"Install And Configure Traefik with Helm","meta_description":"Learn how to install and configure Traefik using the official Helm chart and how to configure Traefik with Cloudflare.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/09/kubernetes-and-helm-twitter.jpg","twitter_title":null,"authors":[{"name":"containeroo","slug":"containeroo","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/09/Containeroo.jpg","twitter":"@containeroo","facebook":null,"website":"https://containeroo.ch/"}],"primary_author":{"name":"containeroo","slug":"containeroo","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/09/Containeroo.jpg","twitter":"@containeroo","facebook":null,"website":"https://containeroo.ch/"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#community-related-resource","slug":"hash-community-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"Guest post by Traefik Ambassador, Robin Scherrer and Daniele Di Rosa aka\nContaineroo.\n\nWhen we started our container journey with Docker some years ago, we looked for\nan easy to configure reverse proxy to expose our services to the internet.\nDaniele had seen a video about the best Docker projects where Emile Vauge,\nfounder of Traefik, delivered a presentation about Traefik. And, we decided to\ngive Traefik a shot. We started with using Traefik 1.x, and then moved to\nTraefik 2.0 a couple of years later.\n\nWhen Traefik 2.0 was released, we spent the weekend figuring out how it works,\nand the next week, decided to help others have a tremendous “getting started”\nexperience by writing a simple step by step guide. And, with our roles on the\nKubernetes team at work, we went on to replace the existing reverse proxy\nAmbassador with Traefik.\n\nThe Tutorial\nIn this tutorial, we will show you how to install and configure Traefik using\nthe official Helm chart. We will also show you how to configure Traefik with\nCloudflare. This makes wildcard Let's Encrypt certificates possible.\nHelm makes it easy to deploy applications onto your Kubernetes cluster. Even\nthough Traefik supports both Ingress as well as Traefik IngressRoute, we prefer\nto use the CRD instead of Ingress which results in a lot of annotations.\n\nPrerequisites\n * Kubernetes Cluster\n * Helm official docs [https://helm.sh]\n * Kubeconfig file for Helm to access your Kubernetes Cluster (~/.kube/config)\n\nPrepare Helm Chart\nFirst, you’ll need to add the official Helm repository to your Helm client. You\ncan do that by issuing the following command:\n\nhelm repo add traefik https://helm.traefik.io/traefik\nhelm repo update\n\n\nIn order to configure the Helm chart, you'll need to specify certain values. You\ncan find all the values possible here\n[https://github.com/traefik/traefik-helm-chart/blob/master/traefik/values.yaml].\nOpen your favourite editor and set the values you want to change. Here is an\nexample traefik-chart-values.yaml file:\n\nadditionalArguments:\n  - --providers.file.filename=/data/traefik-config.yaml\n  - --entrypoints.websecure.http.tls.certresolver=cloudflare\n  - --entrypoints.websecure.http.tls.domains[0].main=example.com\n  - --entrypoints.websecure.http.tls.domains[0].sans=*.example.com\n  - --certificatesresolvers.cloudflare.acme.dnschallenge.provider=cloudflare\n  - --certificatesresolvers.cloudflare.acme.email=mail@example.com\n  - --certificatesresolvers.cloudflare.acme.dnschallenge.resolvers=1.1.1.1\n  - --certificatesresolvers.cloudflare.acme.storage=/certs/acme.json\nports:\n  web:\n    redirectTo: websecure\nenv:\n  - name: CF_API_EMAIL\n    valueFrom:\n      secretKeyRef:\n        key: email\n        name: cloudflare-api-credentials\n  - name: CF_API_KEY\n    valueFrom:\n      secretKeyRef:\n        key: apiKey\n        name: cloudflare-api-credentials\ningressRoute:\n  dashboard:\n    enabled: false\npersistence:\n  enabled: true\n  path: /certs\n  size: 128Mi\nvolumes:\n  - mountPath: /data\n    name: traefik-config\n    type: configMap\n\n\nWith this values file, you are configuring Traefik to:\n\n * use /data/traefik-config.yaml as a static configuration file\n * use Cloudflare as a certificates resolver\n * set the domain example.com as the certificates main domain\n * set *.example.com as the certificates sans\n * store the certificates in /certs/acme.json\n\nInstall Traefik\nAs a first step, you’ll need to create a Kubernetes namespace:\n\nkubectl create namespace traefik\n\n\nBefore you deploy the Helm chart, you’ll need to add the secret containing the\nCloudflare credentials along with the configmap including the static\nconfiguration.\nCreate a traefik-config.yaml file with the following content:\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: cloudflare-api-credentials\n  namespace: traefik\ntype: Opaque\nstringData:\n  email: your@cloudflare.email\n  apiKey: YOURCLOUDFLAREAPIKEY\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: traefik-config\n  namespace: traefik\ndata:\n  traefik-config.yaml: |\n    http:\n      middlewares:\n        headers-default:\n          headers:\n            sslRedirect: true\n            browserXssFilter: true\n            contentTypeNosniff: true\n            forceSTSHeader: true\n            stsIncludeSubdomains: true\n            stsPreload: true\n            stsSeconds: 15552000\n            customFrameOptionsValue: SAMEORIGIN\n\n\nAs an example, we've added a headers-default middleware. For the complete static\nconfiguration, please consult the Traefik docs\n[https://docs.traefik.io/reference/static-configuration/file/].\nNext, you can apply the secret and configmap you created above:\n\nkubectl apply -f traefik-config.yaml\n\n\nThis will create the secret and configmap in the traefik namespace.\nNow it's time to deploy Traefik! The following command will install Traefik in\nthe traefik namespace and with the configuration you created above::\n\nhelm install traefik traefik/traefik --namespace=traefik --values=traefik-chart-values.yaml\n\n\nMake the Dashboard Accessible\nIn order to access the Traefik dashboard, you’ll first need to create an HTTP\nbasic auth middleware. This also requires a secret with the htpasswd\ncredentials.\nUse the following command to create a base64 encoded htpasswd file with a \nkangoroo user and the password jack:\n\nhtpasswd -nb kangoroo jack | openssl base64\n\n\nApply the secret and the middleware to your Kubernetes cluster:\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: traefik-dashboard-auth\n  namespace: traefik\ndata:\n  users: |2\n    a2FuZ29yb286JGFwcjEkdGlQbFBINXYkYlJrUHBSUlYuYUxUWnhFRzdYbmduMAoK\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: traefik-dashboard-basicauth\n  namespace: traefik\nspec:\n  basicAuth:\n    secret: traefik-dashboard-auth\n\n\nNow you can apply the following traefik-dashboard-ingressroute.yaml file:\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-dashboard\n  namespace: traefik\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`traefik.example.com`)\n      kind: Rule\n      middlewares:\n        - name: traefik-dashboard-basicauth\n          namespace: traefik\n      services:\n        - name: api@internal\n          kind: TraefikService\n\n\nPlease change the matching host rule accordingly under the routes section.\nSince Traefik exposes the dashboard in a special way, you’ll need to tell the\nIngressRoute to use the preconfigured service named api@internal with kind \nTraefikService.\n\nThe IngressRoute CRD\nAs we've mentioned above, Traefik both supports Ingress and IngressRoute as a\nconfiguration.\nThe CRD has a few advantages:\n\n * eliminate or reduce the number of annotations on the Ingress controllers\n * abstract commonly used rules and configuration\n * separate concerns across multiple use-cases and configurations\n   To deploy a simple whoami application service, please refer to the appendix.\n   Here is an example IngressRoute for the whoami service:\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: whoami\n  namespace: traefik\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`whoami.example.com`)\n      kind: Rule\n      middlewares:\n        - name: headers-default@file\n      services:\n        - name: whoami\n          port: 80\n\n\nThis IngressRoute tells Traefik to listen via the websecure entrypoint and\nforward all the traffic matching the host whoami.example.com to the whoami \nKubernetes service. It also configures the route to use the headers-default \nmiddleware you configured in traefik-config.yaml.\n\nConclusion\nAs you can see, getting started with Traefik as an Ingress controller isn't that\nhard :-) Helm makes it really easy to reconfigure or update Traefik.\n\nTraefik documentation has a lot of good information and can be a great resource\nonce you’ve gotten started using this guide. We bet it will answer most of your\nquestions!\n\nYou can find us on Twitter [https://twitter.com/containeroo], Medium\n[https://medium.com/@containeroo] or GitHub [https://github.com/containeroo].\nFeel free to ask any questions regarding Traefik and Kubernetes. We are happy to\nhelp!\n\nAppendix\nWhoami Example Deployment\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: whoami\n  namespace: traefik\n  labels:\n    app: whoami\nspec:\n  containers:\n    - name: whoami\n      image: containous/whoami:latest\n      ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: whoami\n  namespace: traefik\nspec:\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 80\n  selector:\n    app: whoami\n  type: ClusterIP\n\n\nAbout Us\nBecause of our knowledge in Docker, we were able to switch departments at work,\nand are now working in the Kubernetes department. One of the first things we did\nwas eliminate the existing reverse proxy and switch to Traefik :-D\n\nRobin:\nSwiss IT nerd since forever. Interested in open source technologies like\nAnsible, Docker, Kubernetes, Traefik, Python and Golang. Maintainer of several\nGitHub repos and Docker images for containeroo. Addicted to music, tv shows and\nYouTube. Speaking German and English. Twitter [https://twitter.com/rxbn], Reddit\n[https://reddit.com/u/rxbn] or GitHub [https://github.com/rxbn].\n\nDaniele:\nCouch potato, film and series junky, hobby-columnist for Containeroo, likes\nTraefik, Ansible, Docker and K8s. Hates corn and dill. Born and raised in\nSwitzerland. Star me on GitHub [https://github.com/gi8lino].","html":"<p><strong>Guest post by Traefik Ambassador, Robin Scherrer and Daniele Di Rosa aka Containeroo.</strong></p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/09/Kubernetes-and-Helm-blog-2.jpg\" class=\"kg-image\" alt=\"Install and Configure Traefik with Helm\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/09/Kubernetes-and-Helm-blog-2.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/09/Kubernetes-and-Helm-blog-2.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/09/Kubernetes-and-Helm-blog-2.jpg 1600w, https://containous.ghost.io/content/images/2020/09/Kubernetes-and-Helm-blog-2.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><!--kg-card-begin: markdown--><p>When we started our container journey with Docker some years ago, we looked for an easy to configure reverse proxy to expose our services to the internet. Daniele had seen a video about the best Docker projects where Emile Vauge, founder of Traefik, delivered a presentation about Traefik. And, we decided to give Traefik a shot. We started with using Traefik 1.x, and then moved to Traefik 2.0 a couple of years later.</p>\n<p>When Traefik 2.0 was released, we spent the weekend figuring out how it works, and the next week, decided to help others have a tremendous “getting started” experience by writing a simple step by step guide. And, with our roles on the Kubernetes team at work, we went on to replace the existing reverse proxy Ambassador with Traefik.</p>\n<h2 id=\"thetutorial\">The Tutorial</h2>\n<p>In this tutorial, we will show you how to install and configure Traefik using the official Helm chart. We will also show you how to configure Traefik with Cloudflare. This makes wildcard Let's Encrypt certificates possible.<br>\nHelm makes it easy to deploy applications onto your Kubernetes cluster. Even though Traefik supports both Ingress as well as Traefik IngressRoute, we prefer to use the CRD instead of Ingress which results in a lot of annotations.</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<ul>\n<li>Kubernetes Cluster</li>\n<li>Helm <a href=\"https://helm.sh\" target=\"_blank\" rel=\"nofollow\">official docs</a></li>\n<li>Kubeconfig file for Helm to access your Kubernetes Cluster (<code>~/.kube/config</code>)</li>\n</ul>\n<h2 id=\"preparehelmchart\">Prepare Helm Chart</h2>\n<p>First, you’ll need to add the official Helm repository to your Helm client. You can do that by issuing the following command:</p>\n<pre><code class=\"language-bash\">helm repo add traefik https://helm.traefik.io/traefik\nhelm repo update\n</code></pre>\n<p>In order to configure the Helm chart, you'll need to specify certain values. You can find all the values possible <a href=\"https://github.com/traefik/traefik-helm-chart/blob/master/traefik/values.yaml\" target=\"_blank\" rel=\"nofollow\">here</a>.<br>\nOpen your favourite editor and set the values you want to change. Here is an example <code>traefik-chart-values.yaml</code> file:</p>\n<pre><code class=\"language-yaml\">additionalArguments:\n  - --providers.file.filename=/data/traefik-config.yaml\n  - --entrypoints.websecure.http.tls.certresolver=cloudflare\n  - --entrypoints.websecure.http.tls.domains[0].main=example.com\n  - --entrypoints.websecure.http.tls.domains[0].sans=*.example.com\n  - --certificatesresolvers.cloudflare.acme.dnschallenge.provider=cloudflare\n  - --certificatesresolvers.cloudflare.acme.email=mail@example.com\n  - --certificatesresolvers.cloudflare.acme.dnschallenge.resolvers=1.1.1.1\n  - --certificatesresolvers.cloudflare.acme.storage=/certs/acme.json\nports:\n  web:\n    redirectTo: websecure\nenv:\n  - name: CF_API_EMAIL\n    valueFrom:\n      secretKeyRef:\n        key: email\n        name: cloudflare-api-credentials\n  - name: CF_API_KEY\n    valueFrom:\n      secretKeyRef:\n        key: apiKey\n        name: cloudflare-api-credentials\ningressRoute:\n  dashboard:\n    enabled: false\npersistence:\n  enabled: true\n  path: /certs\n  size: 128Mi\nvolumes:\n  - mountPath: /data\n    name: traefik-config\n    type: configMap\n</code></pre>\n<p>With this values file, you are configuring Traefik to:</p>\n<ul>\n<li>use <code>/data/traefik-config.yaml</code> as a static configuration file</li>\n<li>use Cloudflare as a certificates resolver</li>\n<li>set the domain <code>example.com</code> as the certificates main domain</li>\n<li>set <code>*.example.com</code> as the certificates sans</li>\n<li>store the certificates in <code>/certs/acme.json</code></li>\n</ul>\n<h2 id=\"installtraefik\">Install Traefik</h2>\n<p>As a first step, you’ll need to create a Kubernetes namespace:</p>\n<pre><code class=\"language-bash\">kubectl create namespace traefik\n</code></pre>\n<p>Before you deploy the Helm chart, you’ll need to add the secret containing the Cloudflare credentials along with the configmap including the static configuration.<br>\nCreate a <code>traefik-config.yaml</code> file with the following content:</p>\n<pre><code class=\"language-yaml\">---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: cloudflare-api-credentials\n  namespace: traefik\ntype: Opaque\nstringData:\n  email: your@cloudflare.email\n  apiKey: YOURCLOUDFLAREAPIKEY\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: traefik-config\n  namespace: traefik\ndata:\n  traefik-config.yaml: |\n    http:\n      middlewares:\n        headers-default:\n          headers:\n            sslRedirect: true\n            browserXssFilter: true\n            contentTypeNosniff: true\n            forceSTSHeader: true\n            stsIncludeSubdomains: true\n            stsPreload: true\n            stsSeconds: 15552000\n            customFrameOptionsValue: SAMEORIGIN\n</code></pre>\n<p>As an example, we've added a <code>headers-default</code> middleware. For the complete static configuration, please consult the <a href=\"https://docs.traefik.io/reference/static-configuration/file/\">Traefik docs</a>.<br>\nNext, you can apply the secret and configmap you created above:</p>\n<pre><code class=\"language-bash\">kubectl apply -f traefik-config.yaml\n</code></pre>\n<p>This will create the secret and configmap in the <code>traefik</code> namespace.<br>\nNow it's time to deploy Traefik! The following command will install Traefik in the <code>traefik</code> namespace and with the configuration you created above::</p>\n<pre><code class=\"language-bash\">helm install traefik traefik/traefik --namespace=traefik --values=traefik-chart-values.yaml\n</code></pre>\n<h2 id=\"makethedashboardaccessible\">Make the Dashboard Accessible</h2>\n<p>In order to access the Traefik dashboard, you’ll first need to create an HTTP basic auth middleware. This also requires a secret with the htpasswd credentials.<br>\nUse the following command to create a base64 encoded htpasswd file with a <code>kangoroo</code> user and the password <code>jack</code>:</p>\n<pre><code class=\"language-bash\">htpasswd -nb kangoroo jack | openssl base64\n</code></pre>\n<p>Apply the secret and the middleware to your Kubernetes cluster:</p>\n<pre><code class=\"language-yaml\">---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: traefik-dashboard-auth\n  namespace: traefik\ndata:\n  users: |2\n    a2FuZ29yb286JGFwcjEkdGlQbFBINXYkYlJrUHBSUlYuYUxUWnhFRzdYbmduMAoK\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: traefik-dashboard-basicauth\n  namespace: traefik\nspec:\n  basicAuth:\n    secret: traefik-dashboard-auth\n</code></pre>\n<p>Now you can apply the following <code>traefik-dashboard-ingressroute.yaml</code> file:</p>\n<pre><code class=\"language-yaml\">apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-dashboard\n  namespace: traefik\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`traefik.example.com`)\n      kind: Rule\n      middlewares:\n        - name: traefik-dashboard-basicauth\n          namespace: traefik\n      services:\n        - name: api@internal\n          kind: TraefikService\n</code></pre>\n<p>Please change the matching host rule accordingly under the <code>routes</code> section.<br>\nSince Traefik exposes the dashboard in a special way, you’ll need to tell the IngressRoute to use the preconfigured service named <code>api@internal</code> with kind <code>TraefikService</code>.</p>\n<h2 id=\"theingressroutecrd\">The IngressRoute CRD</h2>\n<p>As we've mentioned above, Traefik both supports Ingress and IngressRoute as a configuration.<br>\nThe CRD has a few advantages:</p>\n<ul>\n<li>eliminate or reduce the number of annotations on the Ingress controllers</li>\n<li>abstract commonly used rules and configuration</li>\n<li>separate concerns across multiple use-cases and configurations<br>\nTo deploy a simple <code>whoami</code> application service, please refer to the appendix.<br>\nHere is an example IngressRoute for the <code>whoami</code> service:</li>\n</ul>\n<pre><code class=\"language-yaml\">apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: whoami\n  namespace: traefik\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`whoami.example.com`)\n      kind: Rule\n      middlewares:\n        - name: headers-default@file\n      services:\n        - name: whoami\n          port: 80\n</code></pre>\n<p>This IngressRoute tells Traefik to listen via the <code>websecure</code> entrypoint and forward all the traffic matching the host <code>whoami.example.com</code> to the <code>whoami</code> Kubernetes service. It also configures the route to use the <code>headers-default</code> middleware you configured in <code>traefik-config.yaml</code>.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>As you can see, getting started with Traefik as an Ingress controller isn't that hard :-)  Helm makes it really easy to reconfigure or update Traefik.</p>\n<p>Traefik documentation has a lot of good information and can be a great resource once you’ve gotten started using this guide. We bet it will answer most of your questions!</p>\n<p>You can find us on <a href=\"https://twitter.com/containeroo\" target=\"_blank\" rel=\"nofollow\">Twitter</a>, <a href=\"https://medium.com/@containeroo\" target=\"_blank\" rel=\"nofollow\">Medium</a> or <a href=\"https://github.com/containeroo\" target=\"_blank\" rel=\"nofollow\">GitHub</a>. Feel free to ask any questions regarding Traefik and Kubernetes. We are happy to help!</p>\n<h2 id=\"appendix\">Appendix</h2>\n<h3 id=\"whoamiexampledeployment\">Whoami Example Deployment</h3>\n<pre><code class=\"language-yaml\">---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: whoami\n  namespace: traefik\n  labels:\n    app: whoami\nspec:\n  containers:\n    - name: whoami\n      image: containous/whoami:latest\n      ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: whoami\n  namespace: traefik\nspec:\n  ports:\n    - port: 80\n      protocol: TCP\n      targetPort: 80\n  selector:\n    app: whoami\n  type: ClusterIP\n</code></pre>\n<h2 id=\"aboutus\">About Us</h2>\n<p>Because of our knowledge in Docker, we were able to switch departments at work, and are now working in the Kubernetes department. One of the first things we did was eliminate the existing reverse proxy and switch to Traefik :-D</p>\n<p>Robin:<br>\nSwiss IT nerd since forever. Interested in open source technologies like Ansible, Docker, Kubernetes, Traefik, Python and Golang. Maintainer of several GitHub repos and Docker images for containeroo. Addicted to music, tv shows and YouTube. Speaking German and English. <a href=\"https://twitter.com/rxbn\" target=\"_blank\" rel=\"nofollow\">Twitter</a>, <a href=\"https://reddit.com/u/rxbn\" target=\"_blank\" rel=\"nofollow\">Reddit</a> or <a href=\"https://github.com/rxbn\" target=\"_blank\" rel=\"nofollow\">GitHub</a>.</p>\n<p>Daniele:<br>\nCouch potato, film and series junky, hobby-columnist for Containeroo, likes Traefik, Ansible, Docker and K8s. Hates corn and dill. Born and raised in Switzerland. Star me on <a href=\"https://github.com/gi8lino\" target=\"_blank\" rel=\"nofollow\">GitHub</a>.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/install-and-configure-traefik-with-helm/","canonical_url":null,"uuid":"67cb07b2-be3a-461e-979b-92dcdab2d516","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f5fc262a72a090039800e87","reading_time":5}},{"node":{"id":"Ghost__Post__5f4ee6313a6f7f00398c1198","title":"Unlock the potential of data APIs with strong authentication and Traefik Enterprise","slug":"unlock-the-potential-of-data-apis-with-strong-authentication-and-traefik-enterprise","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/cfaeda0f50c979152fc15e686c80b150/47498/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg","srcSet":"/static/cfaeda0f50c979152fc15e686c80b150/9dc27/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg 300w,\n/static/cfaeda0f50c979152fc15e686c80b150/4fe8c/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg 600w,\n/static/cfaeda0f50c979152fc15e686c80b150/47498/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg 1200w,\n/static/cfaeda0f50c979152fc15e686c80b150/52258/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg 1800w,\n/static/cfaeda0f50c979152fc15e686c80b150/a41d1/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"One of the top goals for enterprises today is to open up the data held within legacy systems and expose it through APIs, microservices, and other modern means.","custom_excerpt":"One of the top goals for enterprises today is to open up the data held within legacy systems and expose it through APIs, microservices, and other modern means.","visibility":"public","created_at_pretty":"02 September, 2020","published_at_pretty":"September 2, 2020","updated_at_pretty":"23 September, 2020","created_at":"2020-09-02T00:24:17.000+00:00","published_at":"2020-09-02T14:30:58.000+00:00","updated_at":"2020-09-23T12:31:19.000+00:00","meta_title":"Unlock the potential of data APIs with strong authentication & Traefik","meta_description":"One of the top goals for enterprises today is to open up data held within legacy systems and expose it through APIs, microservices, and other modern means","og_description":null,"og_image":null,"og_title":null,"twitter_description":"One of the top goals for enterprises today is to open up the data held within legacy systems and expose it through APIs, microservices, and other modern means.","twitter_image":"https://containous.ghost.io/content/images/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise---Twitter.png","twitter_title":"Unlock the potential of data APIs with strong authentication and Traefik Enterprise","authors":[{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Neil McAllister","slug":"neil","bio":null,"profile_image":"https://containous.ghost.io/content/images/2020/05/Neil_McAllister_GPS_sm.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#api-gateway-related-resource","slug":"hash-api-gateway-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"When it comes to enterprise IT infrastructure, security is of paramount\nimportance. Between the need for data protection and privacy, regulatory\nrequirements, and the constant threat of bad actors on the network, there is\nlittle room for error when designing and maintaining enterprise systems.\n\nBecause of this, strong authentication is a critical component of any IT\nmodernization project. One of the top goals for enterprises today is to open up\nthe data held within legacy systems and expose it through APIs, microservices,\nand other modern means. And yet, while this data represents untapped business\nvalue, it’s essential to only expose it in controlled ways by using\nauthentication to ensure each request’s validity.\n\nTraefik can help. As a modern, cloud-native edge router, Traefik’s goal is to\ndirect valid requests from the external network to applications and services,\nwhile minimizing the risk posed by malformed, malicious, or fraudulent requests.\nOne way it can do this is by acting as an intermediary to ensure that\ntransactions are authorized. What’s more, Traefik Enterprise (TraefikEE) bundles\nadditional, exclusive features to provide enterprise-grade authentication –\nincluding, most recently, support for OpenID Connect.\n\nWho goes there?\nOne of Traefik’s key concepts is its use of middlewares\n[https://docs.traefik.io/v2.2/middlewares/overview/], which are pluggable\ncomponents that provide conditional controls over network traffic. These\ncontrols can take various forms, including enabling security features such as\nrate limiting, restricting requests by IP address, and authentication.\n\nTraefikEE’s enterprise authentication middlewares work by referencing external \nauthentication sources. For example, the LDAP middleware connects to an LDAP\nserver to verify credentials. In this way, Traefik can act as a gatekeeper at\nthe edge of the internal network by intercepting incoming requests and\nauthenticating them against the external source before forwarding them to the\nappropriate applications.\n\nThis model can be particularly critical for legacy modernization projects\nbecause it allows authentication to occur externally to the application. One\nbenefit of this is that it makes it possible to add modern authentication\nmethods to legacy applications to satisfy the latest security requirements,\nwithout making any direct modifications to legacy code.\n\nEnterprise options\nIn addition to LDAP, Traefik Enterprise offers several other middlewares for\nenterprise authentication, and the collection continues to grow. Among the\nmethods that TraefikEE supports are:\n\nHMAC\nHash-based message authentication codes (HMAC\n[https://docs.containo.us/middlewares/hmac/]) is a method of using cryptographic\nhash functions with a shared secret (also known as a symmetric key) to ensure\nthe content delivered in an HTTP request is valid and genuine. Like digital\nsignatures, HMAC can verify a message sender’s identity and that the message’s\ncontent is unaltered from the moment of the HMAC’s  creation. The technique can\nbe used to secure file transfers, API calls, and other machine-to-machine\ninteractions.\n\nJWT\nJSON web tokens (JWT [https://docs.containo.us/middlewares/jwt/]) is another\npopular tool used to authenticate API calls and SSO applications. It’s a method\nof digitally signing information as a JSON object. The JWT includes a set of\n“claims,” which typically describe the things that an authenticated user is\nallowed to do. TraefikEE”s JWT middleware also includes support for JSON web key\nsets.\n\nOpenID Connect\nTraefikEE also includes support for OpenID Connect\n[https://docs.containo.us/middlewares/oidc/], an authentication layer built on\ntop of the OAuth 2.0 protocol. OpenID Connect allows an application to obtain\nuser login information by exchanging cryptographic tokens with an identity\nprovider, and is often used to implement federated single sign-on (SSO) between\nmultiple applications.\n\nOpenID Connect has become a popular option for enterprises because it allows\noperators to self-host their on-premises identity provider or choose from a\ngrowing number of third-party options. Okta\n[https://www.okta.com/openid-connect/], for example, is a cloud-hosted\nenterprise identity platform that supports authentication via OpenID Connect.\nSeveral public options are also available, allowing users to authenticate based\non their logins for services such as Google\n[https://developers.google.com/identity/protocols/oauth2/openid-connect] and \nPaypal [https://developer.paypal.com/docs/connect-with-paypal/].If full\nauthentication isn’t needed, TraefikEE also supplies a middleware for verifying\nthe authorization of requests via the OAuth 2.0 token introspection\n[https://docs.containo.us/middlewares/oauth-intro/] method.\n\nAuthentication the easy way\nThe best thing about implementing enterprise authentication using TraefikEE,\nhowever, is how easy it is to do. Enabling any of the authentication middleware\nmentioned here is generally as simple as adding a few lines to your Traefik\nconfiguration to supply the necessary credentials and point the middleware to\nyour authentication source.\n\nThe authentication options available in TraefikEE today offer a powerful range\nof options for exposing enterprise applications and data securely, without\nrequiring extensive and risky legacy code changes. You can expect other such\nfeatures to be included over time, as we continue our commitment to ensure\nTraefikEE is a premier tool for enterprise application networking.To learn more\nabout how Traefik and Traefik Enterprise can help you lock down enterprise data\nwith secure authentication, watch our recent webinar, “Enterprise best\npractices\nto expose and secure microservices and APIs\n[https://info.containo.us/webinar-recording-enterprise-best-practices-to-expose-and-secure-microservices-apis]\n”. We’ll discuss deploying OAuth and OpenID Connect with Okta to secure user\nlogins, and we’ll also walk through enabling mutual TLS (mTLS) for secure\nmachine-to-machine communications.","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise.jpg\" class=\"kg-image\" alt=\"Unlock the potential of data APIs with strong authentication and Traefik\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise.jpg 1600w, https://containous.ghost.io/content/images/2020/09/Unlock-the-potential-of-data-APIs-with-strong-authentication-and-Traefik-Enterprise.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>When it comes to enterprise IT infrastructure, security is of paramount importance. Between the need for data protection and privacy, regulatory requirements, and the constant threat of bad actors on the network, there is little room for error when designing and maintaining enterprise systems.</p><p>Because of this, strong authentication is a critical component of any IT modernization project. One of the top goals for enterprises today is to open up the data held within legacy systems and expose it through APIs, microservices, and other modern means. And yet, while this data represents untapped business value, it’s essential to only expose it in controlled ways by using authentication to ensure each request’s validity.</p><p>Traefik can help. As a modern, cloud-native edge router, Traefik’s goal is to direct valid requests from the external network to applications and services, while minimizing the risk posed by malformed, malicious, or fraudulent requests. One way it can do this is by acting as an intermediary to ensure that transactions are authorized. What’s more, Traefik Enterprise (TraefikEE) bundles additional, exclusive features to provide enterprise-grade authentication – including, most recently, support for OpenID Connect.</p><h2 id=\"who-goes-there\">Who goes there?</h2><p>One of Traefik’s key concepts is its use of<a href=\"https://docs.traefik.io/v2.2/middlewares/overview/\"> <em>middlewares</em></a>, which are pluggable components that provide conditional controls over network traffic. These controls can take various forms, including enabling security features such as rate limiting, restricting requests by IP address, and authentication.</p><p>TraefikEE’s enterprise authentication middlewares work by referencing external <em>authentication sources</em>. For example, the LDAP middleware connects to an LDAP server to verify credentials. In this way, Traefik can act as a gatekeeper at the edge of the internal network by intercepting incoming requests and authenticating them against the external source before forwarding them to the appropriate applications.</p><p>This model can be particularly critical for legacy modernization projects because it allows authentication to occur externally to the application. One benefit of this is that it makes it possible to add modern authentication methods to legacy applications to satisfy the latest security requirements, without making any direct modifications to legacy code.</p><h2 id=\"enterprise-options\"><strong>Enterprise options</strong></h2><p>In addition to LDAP, Traefik Enterprise offers several other middlewares for enterprise authentication, and the collection continues to grow. Among the methods that TraefikEE supports are:</p><h3 id=\"hmac\"><strong>HMAC</strong></h3><p>Hash-based message authentication codes (<a href=\"https://docs.containo.us/middlewares/hmac/\">HMAC</a>) is a method of using cryptographic hash functions with a shared secret (also known as a symmetric key) to ensure the content delivered in an HTTP request is valid and genuine. Like digital signatures, HMAC can verify a message sender’s identity and that the message’s content is unaltered from the moment of the HMAC’s  creation. The technique can be used to secure file transfers, API calls, and other machine-to-machine interactions.</p><h3 id=\"jwt\"><strong>JWT</strong></h3><p>JSON web tokens (<a href=\"https://docs.containo.us/middlewares/jwt/\">JWT</a>) is another popular tool used to authenticate API calls and SSO applications. It’s a method of digitally signing information as a JSON object. The JWT includes a set of “claims,” which typically describe the things that an authenticated user is allowed to do. TraefikEE”s JWT middleware also includes support for JSON web key sets.</p><h3 id=\"openid-connect\"><strong>OpenID Connect</strong></h3><p>TraefikEE also includes<a href=\"https://docs.containo.us/middlewares/oidc/\"> support for OpenID Connect</a>, an authentication layer built on top of the OAuth 2.0 protocol. OpenID Connect allows an application to obtain user login information by exchanging cryptographic tokens with an identity provider, and is often used to implement federated single sign-on (SSO) between multiple applications.</p><!--kg-card-begin: markdown--><p>OpenID Connect has become a popular option for enterprises because it allows operators to self-host their on-premises identity provider or choose from a growing number of third-party options. <a href=\"https://www.okta.com/openid-connect/\" target=\"_blank\" rel=\"nofollow\">Okta</a>, for example, is a cloud-hosted enterprise identity platform that supports authentication via OpenID Connect. Several public options are also available, allowing users to authenticate based on their logins for services such as <a href=\"https://developers.google.com/identity/protocols/oauth2/openid-connect\" target=\"_blank\" rel=\"nofollow\">Google</a> and <a href=\"https://developer.paypal.com/docs/connect-with-paypal/\" target=\"_blank\" rel=\"nofollow\">Paypal</a>.If full authentication isn’t needed, TraefikEE also supplies a middleware for verifying the authorization of requests via the <a href=\"https://docs.containo.us/middlewares/oauth-intro/\">OAuth 2.0 token introspection</a> method.</p>\n<!--kg-card-end: markdown--><h2 id=\"authentication-the-easy-way\"><strong>Authentication the easy way</strong></h2><p>The best thing about implementing enterprise authentication using TraefikEE, however, is how easy it is to do. Enabling any of the authentication middleware mentioned here is generally as simple as adding a few lines to your Traefik configuration to supply the necessary credentials and point the middleware to your authentication source.</p><p>The authentication options available in TraefikEE today offer a powerful range of options for exposing enterprise applications and data securely, without requiring extensive and risky legacy code changes. You can expect other such features to be included over time, as we continue our commitment to ensure TraefikEE is a premier tool for enterprise application networking.To learn more about how Traefik and Traefik Enterprise can help you lock down enterprise data with secure authentication, watch our recent webinar, “<a href=\"https://info.containo.us/webinar-recording-enterprise-best-practices-to-expose-and-secure-microservices-apis\">Enterprise best practices to expose and secure microservices and APIs</a>”. We’ll discuss deploying OAuth and OpenID Connect with Okta to secure user logins, and we’ll also walk through enabling mutual TLS (mTLS) for secure machine-to-machine communications.</p>","url":"https://containous.ghost.io/blog/unlock-the-potential-of-data-apis-with-strong-authentication-and-traefik-enterprise/","canonical_url":null,"uuid":"b5745b78-cc68-4b41-ae52-2ec9bec07a62","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f4ee6313a6f7f00398c1198","reading_time":3}},{"node":{"id":"Ghost__Post__5f1f5d0faf4f3b0045f36388","title":"Traefik 2.3: Towards Plugins and Beyond!","slug":"traefik-plugins-pilot","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/08/Blog@1x-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/bcd2c09a2eb9c87798dde34e7c3139a7/47498/Blog%401x-1.jpg","srcSet":"/static/bcd2c09a2eb9c87798dde34e7c3139a7/9dc27/Blog%401x-1.jpg 300w,\n/static/bcd2c09a2eb9c87798dde34e7c3139a7/4fe8c/Blog%401x-1.jpg 600w,\n/static/bcd2c09a2eb9c87798dde34e7c3139a7/47498/Blog%401x-1.jpg 1200w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"In this post, Teddy Ferdinand talks about Traefik 2.3, and its features. He dives into Traefik Pilot, our new SaaS control platform, and the middleware plugin management. ","custom_excerpt":"In this post, Teddy Ferdinand talks about Traefik 2.3, and its features. He dives into Traefik Pilot, our new SaaS control platform, and the middleware plugin management. ","visibility":"public","created_at_pretty":"27 July, 2020","published_at_pretty":"August 4, 2020","updated_at_pretty":"25 August, 2020","created_at":"2020-07-27T23:02:39.000+00:00","published_at":"2020-08-04T14:30:00.000+00:00","updated_at":"2020-08-25T14:37:55.000+00:00","meta_title":"Traefik 2.3: Towards Plugins and Beyond!","meta_description":"In this post, Teddy Ferdinand talks about Traefik 2.3, and its features. He dives into Traefik Pilot, our new SaaS control platform, and middlewares.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/08/Twitter@2x.jpg","twitter_title":null,"authors":[{"name":"Teddy Ferdinand","slug":"tferdinand","bio":"Cloud Security Architect at WeScale, Cloud experts in France. I'm a former Ops,  self-taught, and passionate by containers and automatation. I think that knowledge is a wealth that must be shared.","profile_image":"https://containous.ghost.io/content/images/2020/07/portrait.png","twitter":"@TeddyFERDINAND1","facebook":null,"website":"https://tferdinand.net/en/"}],"primary_author":{"name":"Teddy Ferdinand","slug":"tferdinand","bio":"Cloud Security Architect at WeScale, Cloud experts in France. I'm a former Ops,  self-taught, and passionate by containers and automatation. I think that knowledge is a wealth that must be shared.","profile_image":"https://containous.ghost.io/content/images/2020/07/portrait.png","twitter":"@TeddyFERDINAND1","facebook":null,"website":"https://tferdinand.net/en/"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#community-related-resource","slug":"hash-community-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"},{"name":"#traefik-related-resource","slug":"hash-traefik-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"},{"name":"#pilot-related-resource","slug":"hash-pilot-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"Traefik 2.3 (codename: Picodon - the cheese you can see illustrated below) and\nis available as a release candidate since mid-July 2020. More than a simple\nversion increment, this release brings a lot of new features. Two significant\nnew features caught my attention:\n\n * Introduction of Traefik Pilot\n   [/blog/introducing-traefik-pilot-a-first-look-at-our-new-saas-control-platform-for-traefik/]\n   : a new SaaS platform\n * Middleware plugin management\n\nThere are other new features that I won't cover in this post, such as\ncompatibility with ECS, but be sure to check out my blog\n[https://tferdinand.net/en/], I'll be posting an article on that soon.\n\nPicodonIs there a pilot in the plane?\nTraefik is a complete and powerful reverse proxy, as I already presented in a \nprevious article\n[https://tferdinand.net/en/traefik-2-reverse-proxy-in-kubernetes/].\nNevertheless, it lacked a managed health check solution.\n\nIt is now possible for free! The new service was launched in conjunction with\nthe Traefik 2.3 release candidate.\n\nTraefik Pilot is a new concept, delivering an entirely new approach to network\nmanagement in the cloud. At the moment, it only facilitates the health check of\nyour Traefik instances, allowing you to receive a notification if it becomes\nunavailable or unhealthy. Traefik Pilot is available now at pilot.traefik.io\n[https://pilot.traefik.io/]. Additional features are planned and will launch in\nthe coming months!\n\nAfter a quick sign-up, it is now possible to register one or more instances of\nTraefik.\n\nI added the command line parameter in the Traefik startup arguments in my\nKubernetes manifest, and after a reboot, the status changed to Green (OK).\n\nHowever, there are a few things to keep in mind:\n\n * This status currently only corresponds to your Traefik container's state and\n   does not mean that the backends are functional.\n * This health check is sent from your instance, in \"heartbeat\" mode, and does\n   not necessarily mean that your server is reachable.\n * As the signal transmitted is a heartbeat, it is possible to monitor instances\n   in the Pilot application area.\n\nBy clicking on your profile name at the top right, it is possible to define\nalarms, via webhooks or by e-mail.\n\nIt is worth noting that it is possible to indicate you wish to receive security\nalarms linked to the discovery of possible CVE that corresponds to your version\nof Traefik.\n\nWarm up the plugins\nFor many years I've been using the ubiquitous Apache HTTP web server.\nUndoubtedly, one of the enormous strengths of this product is its modularity,\nallowing the community to extend its functionality.\n\nTraefik now allows the use of plugins as well. The list is currently rather\nsmall, but I do not doubt that the catalog will snowball as the community begins\npublishing its creations!\n\nIt is possible to contribute plugins written in Go by following the guide\nprovided by Containous [https://github.com/containous/plugindemo].\n\n\nFor this article, I chose the \"Block Path\" plugin written by Containous\n[https://github.com/containous/plugin-blockpath]. This plugin allows us to block\naccess to individual pages based on regular expressions dynamically.\n\nBlocked pages will directly return a 403 (Forbidden) error.\n\nThe interest of this kind of plugins, already existing in most reverse proxies,\nis to be able to intercept access to individual pages and prevent the backend\nfrom receiving the request.\n\nThis type of middleware enables operators:\n\n * To not generate a load (for example, in the case of an admin page that could\n   be brute-forced/DDOS).\n * To avoid exposing an undiscovered zero-day flaw, since the backend does not\n   receive any requests.\n\nInstall the Plugin\nPlugins load via the static configuration\n[https://docs.traefik.io/v1.7/basics/#static-traefik-configuration] of Traefik.\nFor this part, I loaded it via the command line parameters, since this is how I\napproach loading my entire configuration in Kubernetes.\n\nargs:\n  - --providers.kubernetescrd\n  - --accesslog=true\n  - --accesslog.filepath=/var/log/traefik/access.log\n  - --accesslog.fields.headers.defaultmode=keep\n  - --entrypoints.web.address=:80\n  - --entrypoints.websecure.address=:443\n  - --certificatesresolvers.le.acme.email=myawesomemail@mail.com\n  - --certificatesresolvers.le.acme.storage=/cert/acme.json\n  - --certificatesResolvers.le.acme.httpChallenge.entryPoint=web\n  - --experimental.pilot.token=mytoken\n  - --experimental.plugins.demo.moduleName=github.com/containous/plugin-blockpath\n  - --experimental.plugins.demo.version=v0.1.2\n\nAs you can see above, declaring the plugins is manageable via the \nexperimental.plugins arguments.\n\nIn my command line example, \"demo\" is the name I gave to the plugin before\nmoduleName. Thus, it contains the path to the GitHub repository containing the\nplugin, version being the Git version to checkout.\n\nOnce this configuration is in place, it is necessary to restart Traefik.\n\nConfiguring the plugin\nThe plugin then behaves like a traditional middleware; which I explain in my\nprevious article on Traefik TLS configuration, middlewares are components that\nexist between Traefik and your backend and modify the normal behavior. For\nexample, in the article mentioned above, the middleware I used allows you to\ndefine the necessary security headers for ranking A+ on SSL Labs.\n\nThe plugin then behaves like a traditional middleware; which I explain in my \nprevious article on Traefik TLS configuration\n[https://tferdinand.net/en/traefik-2-tls-configuration/], middlewares are\ncomponents that exist between Traefik and your backend and modify the normal\nbehavior. For example, in the article mentioned above, the middleware I used\nallows you to define the necessary security headers for ranking A+ on SSL Labs.\n\nFor this example, I have declared a new middleware for use by Traefik in\nKubernetes:\n\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: demo\nspec:\n  plugin:\n    demo:\n      regex: [\"^/demo-[a-z]{1,5}\"]\n\nConfiguring the plugin declared in the command line arguments requires\nreferencing it in the manifest above in the metadata.name field. In the spec \nfield, we can now configure the plugin according to the schema defined in the\nplugin's documentation. In the example above, I've used regex to indicate that\nTraefik should block any request whose path starts with \"/demo-\" with 1 to 5\nlowercase letters.\n\nLoad middleware\nNow that I have defined my middleware, I have to load it into my IngressRoute.\n\nI modify my IngressRoute by declaring it should load this middleware too. As a\nreminder, you can define multiple middlewares on your IngressRoutes, which will\nexecute in the order specified.\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-web-ui-tls\n  namespace: default\nspec:\n  entryPoints:\n    - websecure\n  routes:\n  - kind: Rule\n    priority: 1\n    match: (Host(`www.tferdinand.net`) || Host(`tferdinand.net`)) && PathPrefix(`/`)\n    services:\n    - name: ghost-tfe-fr\n      port: 2368\n      helthcheck:\n        path: /\n        host: tferdinand.net\n        intervalSeconds: 10\n        timeoutSeconds: 5\n    middlewares:\n      - name: security\n      - name: demo\n  tls:\n    certResolver: le\n    options:\n      name: mytlsoption\n      namespace: default\n\n\nAs you can see in spec.routes[0].middlewares, I've added a reference to the demo \nmiddleware that I installed and configured in the previous steps.\n\nLet's test the plugin\nNow, it's time to test my plugin configuration.\n\nYes, I also use Windows, and I assume it ;)\n\nAs you can see, the behavior we anticipated is present. Legitimate queries work\nas expected, and Traefik is blocking the requests which match the schema defined\nin the demo plugin configuration before ever reaching the backend service.\n\nIn conclusion: A small step for Containous, a big step for the community.\nTraefik Plugins and Traefik Pilot are technology previews and only scratch the\nsurface of their true potential; however, this open modularity will enable the\ncommunity to extend the core features of Traefik without the necessity of custom\nforks or compiled code.\n\nTraefik Pilot and Plugins will potentially allow companies to develop plugins on\ntheir own and thus adapt Traefik to their needs.\n\nTraefik Pilot is an excellent initiative, and I can't wait to see how Containous\nwill take-off with these new features! \n\nUseful links\n * Get started with Pilot › [https://pilot.traefik.io/]\n * Pilot documentation [https://docs.traefik.io/v2.3/plugins/overview/]\n * Traefik [/traefik/]\n * Community forum [https://community.containo.us/c/traefik/5]\n\nAuthor's Bio\nTeddy [https://twitter.com/TeddyFERDINAND1] is a Cloud Security Architect at\nWeScale, an organization made up of cloud experts. He's former Ops, self-taught,\nand is passionate about containers and automation. He believes that knowledge is\nwealth that must be shared.","html":"<figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/08/Blog@1x.jpg\" class=\"kg-image\" alt srcset=\"https://containous.ghost.io/content/images/size/w600/2020/08/Blog@1x.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/08/Blog@1x.jpg 1000w, https://containous.ghost.io/content/images/2020/08/Blog@1x.jpg 1200w\" sizes=\"(min-width: 1200px) 1200px\"></figure><p>Traefik 2.3 (codename: Picodon - the cheese you can see illustrated below) and is available as a release candidate since mid-July 2020. More than a simple version increment, this release brings a lot of new features. Two significant new features caught my attention:</p><ul><li>Introduction of <a href=\"https://containous.ghost.io/blog/introducing-traefik-pilot-a-first-look-at-our-new-saas-control-platform-for-traefik/\">Traefik Pilot</a>: a new SaaS platform</li><li>Middleware plugin management</li></ul><!--kg-card-begin: markdown--><p>There are other new features that I won't cover in this post, such as compatibility with ECS, but be sure to check out <a href=\"https://tferdinand.net/en/\" target=\"_blank\" rel=\"nofollow\">my blog</a>, I'll be posting an article on that soon.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/07/picodon.jpeg\" class=\"kg-image\" alt=\"Credit: https://fr.wikipedia.org/wiki/Picodon\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/07/picodon.jpeg 600w, https://containous.ghost.io/content/images/2020/07/picodon.jpeg 700w\"><figcaption>Picodon</figcaption></figure><h2 id=\"is-there-a-pilot-in-the-plane\"><strong>Is there a pilot in the plane?</strong></h2><!--kg-card-begin: markdown--><p>Traefik is a complete and powerful reverse proxy, as I already presented in a <a href=\"https://tferdinand.net/en/traefik-2-reverse-proxy-in-kubernetes/\" target=\"_blank\">previous article</a>. Nevertheless, it lacked a managed health check solution.</p>\n<!--kg-card-end: markdown--><p>It is now possible for free! The new service was launched in conjunction with the Traefik 2.3 release candidate.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/07/Blog@1x-1.png\" class=\"kg-image\" alt srcset=\"https://containous.ghost.io/content/images/size/w600/2020/07/Blog@1x-1.png 600w, https://containous.ghost.io/content/images/size/w1000/2020/07/Blog@1x-1.png 1000w, https://containous.ghost.io/content/images/2020/07/Blog@1x-1.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Traefik Pilot is a new concept, delivering an entirely new approach to network management in the cloud. At the moment, it only facilitates the health check of your Traefik instances, allowing you to receive a notification if it becomes unavailable or unhealthy. Traefik Pilot is available now at <a href=\"https://pilot.traefik.io/\">pilot.traefik.io</a>. Additional features are planned and will launch in the coming months!</p><p>After a quick sign-up, it is now possible to register one or more instances of Traefik.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://lh3.googleusercontent.com/z6Z52Ixrg3i3IOK0enPGeICQHWk7LVud62tda2goLUx_aHBYmIfO5YuaddKj-IXC28SIpZMkDc5i4F6R1clLQdL39j2z_xog2llgcbnkHnc3HrSEk-sP6NoQfBE6IgKuyZ3Nv85V\" class=\"kg-image\" alt></figure><p>I added the command line parameter in the Traefik startup arguments in my Kubernetes manifest, and after a reboot, the status changed to Green (OK).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://lh3.googleusercontent.com/Af6WNGucCMKrTTea7SOK4wU0AXfIhm1hvrWiK06FmFBbZThMMoDToRz3l6AOHLIeWyQQLzSJ8xH3yWWtqwwVXbB3nuTdnK3YEym8TZM0NYLkmtryauJe7F06_PqJCzGTlZOP-cgQ\" class=\"kg-image\" alt></figure><p>However, there are a few things to keep in mind:</p><ul><li>This status currently only corresponds to your Traefik container's state and does not mean that the backends are functional.</li><li>This health check is sent from your instance, in \"heartbeat\" mode, and does not necessarily mean that your server is reachable.</li><li>As the signal transmitted is a heartbeat, it is possible to monitor instances in the Pilot application area.</li></ul><p>By clicking on your profile name at the top right, it is possible to define alarms, via webhooks or by e-mail.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://lh3.googleusercontent.com/mIpE_f8Is091urCMzXAkgCrrCJARJScSjDRF9LmemzbNfmiEW_DYxPXXdL-6Fc3xYp3OAC3q-Ir04Mbn89CFjLykbenlZaB9FdgzNmiXCFt2DbPzwSR4-Aq5epjCZpLx69zNP4zg\" class=\"kg-image\" alt></figure><p>It is worth noting that it is possible to indicate you wish to receive security alarms linked to the discovery of possible CVE that corresponds to your version of Traefik.</p><h2 id=\"warm-up-the-plugins\"><strong>Warm up the plugins</strong></h2><p>For many years I've been using the ubiquitous Apache HTTP web server. Undoubtedly, one of the enormous strengths of this product is its modularity, allowing the community to extend its functionality.</p><p>Traefik now allows the use of plugins as well. The list is currently rather small, but I do not doubt that the catalog will snowball as the community begins publishing its creations!</p><figure class=\"kg-card kg-image-card\"><img src=\"https://lh3.googleusercontent.com/R5F_9k2vb-vT_4BTOh1_q0cUn8vfnJNRPgiKjTUi8-UazGQk6EBXA-Rxq9ILZlXQE-dPdUmU4WXIMNadjXcT1qxAsXX21vyY-4gX5SEwxHX6JDZltW4u6Cah9BGRXItAo9_IfrbD\" class=\"kg-image\" alt></figure><p>It is possible to contribute plugins written in Go by following <a href=\"https://github.com/containous/plugindemo\">the guide provided by Containous</a>.<br></p><p>For this article, I chose the <a href=\"https://github.com/containous/plugin-blockpath\">\"Block Path\" plugin written by Containous</a>. This plugin allows us to block access to individual pages based on regular expressions dynamically.</p><p>Blocked pages will directly return a 403 (Forbidden) error.</p><p>The interest of this kind of plugins, already existing in most reverse proxies, is to be able to intercept access to individual pages and prevent the backend from receiving the request.</p><p>This type of middleware enables operators:</p><ul><li>To not generate a load (for example, in the case of an admin page that could be brute-forced/DDOS).</li><li>To avoid exposing an undiscovered zero-day flaw, since the backend does not receive any requests.</li></ul><h3 id=\"install-the-plugin\"><strong>Install the Plugin</strong></h3><p>Plugins load via <a href=\"https://docs.traefik.io/v1.7/basics/#static-traefik-configuration\">the static configuration</a> of Traefik. For this part, I loaded it via the command line parameters, since this is how I approach loading my entire configuration in Kubernetes.</p><pre><code class=\"language-yaml\">args:\n  - --providers.kubernetescrd\n  - --accesslog=true\n  - --accesslog.filepath=/var/log/traefik/access.log\n  - --accesslog.fields.headers.defaultmode=keep\n  - --entrypoints.web.address=:80\n  - --entrypoints.websecure.address=:443\n  - --certificatesresolvers.le.acme.email=myawesomemail@mail.com\n  - --certificatesresolvers.le.acme.storage=/cert/acme.json\n  - --certificatesResolvers.le.acme.httpChallenge.entryPoint=web\n  - --experimental.pilot.token=mytoken\n  - --experimental.plugins.demo.moduleName=github.com/containous/plugin-blockpath\n  - --experimental.plugins.demo.version=v0.1.2</code></pre><p>As you can see above, declaring the plugins is manageable via the <code>experimental.plugins</code> arguments.</p><p>In my command line example, \"demo\" is the name I gave to the plugin before moduleName. Thus, it contains the path to the GitHub repository containing the plugin, version being the Git version to checkout.</p><p>Once this configuration is in place, it is necessary to restart Traefik.</p><h3 id=\"configuring-the-plugin\"><strong>Configuring the plugin</strong></h3><!--kg-card-begin: markdown--><p>The plugin then behaves like a traditional middleware; which I explain in my previous article on Traefik TLS configuration, middlewares are components that exist between Traefik and your backend and modify the normal behavior. For example, in the article mentioned above, the middleware I used allows you to define the necessary security headers for ranking A+ on SSL Labs.</p>\n<!--kg-card-end: markdown--><p>The plugin then behaves like a traditional middleware; which I explain in my <a href=\"https://tferdinand.net/en/traefik-2-tls-configuration/\">previous article on Traefik TLS configuration</a>, middlewares are components that exist between Traefik and your backend and modify the normal behavior. For example, in the article mentioned above, the middleware I used allows you to define the necessary security headers for ranking A+ on SSL Labs.</p><p>For this example, I have declared a new middleware for use by Traefik in Kubernetes:</p><pre><code class=\"language-yaml\">apiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: demo\nspec:\n  plugin:\n    demo:\n      regex: [\"^/demo-[a-z]{1,5}\"]</code></pre><p>Configuring the plugin declared in the command line arguments requires referencing it in the manifest above in the <code>metadata.name</code> field. In the <code>spec</code> field, we can now configure the plugin according to the schema defined in the plugin's documentation. In the example above, I've used regex to indicate that Traefik should block any request whose path starts with \"/demo-\" with 1 to 5 lowercase letters.</p><h3 id=\"load-middleware\"><strong>Load middleware</strong></h3><p>Now that I have defined my middleware, I have to load it into my IngressRoute.</p><p>I modify my IngressRoute by declaring it should load this middleware too. As a reminder, you can define multiple middlewares on your IngressRoutes, which will execute in the order specified.</p><pre><code class=\"language-yaml\">apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: traefik-web-ui-tls\n  namespace: default\nspec:\n  entryPoints:\n    - websecure\n  routes:\n  - kind: Rule\n    priority: 1\n    match: (Host(`www.tferdinand.net`) || Host(`tferdinand.net`)) &amp;&amp; PathPrefix(`/`)\n    services:\n    - name: ghost-tfe-fr\n      port: 2368\n      helthcheck:\n        path: /\n        host: tferdinand.net\n        intervalSeconds: 10\n        timeoutSeconds: 5\n    middlewares:\n      - name: security\n      - name: demo\n  tls:\n    certResolver: le\n    options:\n      name: mytlsoption\n      namespace: default\n</code></pre><p>As you can see in <code>spec.routes[0].middlewares</code>, I've added a reference to the <code>demo</code> middleware that I installed and configured in the previous steps.</p><h3 id=\"let-s-test-the-plugin\"><strong>Let's test the plugin</strong></h3><p>Now, it's time to test my plugin configuration.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://lh4.googleusercontent.com/q752UlNP9VLB7Quofs1dfL6MWZIoqLSTopZbxsASgxu2nhJsLpwo_h0ldRuYhbq4_d4m6pq-uiJHDJyqwqnd7X3ZeT9c2-2qd1PnOfItAUmfXoL17ooOXrm7Q6OAQ-13ezfikOHc\" class=\"kg-image\" alt></figure><p>Yes, I also use Windows, and I assume it ;)</p><p>As you can see, the behavior we anticipated is present. Legitimate queries work as expected, and Traefik is blocking the requests which match the schema defined in the demo plugin configuration before ever reaching the backend service.</p><h2 id=\"in-conclusion-a-small-step-for-containous-a-big-step-for-the-community-\"><strong>In conclusion: A small step for Containous, a big step for the community.</strong></h2><p>Traefik Plugins and Traefik Pilot are technology previews and only scratch the surface of their true potential; however, this open modularity will enable the community to extend the core features of Traefik without the necessity of custom forks or compiled code.</p><p>Traefik Pilot and Plugins will potentially allow companies to develop plugins on their own and thus adapt Traefik to their needs.</p><p>Traefik Pilot is an excellent initiative, and I can't wait to see how Containous will take-off with these new features! </p><h2 id=\"useful-links\">Useful links</h2><ul><li><a href=\"https://pilot.traefik.io/\">Get started with Pilot ›</a></li><li><a href=\"https://docs.traefik.io/v2.3/plugins/overview/\">Pilot documentation</a></li><li><a href=\"https://containous.ghost.io/traefik/\">Traefik</a></li><li><a href=\"https://community.containo.us/c/traefik/5\">Community forum</a></li></ul><h3 id=\"author-s-bio\">Author's Bio</h3><!--kg-card-begin: markdown--><p><a href=\"https://twitter.com/TeddyFERDINAND1\" target=\"_blank\" rel=\"nofollow\">Teddy</a> is a Cloud Security Architect at WeScale, an organization made up of cloud experts. He's former Ops, self-taught, and is passionate about containers and automation. He believes that knowledge is wealth that must be shared.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/traefik-plugins-pilot/","canonical_url":null,"uuid":"8f55b279-8cc8-4932-aa5b-fffc61d38439","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5f1f5d0faf4f3b0045f36388","reading_time":6}},{"node":{"id":"Ghost__Post__5efb70c61555240039b0bf3d","title":"Do Machines Learn? Testing in Production with Traefik","slug":"do-machines-learn-testing-in-production-with-traefik","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/1a0b7b5f2141923692e66f755823a69d/47498/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg","srcSet":"/static/1a0b7b5f2141923692e66f755823a69d/9dc27/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg 300w,\n/static/1a0b7b5f2141923692e66f755823a69d/4fe8c/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg 600w,\n/static/1a0b7b5f2141923692e66f755823a69d/47498/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg 1200w,\n/static/1a0b7b5f2141923692e66f755823a69d/52258/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg 1800w,\n/static/1a0b7b5f2141923692e66f755823a69d/a41d1/Do-Machines-Learn--Testing-in-Production-with-Traefik-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Here is the story about the personalization of a large-scale book reading service and building the infrastructure to evaluate new models utilizing Traefik.","custom_excerpt":"Here is the story about the personalization of a large-scale book reading service and building the infrastructure to evaluate new models utilizing Traefik.","visibility":"public","created_at_pretty":"30 June, 2020","published_at_pretty":"July 28, 2020","updated_at_pretty":"25 August, 2020","created_at":"2020-06-30T17:05:10.000+00:00","published_at":"2020-07-28T14:30:00.000+00:00","updated_at":"2020-08-25T22:48:13.000+00:00","meta_title":"Do Machines Learn? Testing in Production with Traefik","meta_description":"Here is the story about the personalization of a large-scale book reading service and building the infrastructure to evaluate new models utilizing Traefik.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik-Twitter.png","twitter_title":null,"authors":[{"name":"Alexander Dmitriev","slug":"datahoarder","bio":"I am passionate about recommendation systems and personalization, love to think more about the product than the code, know that weeks of coding saves hours of planning.","profile_image":"https://containous.ghost.io/content/images/2020/06/Screen-Shot-2020-06-20-at-21.27.08.png","twitter":null,"facebook":null,"website":"https://github.com/uSasha"}],"primary_author":{"name":"Alexander Dmitriev","slug":"datahoarder","bio":"I am passionate about recommendation systems and personalization, love to think more about the product than the code, know that weeks of coding saves hours of planning.","profile_image":"https://containous.ghost.io/content/images/2020/06/Screen-Shot-2020-06-20-at-21.27.08.png","twitter":null,"facebook":null,"website":"https://github.com/uSasha"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#community-related-resource","slug":"hash-community-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"Guest post by Alexander Dmitriev, Traefik Ambassador\n\nAnyone who runs machine learning models in production while trying to improve\nmodel performance most likely knows about A/B tests\n[https://en.wikipedia.org/wiki/A/B_testing]. But what if you are the only\nmachine learning engineer on the project? You must automate these tests as much\nas possible. And what if you have to make dozens of iterations per year and\nsometimes deploy new versions several times a week? Here is my story about the\npersonalization of a large-scale book reading service and building the\ninfrastructure to evaluate new models utilizing Traefik.\n\nAbout MyBook\nMyBook [https://mybook.ru/] is a subscription reading service that publishes\nbook apps for multiple platforms while striving to provide the best reading\nexperience for our users. We've collected a huge catalog of books, audiobooks,\nratings, and summaries that are conveniently always in your pocket. Bookmarks\nare synced across all our user’s devices and text-audiobook versions. Avid\nreaders can use a subscription with unlimited reading, and those who want just\none book can rent it for half price. My name is Alexander Dmitriev, and I am a\nmachine learning engineer. My field of interest is personalization: recommender\nsystems [https://en.wikipedia.org/wiki/Recommender_system], user satisfaction\nmeasurement [https://en.wikipedia.org/wiki/Computer_user_satisfaction], and\ninfrastructure for these systems. I love to solve problems end-to-end: discuss\nthe user interface with the product manager, prepare data, train machine\nlearning models, write the service, deploy to production, and support it.\n\nBuilding a Smart(er) Recommendation Engine\nHelping customers find books that are interesting to them is essential for a\nretail service like ours. MyBook already has talented editors curating popular\nbook selections, so the next logical step was adding frequently updated personal\nrecommendations. When I started at MyBook, my goal was to build a recommender\nsystem that discovered and suggested books that a customer might find\ninteresting based on their behaviors. This service is known internally as recsys\n, and I'll be focusing on the evolution, automation, and maturation of that\nsystem in this post.\n\nProduction testing is critical for the development of machine learning systems\nlike recsys. Simulating ephemeral properties such as serendipity, variety, and\nrelevance is not feasible with more traditional approaches to testing such as\nunit or integration methodologies used during software development.\n\nWhen the first version of the recommender service was ready, I added a Flask\nserver, built a Docker container, and deployed it on a newly purchased cloud\nserver. Backend engineers added NGINX as a reverse proxy with SSL support\nbecause it had been used for many years on our production systems. The recsys \napplication Flask port was published to the host, and all requests were\nforwarded.\n\nSo, at first, the architecture looked like this:\n\nThe Growing Pains of Productionized Testing\nWe regularly performed A/B tests where we measured the mean number\n[https://en.wikipedia.org/wiki/Mean] of books our users added to their\nbookshelves during a single session. The end results showed us that personalized\nsets performed 30% better than a fixed set of bestsellers handpicked by our\neditors. Eventually, all new versions of recsys rolled out through the A/B test\nagainst the previous one in production. And it looked something like this:\n\nAs time passed and new services appeared, the situation became messy and\nunmanageable:\n\n * Many of the recsys services ports were hardcoded on the backend\n * Prior to each A/B test the health checks, Prometheus exports, alerting rules,\n   and Grafana dashboards had to be configured by hand\n * This process was required any time a new version of recsys was deployed\n\nAs mentioned before, user tests are must-have in personalization tasks and it's\ncrucial to be able to set up and teardown one as quickly and easily as possible,\notherwise this overhead would have driven our velocity and impact close to zero.\n\nMachine Learning at Scale\nAt this stage, it was clear that a better solution was required. I spent some\ntime researching concepts such as service discovery, canary deployments, and\ncloud-native. Eventually, I discovered Traefik [/traefik/], a nice and easy to\nuse reverse-proxy and load balancer which works natively with Docker containers\nand Docker Swarm.\n\nAfter reading the Traefik documentation [https://docs.traefik.io] I discovered\nthat I would get:\n\n * auto-discovery of new containers\n * health checks and routing only to healthy containers\n * metrics endpoint for Prometheus\n * configuration via Docker labels which means all my infrastructure will be\n   described alongside my deployment manifests, perfect\n * no more exposed ports on my containers, now they are secure and accessible\n   only inside the Docker network\n\nFor a long time, I was curious about the the multi-armed bandit\n[https://en.wikipedia.org/wiki/Multi-armed_bandit] approach for recsys tests.\nThe idea of this approach is to optimize some kind of reward (e.g. user\nsatisfaction) during the constant test with adjustments made on the fly and to\nminimize resources (e.g. user sessions) used during the exploration of new\nchoices (recsys models). It seems perfect if you want to test every small\niteration or even several versions of service at the same time.\n\nI ended up building a couple of different prototypes and came to this solution:\n\nEvery service became a router in Traefik terminology, and each recommender\nengine container became a service [https://docs.traefik.io/routing/services/].\n\nTraefik made it possible to assign multiple Docker services to one routing rule\n[https://docs.traefik.io/routing/routers/] and split traffic between services\nwhile assigning\n[https://docs.traefik.io/routing/services/#weighted-round-robin-service] weights\nto each one. So here is the most interesting part:\n\n * The sum of all weights for different versions of the recsys would always\n   equal 100\n * All new versions were deployed with weight 1, so they received only 1% of\n   user traffic\n * Several times a day Python script recalculated recommender performance\n   metrics for each version of recommender (for simplicity let's say CTR or \n   click-through rate [https://en.wikipedia.org/wiki/Click-through_rate]) and\n   updated weights for models; so better performing ones receive more user\n   requests while others receive less\n\nTesting a new version of the recommender engine is as simple as adding a service\ndefinition to the docker-compose file and updating the stack. Docker Swarm finds\nthe difference between the desired and current state, starts a new Docker\ncontainer with `weight = 1`. Traefik finds this container and, after successful\nhealth checks, routes 1% of requests to the new version, all while exporting the\nmetrics required for monitoring by our automated scripts. After a set amount of\ntime the CTR metrics are recalculated and if users like the new version, it is\nreconfigured to receive a larger share of the traffic, and it is constantly\nbeing reevaluated against new models.\n\nTraefik Helps Me Do What I Love Most\nWe are a small team and I am the only MLE on the project, so I insist on\nresearching and utilizing tools that are easy to use and built with love for the\nend-user. Traefik definitely meets that criteria. Maintenance costs are close to\nzero, and the learning curve is flat. This approach is pretty universal no\nmatter which container orchestrator you use and how you configure Traefik,\nwhether you’re using Kubernetes, Docker labels, Consul, Etcd, or something else.\n\nIn summary, I’d recommend Traefik [/traefik/] to anyone who needs reverse proxy\nwith all necessary features such as service discovery, monitoring, and metrics\nexporting, which is easy to set up and maintain. It saved me a ton of time so\nthat I could now spend fine-tuning algorithms and adding personal ranking to\neditors' handpicked book sets, which help users find the books they like. All\nthis effort yielded book consumption increase by tens of percent.\n\nAuthor's Bio\nAlex Dmitriev is an engineer in embedded electronics and data scientist in\nmetallurgy. Since 2018, he's been a machine learning engineer at MyBook, and is\nfocused on personalization of user experience and infrastructure for ML\nservices.","html":"<p><strong>Guest post by Alexander Dmitriev, Traefik Ambassador</strong></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik.jpg\" class=\"kg-image\" alt=\"Do Machines Learn? Testing in Production with Traefik\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik.jpg 1600w, https://containous.ghost.io/content/images/2020/08/Do-Machines-Learn--Testing-in-Production-with-Traefik.jpg 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><!--kg-card-begin: markdown--><p>Anyone who runs machine learning models in production while trying to improve model performance most likely knows about <a href=\"https://en.wikipedia.org/wiki/A/B_testing\" target=\"_blank\" rel=\"nofollow\">A/B tests</a>. But what if you are the only machine learning engineer on the project? You must automate these tests as much as possible. And what if you have to make dozens of iterations per year and sometimes deploy new versions several times a week? Here is my story about the personalization of a large-scale book reading service and building the infrastructure to evaluate new models utilizing Traefik.</p>\n<!--kg-card-end: markdown--><h2 id=\"about-mybook\">About MyBook</h2><!--kg-card-begin: markdown--><p><a href=\"https://mybook.ru/\" target=\"_blank\" rel=\"nofollow\">MyBook</a> is a subscription reading service that publishes book apps for multiple platforms while striving to provide the best reading experience for our users. We've collected a huge catalog of books, audiobooks, ratings, and summaries that are conveniently always in your pocket. Bookmarks are synced across all our user’s devices and text-audiobook versions. Avid readers can use a subscription with unlimited reading, and those who want just one book can rent it for half price. My name is Alexander Dmitriev, and I am a machine learning engineer. My field of interest is personalization: <a href=\"https://en.wikipedia.org/wiki/Recommender_system\" target=\"_blank\" rel=\"nofollow\">recommender systems</a>, <a href=\"https://en.wikipedia.org/wiki/Computer_user_satisfaction\" target=\"_blank\" rel=\"nofollow\">user satisfaction measurement</a>, and infrastructure for these systems. I love to solve problems end-to-end: discuss the user interface with the product manager, prepare data, train machine learning models, write the service, deploy to production, and support it.</p>\n<!--kg-card-end: markdown--><h2 id=\"building-a-smart-er-recommendation-engine\">Building a Smart(er) Recommendation Engine</h2><p>Helping customers find books that are interesting to them is essential for a retail service like ours. MyBook already has talented editors curating popular book selections, so the next logical step was adding frequently updated personal recommendations. When I started at MyBook, my goal was to build a recommender system that discovered and suggested books that a customer might find interesting based on their behaviors. This service is known internally as <em>recsys</em>, and I'll be focusing on the evolution, automation, and maturation of that system in this post.</p><p>Production testing is critical for the development of machine learning systems like <em>recsys</em>. Simulating ephemeral properties such as serendipity, variety, and relevance is not feasible with more traditional approaches to testing such as unit or integration methodologies used during software development.</p><p>When the first version of the recommender service was ready, I added a Flask server, built a Docker container, and deployed it on a newly purchased cloud server. Backend engineers added NGINX as a reverse proxy with SSL support because it had been used for many years on our production systems. The <em>recsys </em>application Flask port was published to the host, and all requests were forwarded.</p><p>So, at first, the architecture looked like this:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/06/MyBook_Diagram_01@2x.jpg\" class=\"kg-image\" alt=\"Architecture with Nginx as reverse proxy\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/06/MyBook_Diagram_01@2x.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/06/MyBook_Diagram_01@2x.jpg 1000w, https://containous.ghost.io/content/images/2020/06/MyBook_Diagram_01@2x.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"the-growing-pains-of-productionized-testing\">The Growing Pains of Productionized Testing</h2><!--kg-card-begin: markdown--><p>We regularly performed A/B tests where we measured the <a href=\"https://en.wikipedia.org/wiki/Mean\" target=\"_blank\" rel=\"nofollow\">mean number</a> of books our users added to their bookshelves during a single session. The end results showed us that personalized sets performed 30% better than a fixed set of bestsellers handpicked by our editors. Eventually, all new versions of recsys rolled out through the A/B test against the previous one in production. And it looked something like this:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/06/MyBook_Diagram_02@2x.jpg\" class=\"kg-image\" alt=\"Second version of the architecture with Nginx as reverse proxy\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/06/MyBook_Diagram_02@2x.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/06/MyBook_Diagram_02@2x.jpg 1000w, https://containous.ghost.io/content/images/2020/06/MyBook_Diagram_02@2x.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>As time passed and new services appeared, the situation became messy and unmanageable:</p><ul><li>Many of the recsys services ports were hardcoded on the backend</li><li>Prior to each A/B test the health checks, Prometheus exports, alerting rules, and Grafana dashboards had to be configured by hand</li><li>This process was required any time a new version of recsys was deployed</li></ul><p>As mentioned before, user tests are must-have in personalization tasks and it's crucial to be able to set up and teardown one as quickly and easily as possible, otherwise this overhead would have driven our velocity and impact close to zero.</p><h2 id=\"machine-learning-at-scale\">Machine Learning at Scale</h2><p>At this stage, it was clear that a better solution was required. I spent some time researching concepts such as service discovery, canary deployments, and cloud-native. Eventually, I discovered <a href=\"https://containous.ghost.io/traefik/\">Traefik</a>, a nice and easy to use reverse-proxy and load balancer which works natively with Docker containers and Docker Swarm.</p><p>After reading the Traefik <a href=\"https://docs.traefik.io\">documentation</a> I discovered that I would get:</p><ul><li>auto-discovery of new containers</li><li>health checks and routing only to healthy containers</li><li>metrics endpoint for Prometheus</li><li>configuration via Docker labels which means all my infrastructure will be described alongside my deployment manifests, perfect</li><li>no more exposed ports on my containers, now they are secure and accessible only inside the Docker network</li></ul><!--kg-card-begin: markdown--><p>For a long time, I was curious about the <a href=\"https://en.wikipedia.org/wiki/Multi-armed_bandit\" target=\"_blank\" rel=\"nofollow\">the multi-armed bandit</a> approach for recsys tests. The idea of this approach is to optimize some kind of reward (e.g. user satisfaction) during the constant test with adjustments made on the fly and to minimize resources (e.g. user sessions) used during the exploration of new choices (recsys models). It seems perfect if you want to test every small iteration or even several versions of service at the same time.</p>\n<!--kg-card-end: markdown--><p>I ended up building a couple of different prototypes and came to this solution:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2020/06/MyBook_Diagram_03@2x.jpg\" class=\"kg-image\" alt=\"Architecture with Traefik as reverse proxy\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/06/MyBook_Diagram_03@2x.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/06/MyBook_Diagram_03@2x.jpg 1000w, https://containous.ghost.io/content/images/2020/06/MyBook_Diagram_03@2x.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Every service became a router in Traefik terminology, and each recommender engine container became a <a href=\"https://docs.traefik.io/routing/services/\">service</a>.</p><p>Traefik made it possible to assign multiple Docker services to one <a href=\"https://docs.traefik.io/routing/routers/\">routing rule</a> and split traffic between services while <a href=\"https://docs.traefik.io/routing/services/#weighted-round-robin-service\">assigning</a> weights to each one. So here is the most interesting part:</p><!--kg-card-begin: markdown--><ul>\n<li>The sum of all weights for different versions of the recsys would always equal 100</li>\n<li>All new versions were deployed with weight 1, so they received only 1% of user traffic</li>\n<li>Several times a day Python script recalculated recommender performance metrics for each version of recommender (for simplicity let's say CTR or <a href=\"https://en.wikipedia.org/wiki/Click-through_rate\" target=\"_blank\" rel=\"nofollow\">click-through rate</a>) and updated weights for models; so better performing ones receive more user requests while others receive less</li>\n</ul>\n<!--kg-card-end: markdown--><p>Testing a new version of the recommender engine is as simple as adding a service definition to the docker-compose file and updating the stack. Docker Swarm finds the difference between the desired and current state, starts a new Docker container with `weight = 1`. Traefik finds this container and, after successful health checks, routes 1% of requests to the new version, all while exporting the metrics required for monitoring by our automated scripts. After a set amount of time the CTR metrics are recalculated and if users like the new version, it is reconfigured to receive a larger share of the traffic, and it is constantly being reevaluated against new models.</p><h2 id=\"traefik-helps-me-do-what-i-love-most\">Traefik Helps Me Do What I Love Most</h2><p>We are a small team and I am the only MLE on the project, so I insist on researching and utilizing tools that are easy to use and built with love for the end-user. Traefik definitely meets that criteria. Maintenance costs are close to zero, and the learning curve is flat. This approach is pretty universal no matter which container orchestrator you use and how you configure Traefik, whether you’re using Kubernetes, Docker labels, Consul, Etcd, or something else.</p><p>In summary, I’d recommend <a href=\"https://containous.ghost.io/traefik/\">Traefik</a> to anyone who needs reverse proxy with all necessary features such as service discovery, monitoring, and metrics exporting, which is easy to set up and maintain. It saved me a ton of time so that I could now spend fine-tuning algorithms and adding personal ranking to editors' handpicked book sets, which help users find the books they like. All this effort yielded book consumption increase by tens of percent.</p><h3 id=\"author-s-bio\">Author's Bio</h3><p>Alex Dmitriev is an engineer in embedded electronics and data scientist in metallurgy. Since 2018, he's been a machine learning engineer at MyBook, and is focused on personalization of user experience and infrastructure for ML services.</p>","url":"https://containous.ghost.io/blog/do-machines-learn-testing-in-production-with-traefik/","canonical_url":null,"uuid":"6fdd3d47-70da-43f9-bdfb-c7f840c91d02","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5efb70c61555240039b0bf3d","reading_time":5}},{"node":{"id":"Ghost__Post__5ec806bb4e2e9a0045ce791f","title":"Gradual Migration from Traefik 1.x to 2.x","slug":"gradual-migration-from-traefik-1-to-2","featured":false,"feature_image":"https://containous.ghost.io/content/images/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/e5fd74b8a7a81dde1f452bdfb0e1ed83/47498/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg","srcSet":"/static/e5fd74b8a7a81dde1f452bdfb0e1ed83/9dc27/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg 300w,\n/static/e5fd74b8a7a81dde1f452bdfb0e1ed83/4fe8c/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg 600w,\n/static/e5fd74b8a7a81dde1f452bdfb0e1ed83/47498/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg 1200w,\n/static/e5fd74b8a7a81dde1f452bdfb0e1ed83/52258/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg 1800w,\n/static/e5fd74b8a7a81dde1f452bdfb0e1ed83/a41d1/Gradual-Migration-from-Traefik-1.x-to-2.x-1.jpg 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"In this post, I will share a migration strategy that helped me move to Traefik 2 with very little downtime, one service at a time, with an easy way to rollback.","custom_excerpt":"In this post, I will share a migration strategy that helped me move to Traefik 2 with very little downtime, one service at a time, with an easy way to rollback.","visibility":"public","created_at_pretty":"22 May, 2020","published_at_pretty":"June 9, 2020","updated_at_pretty":"25 August, 2020","created_at":"2020-05-22T17:07:07.000+00:00","published_at":"2020-06-09T05:33:17.000+00:00","updated_at":"2020-08-25T22:50:45.000+00:00","meta_title":"Gradual Migration from Traefik 1.x to 2.x","meta_description":"This post shares a migration strategy that helped move to Traefik 2 with very little downtime, one service at a time, with an easy way to rollback.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":"https://containous.ghost.io/content/images/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x-Twitter.png","twitter_title":null,"authors":[{"name":"Juan Carlos Mejías Rodríguez","slug":"greenled","bio":"DevOps engineer and lecturer at the University of Camagüey, Cuba. Specialized on continuous integration, Linux and Docker containers. Developing, deploying and monitoring web applications since 2015.","profile_image":"//www.gravatar.com/avatar/23f5bab61dffbd57974ca32a6d65dba5?s=250&d=mm&r=x","twitter":"@greenled2013","facebook":null,"website":"https://greenled.github.io"}],"primary_author":{"name":"Juan Carlos Mejías Rodríguez","slug":"greenled","bio":"DevOps engineer and lecturer at the University of Camagüey, Cuba. Specialized on continuous integration, Linux and Docker containers. Developing, deploying and monitoring web applications since 2015.","profile_image":"//www.gravatar.com/avatar/23f5bab61dffbd57974ca32a6d65dba5?s=250&d=mm&r=x","twitter":"@greenled2013","facebook":null,"website":"https://greenled.github.io"},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#community-related-resource","slug":"hash-community-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"},{"name":"#traefik-related-resource","slug":"hash-traefik-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"Guest post by Juan Carlos Mejías, Traefik Ambassador\n\nAre you a happy Traefik user? Join the club! I use Traefik as a reverse proxy to\nmanage the ingress of several dozen services in a Docker Swarm cluster, and\ncouldn't be happier with it. Since its introduction in early 2015, Traefik has\ngrown in maturity and popularity (don't take my word, look at the project's\nstargazers over time [https://star-history.t9t.io/#containous/traefik]. When\nTraefik v2 was released I couldn't help but think about migrating, but I had one\nmajor concern: downtime.\n\nTraefik's documentation explains how to migrate configurations from 1.x format\nto 2.x format however, as in any system with some degree of complexity,\nmigrating is not just about changing configurations but managing them. You have\nto make sure everything keeps running smoothly and be prepared to rollback in\ncase something goes wrong -have you heard of Murphy's Law? Also, you probably\ndon't want to migrate the whole system at a time, or you could quickly find\nyourself trying to put out more fires than you can handle.\n\nIn this post, I will share a migration strategy that helped me move to Traefik 2\nwith very little downtime, one service at a time, with an easy way to rollback.\nFor the sake of clarity and brevity, I will start from a single Traefik instance\nwith two backend services and will keep everything in a single Docker Swarm\nstack. The same strategy could be used in a clustered Traefik deployment with\nmany more backend services as well. In fact, this scenario is where Traefik\nshines the brightest.\n\nInitial setup\nLet's start from the following setup, with a Traefik 1 instance as a reverse\nproxy and two Nginx services, all running on Docker Swarm:\n\nInitial setup. Traefik 1 handling all routingThis configuration can be deployed\nto the swarm with the following stack definition:\n\n# docker-compose.yaml\n\n# Version >= 3.3 so configs are available\nversion: \"3.4\"\n\nnetworks:\n  traefik-public:\n    external: true\n\nconfigs:\n  index1:\n    # Contains string \"1\"\n    file: ./index1.html\n  index2:\n    # Contains string \"2\"\n    file: ./index2.html\n\nservices:\n  traefik1:\n    image: traefik:v1.7\n    ports:\n      - \"80:80\"\n    volumes:\n      # So that Traefik can listen to the Docker events\n      - /var/run/docker.sock:/var/run/docker.sock\n    command: >\n      --docker\n      --docker.swarmmode\n      --entrypoints='Name:http Address::80'\n    networks:\n      - traefik-public\n\n  web1:\n    image: nginx:1-alpine\n    deploy:\n      labels:\n        - traefik.enable=true\n        - traefik.frontend.rule=Host:web1.docker.local\n        - traefik.port=80\n        - traefik.webservice.frontend.entryPoints=http\n    configs:\n      - source: index1\n        target: /usr/share/nginx/html/index.html\n    networks:\n      - traefik-public\n\n  web2:\n    image: nginx:1-alpine\n    deploy:\n      labels:\n        - traefik.enable=true\n        - traefik.frontend.rule=Host:web2.docker.local\n        - traefik.port=80\n        - traefik.webservice.frontend.entryPoints=http\n    configs:\n      - source: index2\n        target: /usr/share/nginx/html/index.html\n    networks:\n      - traefik-public\n\n\nFiles index1.html and index1.html contain strings 1 and 2 respectively:\n\necho 1 > index1.html\necho 2 > index2.html\n\n\nWith the above configuration, you can now create a Docker Swarm (if you don't\nalready have one), an overlay network for Traefik and deploy the stack:\n\ndocker swarm init\ndocker network create --driver=overlay traefik-public\ndocker stack deploy -c docker-compose.yaml traefik\n\n\nWhen the stack deployment finishes you will be able to query the defined Nginx\nservices as web1.docker.local and web2.docker.local. In the example below I’m\nusing curl:\n\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 1\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 2\n\n\nIt may take a few seconds to start the containers so if you get a 404 page not\nfound response just wait and try again.\n\nTraefik 2 with fallback to Traefik 1\nYou now have a working Traefik 1.x reverse proxy and two backend services. Let's\nmigrate it to 2.x! Next you are going to add a Traefik 2 service which will run\nalongside and proxy requests to the existing one. Incoming requests will be\nrouted to the Traefik 2 service and if no routes are matched they will then be\nrouted to the Traefik 1 service.\n\nTraefik 2 routing all requests to Traefik 1Deploy these changes to the stack\ndefinition file:\n\n # docker-compose.yaml\n\n ...\n configs:\n   ...\n+  # Dynamic configuration for Traefik 2 (see below)\n+  traefik2-providers:\n+    file: ./traefik2-providers.yaml\n\n services:\n   traefik1:\n     image: traefik:v1.7\n-    ports:\n-      - \"80:80\"\n   ...\n+  traefik2:\n+    image: traefik:v2.1\n+    ports:\n+      # The HTTP port\n+      - \"80:80\"\n+    volumes:\n+      # So that Traefik can listen to the Docker events\n+      - /var/run/docker.sock:/var/run/docker.sock\n+    command: >\n+      --providers.docker\n+      --providers.docker.swarmMode\n+      --providers.file.directory=/etc/traefik\n+      --providers.file.filename=providers.yaml\n+      --entryPoints.http.address=:80\n+      --api.insecure\n+    configs:\n+      - source: traefik2-providers\n+        target: /etc/traefik/providers.yaml\n+    networks:\n+      - traefik-public\n\n\nThe traefik2-providers.yaml file used in the traefik2-providers config directive\nfor the traefik2 service defines a catch-all route that forwards unmatched\nrequests to the traefik1 service:\n\n# traefik2-providers.yaml\n\nhttp:\n  routers:\n    # Define a catch-all router that forwards requests to legacy Traefik\n    to-traefik1:\n      # Catch all domains (regex matches all strings)\n      # See https://github.com/google/re2/wiki/Syntax\n      rule: \"HostRegexp(`{domain:.+}`)\"\n      # If the rule matches, forward to the traefik1 service (see below)\n      service: traefik1\n      # Set the lowest priority, so this route is only used as a last resort\n      priority: 1\n\n  services:\n    # Define how to reach legacy Traefik\n    traefik1:\n      loadBalancer:\n        servers:\n          # Legacy Traefik is part of the same stack so,\n          # hostname defaults to service name\n          - url: http://traefik1\n\n\nRedeploy the stack and check everything is still working as expected:\n\ndocker stack deploy -c docker-compose.yaml traefik\n# ...\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 1\ncurl -H Host:web2.docker.local http://127.0.0.1\n# 2\n\n\nTraefik 2 replacing Traefik 1\nNext let's set up Traefik 2 to handle requests to web1, as in Image 3:\n\nTraefik 2 handling web1 service's routingThis setup can be achieved by updating web1 service labels to match Traefik 2\nformat as follows:\n\n...\nservices:\n  ...\n  web1:\n    ...\n    deploy:\n      labels:\n        - traefik.enable=true\n        - traefik.http.routers.web1.rule=Host(`web1.docker.local`)\n        - traefik.http.services.web1.loadbalancer.server.port=80\n    ...\n\n\nRedeploy the stack and again check everything is still working as expected:\n\ndocker stack deploy -c docker-compose.yaml traefik\n# ...\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 1\ncurl -H Host:web2.docker.local http://127.0.0.1\n# 2\n\n\nNow repeat the process for web2 service. If something goes wrong, you just need\nto revert to a previous working configuration for the affected service,\nredeploy, and start over. In a real-world scenario with lots of services,\nmigration can take place one service at a time like this, reducing downtime.\nWhen you finish migrating to Traefik 2, take down the Traefik 1 service. You\nwill then end up with this scenario:\n\nTraefik 2 handling all routingWrapping Up\nAnd that's it! You’ve successfully migrated from Traefik [/traefik/] 1.x to 2.x\none service at a time. This step by step migration strategy comes from the\nStranglerFigApplication pattern, as described by Martin Fowler\n[https://martinfowler.com/bliki/StranglerFigApplication.html]. As a final note,\nI would highly recommend putting your configurations under version control as\nthat would make it very easy to roll back changes when needed.\n\nAuthor's Bio\nJuan Carlos is a lecturer at the Informatics and Exact Sciences Faculty of the\nUniversity of Camagüey, Cuba, [https://www.reduc.edu.cu/] and also DevOps\nengineer at the same institution. He has specialized on version control,\ncontinuous integration and deployment, Linux, and Docker containers. Since 2015\nhe has developed, deployed and monitored web applications for the University's\nIT infrastructure.","html":"<p><strong>Guest post by Juan Carlos Mejías, Traefik Ambassador</strong></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x.jpg\" class=\"kg-image\" alt=\"Gradual Migration from Traefik 1.x to 2.x\" srcset=\"https://containous.ghost.io/content/images/size/w600/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x.jpg 600w, https://containous.ghost.io/content/images/size/w1000/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x.jpg 1000w, https://containous.ghost.io/content/images/size/w1600/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x.jpg 1600w, https://containous.ghost.io/content/images/2020/08/Gradual-Migration-from-Traefik-1.x-to-2.x.jpg 2400w\" sizes=\"(min-width: 1200px) 1200px\"></figure><!--kg-card-begin: markdown--><p>Are you a happy Traefik user? Join the club! I use Traefik as a reverse proxy to manage the ingress of several dozen services in a Docker Swarm cluster, and couldn't be happier with it. Since its introduction in early 2015, Traefik has grown in maturity and popularity (don't take my word, look at <a href=\"https://star-history.t9t.io/#containous/traefik\" target=\"_blank\" rel=\"nofollow\">the project's stargazers over time</a>. When Traefik v2 was released  I couldn't help but think about migrating, but I had one major concern: downtime.</p>\n<p>Traefik's documentation explains how to migrate configurations from 1.x format to 2.x format however, as in any system with some degree of complexity, migrating is not just about changing configurations but managing them. You have to make sure everything keeps running smoothly and be prepared to rollback in case something goes wrong -have you heard of Murphy's Law? Also, you probably don't want to migrate the whole system at a time, or you could quickly find yourself trying to put out more fires than you can handle.</p>\n<p>In this post, I will share a migration strategy that helped me move to Traefik 2 with very little downtime, one service at a time, with an easy way to rollback. For the sake of clarity and brevity, I will start from a single Traefik instance with two backend services and will keep everything in a single Docker Swarm stack. The same strategy could be used in a clustered Traefik deployment with many more backend services as well. In fact, this scenario is where Traefik shines the brightest.</p>\n<h2 id=\"initialsetup\">Initial setup</h2>\n<p>Let's start from the following setup, with a Traefik 1 instance as a reverse proxy and two Nginx services, all running on Docker Swarm:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/06/1-diagram1-traefik1-handling-all-routing.png\" class=\"kg-image\" alt=\"Initial setup. Traefik 1 handling all routing\"><figcaption>Initial setup. Traefik 1 handling all routing</figcaption></figure><!--kg-card-begin: markdown--><p>This configuration can be deployed to the swarm with the following stack definition:</p>\n<pre><code class=\"language-yaml\"># docker-compose.yaml\n\n# Version &gt;= 3.3 so configs are available\nversion: &quot;3.4&quot;\n\nnetworks:\n  traefik-public:\n    external: true\n\nconfigs:\n  index1:\n    # Contains string &quot;1&quot;\n    file: ./index1.html\n  index2:\n    # Contains string &quot;2&quot;\n    file: ./index2.html\n\nservices:\n  traefik1:\n    image: traefik:v1.7\n    ports:\n      - &quot;80:80&quot;\n    volumes:\n      # So that Traefik can listen to the Docker events\n      - /var/run/docker.sock:/var/run/docker.sock\n    command: &gt;\n      --docker\n      --docker.swarmmode\n      --entrypoints='Name:http Address::80'\n    networks:\n      - traefik-public\n\n  web1:\n    image: nginx:1-alpine\n    deploy:\n      labels:\n        - traefik.enable=true\n        - traefik.frontend.rule=Host:web1.docker.local\n        - traefik.port=80\n        - traefik.webservice.frontend.entryPoints=http\n    configs:\n      - source: index1\n        target: /usr/share/nginx/html/index.html\n    networks:\n      - traefik-public\n\n  web2:\n    image: nginx:1-alpine\n    deploy:\n      labels:\n        - traefik.enable=true\n        - traefik.frontend.rule=Host:web2.docker.local\n        - traefik.port=80\n        - traefik.webservice.frontend.entryPoints=http\n    configs:\n      - source: index2\n        target: /usr/share/nginx/html/index.html\n    networks:\n      - traefik-public\n</code></pre>\n<p>Files <code>index1.html</code> and <code>index1.html</code> contain strings <code>1</code> and <code>2</code> respectively:</p>\n<pre><code class=\"language-bash\">echo 1 &gt; index1.html\necho 2 &gt; index2.html\n</code></pre>\n<p>With the above configuration, you can now create a Docker Swarm (if you don't already have one), an overlay network for Traefik and deploy the stack:</p>\n<pre><code class=\"language-bash\">docker swarm init\ndocker network create --driver=overlay traefik-public\ndocker stack deploy -c docker-compose.yaml traefik\n</code></pre>\n<p>When the stack deployment finishes you will be able to query the defined Nginx services as <code>web1.docker.local</code> and <code>web2.docker.local</code>. In the example below I’m using curl:</p>\n<pre><code class=\"language-bash\">curl -H Host:web1.docker.local http://127.0.0.1\n# 1\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 2\n</code></pre>\n<p>It may take a few seconds to start the containers so if you get a <code>404 page not found</code> response just wait and try again.</p>\n<h2 id=\"traefik2withfallbacktotraefik1\">Traefik 2 with fallback to Traefik 1</h2>\n<p>You now  have a working Traefik 1.x reverse proxy and two backend services. Let's migrate it to 2.x! Next you are going to add a Traefik 2 service which will run alongside and proxy requests to the existing one. Incoming requests will be routed to the Traefik 2 service and if no routes are matched they will then be routed to the  Traefik 1 service.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/06/2-diagram2-traefik2-routing-requests-to-traefik1.png\" class=\"kg-image\" alt=\"Traefik 2 routing all requests to Traefik 1\"><figcaption>Traefik 2 routing all requests to Traefik 1</figcaption></figure><!--kg-card-begin: markdown--><p>Deploy these changes to the stack definition file:</p>\n<pre><code class=\"language-diff\"> # docker-compose.yaml\n\n ...\n configs:\n   ...\n+  # Dynamic configuration for Traefik 2 (see below)\n+  traefik2-providers:\n+    file: ./traefik2-providers.yaml\n\n services:\n   traefik1:\n     image: traefik:v1.7\n-    ports:\n-      - &quot;80:80&quot;\n   ...\n+  traefik2:\n+    image: traefik:v2.1\n+    ports:\n+      # The HTTP port\n+      - &quot;80:80&quot;\n+    volumes:\n+      # So that Traefik can listen to the Docker events\n+      - /var/run/docker.sock:/var/run/docker.sock\n+    command: &gt;\n+      --providers.docker\n+      --providers.docker.swarmMode\n+      --providers.file.directory=/etc/traefik\n+      --providers.file.filename=providers.yaml\n+      --entryPoints.http.address=:80\n+      --api.insecure\n+    configs:\n+      - source: traefik2-providers\n+        target: /etc/traefik/providers.yaml\n+    networks:\n+      - traefik-public\n</code></pre>\n<p>The <code>traefik2-providers.yaml</code> file used in the <code>traefik2-providers</code> config directive for the <code>traefik2</code> service defines a catch-all route that forwards unmatched requests to the <code>traefik1</code> service:</p>\n<pre><code class=\"language-yaml\"># traefik2-providers.yaml\n\nhttp:\n  routers:\n    # Define a catch-all router that forwards requests to legacy Traefik\n    to-traefik1:\n      # Catch all domains (regex matches all strings)\n      # See https://github.com/google/re2/wiki/Syntax\n      rule: &quot;HostRegexp(`{domain:.+}`)&quot;\n      # If the rule matches, forward to the traefik1 service (see below)\n      service: traefik1\n      # Set the lowest priority, so this route is only used as a last resort\n      priority: 1\n\n  services:\n    # Define how to reach legacy Traefik\n    traefik1:\n      loadBalancer:\n        servers:\n          # Legacy Traefik is part of the same stack so,\n          # hostname defaults to service name\n          - url: http://traefik1\n</code></pre>\n<p>Redeploy the stack and check everything is still  working as expected:</p>\n<pre><code class=\"language-bash\">docker stack deploy -c docker-compose.yaml traefik\n# ...\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 1\ncurl -H Host:web2.docker.local http://127.0.0.1\n# 2\n</code></pre>\n<h2 id=\"traefik2replacingtraefik1\">Traefik 2 replacing Traefik 1</h2>\n<p>Next let's set up Traefik 2 to handle requests to <code>web1</code>, as in Image 3:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/06/3-diagram3-traefik2-handling-web1-routing.png\" class=\"kg-image\" alt=\"Traefik 2 handling web1 service's routing\"><figcaption>Traefik 2 handling web1 service's routing</figcaption></figure><!--kg-card-begin: markdown--><p>This setup can be achieved by updating <code>web1</code> service labels to match Traefik 2 format as follows:</p>\n<pre><code class=\"language-yaml\">...\nservices:\n  ...\n  web1:\n    ...\n    deploy:\n      labels:\n        - traefik.enable=true\n        - traefik.http.routers.web1.rule=Host(`web1.docker.local`)\n        - traefik.http.services.web1.loadbalancer.server.port=80\n    ...\n</code></pre>\n<p>Redeploy the stack and again check everything is still working as expected:</p>\n<pre><code class=\"language-bash\">docker stack deploy -c docker-compose.yaml traefik\n# ...\ncurl -H Host:web1.docker.local http://127.0.0.1\n# 1\ncurl -H Host:web2.docker.local http://127.0.0.1\n# 2\n</code></pre>\n<p>Now repeat the process for <code>web2</code> service. If something goes wrong, you just need to revert to a previous working configuration for the affected service, redeploy, and start over. In a real-world scenario with lots of services, migration can take place one service at a time like this, reducing downtime.<br>\nWhen you finish migrating to Traefik 2, take down the Traefik 1 service. You will then end up with this scenario:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://containous.ghost.io/content/images/2020/06/4-diagram4-traefik2-handling-all-routing.png\" class=\"kg-image\" alt=\"Traefik 2 handling all routing\"><figcaption>Traefik 2 handling all routing</figcaption></figure><!--kg-card-begin: markdown--><h2 id=\"wrappingup\">Wrapping Up</h2>\n<p>And that's it! You’ve successfully migrated from <a href=\"https://containous.ghost.io/traefik/\">Traefik</a> 1.x to 2.x one service at a time. This step by step migration strategy comes from the StranglerFigApplication pattern, as <a href=\"https://martinfowler.com/bliki/StranglerFigApplication.html\" target=\"_blank\" rel=\"nofollow\">described by Martin Fowler</a>. As a final note, I would highly recommend putting your configurations under version control as that would make it very easy to roll back changes when needed.</p>\n<h3 id=\"authorsbio\">Author's Bio</h3>\n<p>Juan Carlos is a lecturer at the <a href=\"https://www.reduc.edu.cu/\">Informatics and Exact Sciences Faculty of the University of Camagüey, Cuba,</a> and also DevOps engineer at the same institution. He has specialized on version control, continuous integration and deployment, Linux, and Docker containers. Since 2015 he has developed, deployed and monitored web applications for the University's IT infrastructure.</p>\n<!--kg-card-end: markdown-->","url":"https://containous.ghost.io/blog/gradual-migration-from-traefik-1-to-2/","canonical_url":null,"uuid":"54e054d8-0db0-4a41-9c09-13d3db8daeb1","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ec806bb4e2e9a0045ce791f","reading_time":6}},{"node":{"id":"Ghost__Post__5dcdfa6f2345360038abe218","title":"Traefik 2 & TLS 101","slug":"traefik-2-tls-101-23b4fbee81f1","featured":false,"feature_image":"https://containous.ghost.io/content/images/2019/11/Traefik-2---TLS-101-x-Docker---Blog-Post-@2x-2.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/cc3e270abe4acb548943583a98f72cfb/f3583/Traefik-2---TLS-101-x-Docker---Blog-Post-%402x-2.png","srcSet":"/static/cc3e270abe4acb548943583a98f72cfb/630fb/Traefik-2---TLS-101-x-Docker---Blog-Post-%402x-2.png 300w,\n/static/cc3e270abe4acb548943583a98f72cfb/2a4de/Traefik-2---TLS-101-x-Docker---Blog-Post-%402x-2.png 600w,\n/static/cc3e270abe4acb548943583a98f72cfb/f3583/Traefik-2---TLS-101-x-Docker---Blog-Post-%402x-2.png 1200w,\n/static/cc3e270abe4acb548943583a98f72cfb/bbee5/Traefik-2---TLS-101-x-Docker---Blog-Post-%402x-2.png 1800w,\n/static/cc3e270abe4acb548943583a98f72cfb/ed396/Traefik-2---TLS-101-x-Docker---Blog-Post-%402x-2.png 2000w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"You have an HTTP service exposed through Traefik, and you want Traefik to deal with the HTTPS burden (TLS termination)...","custom_excerpt":"You have an HTTP service exposed through Traefik, and you want Traefik to deal with the HTTPS burden (TLS termination)...","visibility":"public","created_at_pretty":"15 November, 2019","published_at_pretty":"November 14, 2019","updated_at_pretty":"22 May, 2020","created_at":"2019-11-15T01:07:59.000+00:00","published_at":"2019-11-14T08:07:00.000+00:00","updated_at":"2020-05-22T00:43:50.000+00:00","meta_title":"How to configure Traefik 2 with TLS - Traefik 2 & TLS 101","meta_description":"You have an HTTP service exposed through Traefik, and you want Traefik to deal with the HTTPS burden (TLS termination)...","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gerald Croes","slug":"gerald","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/12/ghost.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Gerald Croes","slug":"gerald","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/12/ghost.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"#community-related-resource","slug":"hash-community-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"},{"name":"#traefik-related-resource","slug":"hash-traefik-related-resource","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"internal"}],"plaintext":"HTTPS (& TCP over TLS) for everyone!\n\nThere are hundreds of reasons why I love being a developer (besides memories of\nsleepless nights trying to fix a video game that nobody except myself would ever\nplay).\n\nBeing a developer gives you superpowers — you can solve any kind of problems.\nYes, especially if they don’t involve real-life practical situations.\n\nBut these superpowers are sometimes hindered by tedious configuration work that\nexpects you to master yet another arcane language assembled with heaps of words\nyou’ve never seen before. Such a barrier can be encountered when dealing with\nHTTPS and its certificates.\n\nLuckily for us, Traefik tends to lower this kind of hurdle and makes sure that\nthere are easy ways of securely connecting your developments to the outside\nworld.\n\nThe Goal for Today\nThe challenge we’ll accept is the following — You have an HTTP service exposed\nthrough Traefik, and you want Traefik to deal with the HTTPS burden (TLS\ntermination), leaving your pristine service unspoiled by mundane technical\ndetails.\n\nWe’ll assume you have a basic understanding of Traefik on Docker and that you’re\nfamiliar with its configuration (if not, it’s time to read Traefik 2 & Docker\n101 [/blog/traefik-2-0-docker-101-fc2893944b9d/]).\n\nDuring this article, we’ll use my pet demo docker-compose file: it enables the\ndocker provider and launches a my-app application that allows us to test any\nrequest.\n\nversion: \"3\"\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.web.address=:80\n      - --providers.docker=true\n    ports:\n      - \"80:80\"\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n  \n  my-app:\n    image: containous/whoami:v1.3.0\n\nGetting Things Ready\nFirst things first, let’s make sure our setup can handle HTTPS traffic on the\ndefault port (:443), and that Traefik listens to this port thanks to an \nentrypoint [https://docs.traefik.io/routing/entrypoints/] we’ll name web-secure.\n\nversion: \"3\"\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.web.address=:80\n      - --entrypoints.web-secure.address=:443 #Declares the web-secure entrypoint in Traefik\n      - --providers.docker=true\n    ports:\n      - \"80:80\"\n      - \"443:443\" #Docker sends requests on port 443 to Traefik on port 443\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n  \n  my-app:\n    image: containous/whoami:v1.3.0\n\nTo avoid confusion, let’s state the obvious — We haven’t yet configured anything\nbut enabled requests on 443 to be handled by Traffic. So, no certificate\nmanagement yet!\n\nGeneral Concepts\nUltimately, in Traefik, you configure HTTPS on the router\n[https://docs.traefik.io/routing/routers/] level. While defining routes, you\ndecide whether they are HTTP routes or HTTPS routes (by default, they are HTTP\nroutes).\n\nFirst, let’s expose our my-app service on HTTP so that it handles requests on\ndomain example.com.\n\nversion: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n\nAnd now, see what it takes to make this route HTTPS only!\n\nversion: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n      - \"traefik.http.routers.my-app.tls=true\"\n\nThere, by adding the tls option to the route, we’ve made it HTTPS.\n\nThe only unanswered question left is, “Where does Traefik get its certificates\nfrom?” And the answer is, “Either from a collection of certificates you own and\nhave configured or from a fully automatic mechanism that gets them for you.”\n\nLet’s see these solutions in action!\n\n\n--------------------------------------------------------------------------------\n\nOption 1 — Certificates You Own\nThe least magical of the two options involves creating a configuration file.\n\nSay you already own a certificate for a domain (or a collection of certificates\nfor different domains) and that you are then the proud holder of files to claim\nyour ownership of the said domain.\n\nTo have Traefik make a claim on your behalf, you’ll have to give it access to\nthe certificate files. Let’s do this.\n\nAdd a Configuration File for Certificates\n\nversion: \"3\"\n\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.web.address=:80\n      - --entrypoints.web-secure.address=:443\n      - --providers.docker=true\n      - --providers.file.directory=/configuration/\n      - --providers.file.watch=true\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n      - \"/home/username/traefik/configuration/:/configuration/\"\n\nTraefik runs with many providers beyond Docker (i.e., Kubernetes\n[https://docs.traefik.io/providers/kubernetes-crd/], Rancher\n[https://docs.traefik.io/providers/rancher/], Marathon\n[https://docs.traefik.io/providers/marathon/]), and here we chose to add plain\nold configuration files (--providers.file) in the configuration/ directory (and\nwe’ll automatically reload changes with --providers.file.watch=true). We’ll use\na configuration file to declare our certificates.\n\nAdd the Certificates to the Configuration File\n# in files/certificates.toml\n\n[[tls.certificates]] #first certificate\n   certFile = “/path/to/example-com.cert” \n   keyFile = “/path/to/example-com.key”\n\n[[tls.certificates]] #second certificate\n   certFile = “/path/to/other.cert” \n   keyFile = “/path/to/other.key”\n   \n# and so on\n\nNow that we have our TOML configuration file available (thanks to the enabled\nfile provider), we can fill in certificates in the [[tls.certificates]]section.\n\nEnjoy!\nThis is all there is to do. When dealing with an HTTPS route, Traefik goes\nthrough your default certificate store to find a matching certificate.\n\nSpecifying a Default Certificate?\nIf no valid certificate is found, Traefik serves a default auto-signed\ncertificate. But if needed, you can customize the default certificate like so:\n\n[tls.stores]\n  [tls.stores.default]\n   [tls.stores.default.defaultCertificate] \n     certFile = “path/to/cert.crt” \n     keyFile = “path/to/cert.key”\n\nAdditional Thoughts\nEven though the configuration is straightforward, it is your responsibility, as\nthe administrator, to configure / renew your certificates when they expire. If\nyou don’t like such constraints, keep reading!\n\n\n--------------------------------------------------------------------------------\n\nOption 2 — Dynamic / Automatic Certificates\nHaving to manage (buy/install/renew) your certificates is a process you might \nnot enjoy (I don’t). If so, you’ll be interested in the automatic certificate\ngeneration embedded in Traefik (thanks to Let’s Encrypt).\n\nLong story short, you can start Traefik with no other configuration than your\nLet’s Encrypt account, and Traefik automatically negotiates\n(get/renew/configure) certificates for you — No extra step.\n\nCertificate Resolvers\nWe saw that you can configure a router to use TLS\n(--traefik.http.routers.router-name.tls=true). \nAs a consequence, we saw that Traefik would go through your certificate list to\nfind a suitable match for the domain at hand (and if not would use a default\ncertificate).\n\nFor automatic certificate generation, you can add a certificate resolver to your\nTLS options. A certificate resolver is responsible for retrieving certificates.\n\nHere, let’s define a certificate resolver that works with your Let’s Encrypt\naccount!\n\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.websecure.address=:443\n      # ...\n      - --certificatesresolvers.le.acme.email=my@email.com\n      - --certificatesresolvers.le.acme.storage=/acme.json\n      - --certificatesresolvers.le.acme.tlschallenge=true\n      # ...\n\nAs you can read, we defined a certificate resolver named le of type acme. Then,\nwe provided an email (your Let’s Encrypt account), the storage file (for\ncertificates it retrieves), and the challenge for certificate negotiation\n[https://docs.traefik.io/https/acme/#the-different-acme-challenges](here \ntlschallenge, just because it’s the most concise configuration option for the\nsake of the example).\n\nFrom now on, Traefik is fully equipped to generate certificates for you!\n\nUsing the Certificate Resolver\nIf you remember correctly (I’m sure you do!), we enabled TLS on our router like\nso:\n\nversion: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n      - \"traefik.http.routers.my-app.tls=true\"\n\nNow, to enable our certificate resolver and have it automatically generate\ncertificates (when needed), we’ll add it to the TLS configuration, like so:\n\nversion: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n      - \"traefik.http.routers.my-app.tls=true\"\n      - \"traefik.http.routers.my-app.tls.certresolver=le\"\n\nNow, if your certificate store doesn’t yet have a valid certificate for \nexample.com, the le certificate resolver will transparently negotiate one for\nyou — it’s that simple.\n\nMultiple Certificate Resolvers?\nWith certificate resolvers, you can configure different challenges.\n\nBelow is an example that shows how to configure two CertResolvers that leverage\nLet’s Encrypt, one using the dnsChallenge\n[https://docs.traefik.io/https/acme/#dnschallenge], the other using the \ntlsChallenge [https://docs.traefik.io/https/acme/#tlschallenge].\n\n[certificatesResolvers.resolver-digital-ocean.acme]\n  # ... \n  [certificatesResolvers.resolver-digital-ocean.acme.dnsChallenge]\n    provider = \"digitalocean\"\n    delayBeforeCheck = 0\n\n[certificatesResolvers.tls-challenge-resolver.acme]\n  # ...\n  [certificatesResolvers.tls-challenge-resolver.acme.tlsChallenge]\n\nLater on, you’ll be able to use one or the other on your routers.\n\n# in routers.toml\n\n[http.routers]\n  [http.routers.https-route]\n    rule = \"Host(`my.domain`)\"\n    [http.routers.https-route.tls]\n      certResolver = \"resolver-digital-ocean\"\n\n[http.routers.https-route-2]\n    rule = \"Host(`other.domain`)\"\n    [http.routers.https-route-2.tls]\n      certResolver = \"tls-challenge-resolver\"\n\nIn the above example (that uses the file provider), we’ve asked Traefik to\ngenerate certificates for my.domain using the dnsChallenge (with digital ocean)\nand to generate certificates for other.domain using the TLSChallenge.\n\nAnd you’ve guessed it already — Traefik supports DNS challenge for different DNS\nproviders, at the same time!\n\n\n\n--------------------------------------------------------------------------------\n\nWildcard and Let’s Encrypt?\nInstead of generating a certificate for each subdomain, you can choose to\ngenerate wildcard certificates!\n\n[http.routers]\n  [http.routers.router-example]\n    rule = \"Host(`something.my.domain`)\"\n    [http.routers.router-example.tls]\n      certResolver = \"my-resolver\"\n      [[http.routers.router-example.tls.domains]]\n        main = \"my.domain\"\n        sans = \"*.my.domain\"\n\nIn the above example, we’ve configured Traefik to generate a wildcard\ncertificate for *.my.domain.\n\nIf we had omitted the .tls.domains section, Traefik would have used the host\n(here something.my.domain) defined in the Host rule to generate a certificate.\n\n\n--------------------------------------------------------------------------------\n\nWhat About TCP & TLS?\nIf you want to configure TLS with TCP, then good news: nothing changes, you’ll\nconfigure the same tls option, but this time on your tcp router.\n\nversion: \"3\"\n\nservices:\n  # ...\n  my-tcp-app:\n    image: containous/whoamitcp:v1.0.0\n    labels:\n      - \"traefik.tcp.routers.my-tcp-app.rule=HostSNI(`tcp-example.com`)\"\n      - \"traefik.tcp.routers.my-tcp-app.tls=true\"\n\n\n--------------------------------------------------------------------------------\n\nWhat About Pass-Through?\nSometimes your services handle TLS by themselves. In such cases, Traefik mustn’t\nterminate the TLS connection but forward the request “as is” to these services.\nTo configure this passthrough, you’ll need to configure a TCP router (even if\nyour service handles HTTPS).\n\nversion: \"3\"\n\nservices:\n  # ...\n  my-tcp-app:\n    image: containous/whoamitcp:v1.0.0\n    labels:\n      - \"traefik.tcp.routers.my-tcp-app.rule=HostSNI(`tcp-example.com`)\"\n      - \"traefik.tcp.routers.my-tcp-app.tls.passthrough=true\"\n\n\n--------------------------------------------------------------------------------\n\nQuestions? Where to Go Next?\nHopefully, this article sheds light on how to configure Traefik 2 with TLS.\n\nIf there are missing use cases or still unanswered questions, let me know in the\ncomments or on the community forum\n[https://community.containo.us/c/traefik/traefik-v2]!\n\nIn the meantime — Happy Traefik!","html":"<!--kg-card-begin: html--><p class=\"post-sub-title\">HTTPS (& TCP over TLS) for everyone!</p><!--kg-card-end: html--><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://containous.ghost.io/content/images/2019/11/image-103.png\" class=\"kg-image\"></figure><p>There are hundreds of reasons why I love being a developer (besides memories of sleepless nights trying to fix a video game that nobody except myself would ever play).</p><p>Being a developer gives you superpowers — you can solve any kind of problems. Yes, especially if they don’t involve real-life practical situations.</p><p>But these superpowers are sometimes hindered by tedious configuration work that expects you to master <em><em>yet another</em></em> arcane language assembled with heaps of words you’ve never seen before. Such a barrier can be encountered when dealing with HTTPS and its certificates.</p><p>Luckily for us, Traefik tends to lower this kind of hurdle and makes sure that there are easy ways of securely connecting your developments to the outside world.</p><h2 id=\"the-goal-for-today\">The Goal for Today</h2><p>The challenge we’ll accept is the following — You have an HTTP service exposed through Traefik, and you want Traefik to deal with the HTTPS burden (TLS termination), leaving your pristine service unspoiled by mundane technical details.</p><p>We’ll assume you have a basic understanding of Traefik on Docker and that you’re familiar with its configuration (if not, it’s time to read <a href=\"https://containous.ghost.io/blog/traefik-2-0-docker-101-fc2893944b9d/\">Traefik 2 &amp; Docker 101</a>).</p><p>During this article, we’ll use my pet demo docker-compose file: it enables the docker provider and launches a <code>my-app</code> application that allows us to test any request.</p><pre><code class=\"language-yaml\">version: \"3\"\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.web.address=:80\n      - --providers.docker=true\n    ports:\n      - \"80:80\"\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n  \n  my-app:\n    image: containous/whoami:v1.3.0</code></pre><h2 id=\"getting-things-ready\">Getting Things Ready</h2><p>First things first, let’s make sure our setup can handle HTTPS traffic on the default port (<code>:443</code>), and that Traefik listens to this port thanks to an <a href=\"https://docs.traefik.io/routing/entrypoints/\" rel=\"noopener nofollow\">entrypoint</a> we’ll name <code>web-secure</code>.</p><pre><code class=\"language-yaml\">version: \"3\"\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.web.address=:80\n      - --entrypoints.web-secure.address=:443 #Declares the web-secure entrypoint in Traefik\n      - --providers.docker=true\n    ports:\n      - \"80:80\"\n      - \"443:443\" #Docker sends requests on port 443 to Traefik on port 443\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n  \n  my-app:\n    image: containous/whoami:v1.3.0</code></pre><p>To avoid confusion, let’s state the obvious — We haven’t yet configured anything but enabled requests on 443 to be handled by Traffic. So, no certificate management yet!</p><h2 id=\"general-concepts\">General Concepts</h2><p>Ultimately, in Traefik, you configure HTTPS on the <a href=\"https://docs.traefik.io/routing/routers/\" rel=\"noopener nofollow\">router</a> level. While defining routes, you decide whether they are HTTP routes or HTTPS routes (by default, they are HTTP routes).</p><p>First, let’s expose our <code>my-app</code> service on HTTP so that it handles requests on domain <code>example.com</code>.</p><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"</code></pre><p>And now, see what it takes to make this route HTTPS only!</p><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n      - \"traefik.http.routers.my-app.tls=true\"</code></pre><p>There, by adding the <code>tls</code> option to the route, we’ve made it HTTPS.</p><p>The only unanswered question left is, “Where does Traefik get its certificates from?” And the answer is, “Either from a collection of certificates you own and have configured or from a fully automatic mechanism that gets them for you.”</p><p>Let’s see these solutions in action!</p><hr><h2 id=\"option-1-certificates-you-own\">Option 1 — Certificates You Own</h2><p>The least magical of the two options involves creating a configuration file.</p><p>Say you already own a certificate for a domain (or a collection of certificates for different domains) and that you are then the proud holder of files to claim your ownership of the said domain.</p><p>To have Traefik make a claim on your behalf, you’ll have to give it access to the certificate files. Let’s do this.</p><h3 id=\"add-a-configuration-file-for-certificates\">Add a Configuration File for Certificates<br></h3><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.web.address=:80\n      - --entrypoints.web-secure.address=:443\n      - --providers.docker=true\n      - --providers.file.directory=/configuration/\n      - --providers.file.watch=true\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - \"/var/run/docker.sock:/var/run/docker.sock:ro\"\n      - \"/home/username/traefik/configuration/:/configuration/\"</code></pre><p>Traefik runs with many providers beyond Docker (i.e., <a href=\"https://docs.traefik.io/providers/kubernetes-crd/\" rel=\"noopener nofollow\">Kubernetes</a>, <a href=\"https://docs.traefik.io/providers/rancher/\" rel=\"noopener nofollow\">Rancher</a>, <a href=\"https://docs.traefik.io/providers/marathon/\" rel=\"noopener nofollow\">Marathon</a>), and here we chose to add plain old configuration files (<code>--providers.file</code>) in the <code>configuration/</code> directory (and we’ll automatically reload changes with <code>--providers.file.watch=true</code>). We’ll use a configuration file to declare our certificates.</p><h3 id=\"add-the-certificates-to-the-configuration-file\">Add the Certificates to the Configuration File</h3><pre><code class=\"language-toml\"># in files/certificates.toml\n\n[[tls.certificates]] #first certificate\n   certFile = “/path/to/example-com.cert” \n   keyFile = “/path/to/example-com.key”\n\n[[tls.certificates]] #second certificate\n   certFile = “/path/to/other.cert” \n   keyFile = “/path/to/other.key”\n   \n# and so on</code></pre><p>Now that we have our TOML configuration file available (thanks to the enabled file provider), we can fill in certificates in the <code>[[tls.certificates]]</code>section.</p><h3 id=\"enjoy-\">Enjoy!</h3><p>This is all there is to do. When dealing with an HTTPS route, Traefik goes through your default certificate store to find a matching certificate.</p><h3 id=\"specifying-a-default-certificate\">Specifying a Default Certificate?</h3><p>If no valid certificate is found, Traefik serves a default auto-signed certificate. But if needed, you can customize the default certificate like so:</p><pre><code class=\"language-toml\">[tls.stores]\n  [tls.stores.default]\n   [tls.stores.default.defaultCertificate] \n     certFile = “path/to/cert.crt” \n     keyFile = “path/to/cert.key”</code></pre><h3 id=\"additional-thoughts\">Additional Thoughts</h3><p>Even though the configuration is straightforward, it is your responsibility, as the administrator, to configure / renew your certificates when they expire. If you don’t like such constraints, keep reading!</p><hr><h2 id=\"option-2-dynamic-automatic-certificates\">Option 2 — Dynamic / Automatic Certificates</h2><p>Having to manage (buy/install/renew) your certificates is a process you might <em><em>not</em></em> enjoy (I don’t). If so, you’ll be interested in the automatic certificate generation embedded in Traefik (thanks to Let’s Encrypt).</p><p>Long story short, you can start Traefik with no other configuration than your Let’s Encrypt account, and Traefik automatically negotiates (get/renew/configure) certificates for you — No extra step.</p><h3 id=\"certificate-resolvers\">Certificate Resolvers</h3><p>We saw that you can configure a router to use TLS<br>(<code>--traefik.http.routers.router-name.tls=true</code>). <br>As a consequence, we saw that Traefik would go through your certificate list to find a suitable match for the domain at hand (and if not would use a default certificate).</p><p>For automatic certificate generation, you can add a <em><em>certificate resolver</em></em> to your TLS options. A certificate resolver is responsible for retrieving certificates.</p><p>Here, let’s define a certificate resolver that works with your Let’s Encrypt account!</p><pre><code class=\"language-yaml\">services:\n  traefik:\n    image: \"traefik:v2.0\"\n    command:\n      - --entrypoints.websecure.address=:443\n      # ...\n      - --certificatesresolvers.le.acme.email=my@email.com\n      - --certificatesresolvers.le.acme.storage=/acme.json\n      - --certificatesresolvers.le.acme.tlschallenge=true\n      # ...</code></pre><p>As you can read, we defined a certificate resolver named <code>le</code> of type <code>acme</code>. Then, we provided an email (your Let’s Encrypt account), the storage file (for certificates it retrieves), and <a href=\"https://docs.traefik.io/https/acme/#the-different-acme-challenges\" rel=\"noopener nofollow\">the challenge for certificate negotiation</a>(here <code>tlschallenge</code>, just because it’s the most concise configuration option for the sake of the example).</p><p>From now on, Traefik is fully equipped to generate certificates for you!</p><h3 id=\"using-the-certificate-resolver\">Using the Certificate Resolver</h3><p>If you remember correctly (I’m sure you do!), we enabled TLS on our router like so:</p><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n      - \"traefik.http.routers.my-app.tls=true\"</code></pre><p>Now, to enable our certificate resolver and have it automatically generate certificates (when needed), we’ll add it to the TLS configuration, like so:</p><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  # ...\n  my-app:\n    image: containous/whoami:v1.3.0\n    labels:\n      - \"traefik.http.routers.my-app.rule=Host(`example.com`)\"\n      - \"traefik.http.routers.my-app.tls=true\"\n      - \"traefik.http.routers.my-app.tls.certresolver=le\"</code></pre><p>Now, if your certificate store doesn’t yet have a valid certificate for <code>example.com</code>, the <code>le</code> certificate resolver will transparently negotiate one for you — it’s that simple.</p><h3 id=\"multiple-certificate-resolvers\">Multiple Certificate Resolvers?</h3><p>With certificate resolvers, you can configure different challenges.</p><p>Below is an example that shows how to configure two CertResolvers that leverage Let’s Encrypt, one using the <a href=\"https://docs.traefik.io/https/acme/#dnschallenge\" rel=\"noopener nofollow\">dnsChallenge</a>, the other using the <a href=\"https://docs.traefik.io/https/acme/#tlschallenge\" rel=\"noopener nofollow\">tlsChallenge</a>.</p><pre><code class=\"language-toml\">[certificatesResolvers.resolver-digital-ocean.acme]\n  # ... \n  [certificatesResolvers.resolver-digital-ocean.acme.dnsChallenge]\n    provider = \"digitalocean\"\n    delayBeforeCheck = 0\n\n[certificatesResolvers.tls-challenge-resolver.acme]\n  # ...\n  [certificatesResolvers.tls-challenge-resolver.acme.tlsChallenge]</code></pre><p>Later on, you’ll be able to use one or the other on your routers.</p><pre><code class=\"language-toml\"># in routers.toml\n\n[http.routers]\n  [http.routers.https-route]\n    rule = \"Host(`my.domain`)\"\n    [http.routers.https-route.tls]\n      certResolver = \"resolver-digital-ocean\"\n\n[http.routers.https-route-2]\n    rule = \"Host(`other.domain`)\"\n    [http.routers.https-route-2.tls]\n      certResolver = \"tls-challenge-resolver\"</code></pre><p>In the above example (that uses the file provider), we’ve asked Traefik to generate certificates for <code>my.domain</code> using the dnsChallenge (with digital ocean) and to generate certificates for <code>other.domain</code> using the TLSChallenge.</p><p>And you’ve guessed it already — Traefik supports DNS challenge for different DNS providers, <em><em>at the same time</em></em>!<br></p><hr><h2 id=\"wildcard-and-let-s-encrypt\">Wildcard and Let’s Encrypt?</h2><p>Instead of generating a certificate for each subdomain, you can choose to generate wildcard certificates!</p><pre><code class=\"language-toml\">[http.routers]\n  [http.routers.router-example]\n    rule = \"Host(`something.my.domain`)\"\n    [http.routers.router-example.tls]\n      certResolver = \"my-resolver\"\n      [[http.routers.router-example.tls.domains]]\n        main = \"my.domain\"\n        sans = \"*.my.domain\"</code></pre><p>In the above example, we’ve configured Traefik to generate a wildcard certificate for <code>*.my.domain</code>.</p><p>If we had omitted the <code>.tls.domains</code> section, Traefik would have used the host (here <code>something.my.domain</code>) defined in the <code>Host</code> rule to generate a certificate.</p><hr><h2 id=\"what-about-tcp-tls\">What About TCP &amp; TLS?</h2><p>If you want to configure TLS with TCP, then good news: nothing changes, you’ll configure the same <code>tls</code> option, but this time on your <code>tcp</code> router.</p><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  # ...\n  my-tcp-app:\n    image: containous/whoamitcp:v1.0.0\n    labels:\n      - \"traefik.tcp.routers.my-tcp-app.rule=HostSNI(`tcp-example.com`)\"\n      - \"traefik.tcp.routers.my-tcp-app.tls=true\"</code></pre><hr><h2 id=\"what-about-pass-through\">What About Pass-Through?</h2><p>Sometimes your services handle TLS by themselves. In such cases, Traefik mustn’t terminate the TLS connection but forward the request “as is” to these services. To configure this passthrough, you’ll need to configure a TCP router (even if your service handles HTTPS).</p><pre><code class=\"language-yaml\">version: \"3\"\n\nservices:\n  # ...\n  my-tcp-app:\n    image: containous/whoamitcp:v1.0.0\n    labels:\n      - \"traefik.tcp.routers.my-tcp-app.rule=HostSNI(`tcp-example.com`)\"\n      - \"traefik.tcp.routers.my-tcp-app.tls.passthrough=true\"</code></pre><hr><h2 id=\"questions-where-to-go-next\">Questions? Where to Go Next?</h2><p>Hopefully, this article sheds light on how to configure Traefik 2 with TLS.</p><p>If there are missing use cases or still unanswered questions, let me know in the comments or on the <a href=\"https://community.containo.us/c/traefik/traefik-v2\" rel=\"noopener nofollow\">community forum</a>!</p><p>In the meantime — Happy Traefik!</p>","url":"https://containous.ghost.io/blog/traefik-2-tls-101-23b4fbee81f1/","canonical_url":null,"uuid":"63ca7b89-9af1-4516-ba7c-c4f4747cf300","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5dcdfa6f2345360038abe218","reading_time":7}},{"node":{"id":"Ghost__Post__5dd7badbf1db6f0038c74299","title":"The Journey to Traefik Enterprise Edition: Smooth Operations","slug":"the-journey-to-traefik-enterprise-edition-smooth-operations-2591bb7ff1fe","featured":false,"feature_image":"https://containous.ghost.io/content/images/2019/11/smooth-ops.png","featureImageSharp":{"childImageSharp":{"fluid":{"src":"/static/3e8dd3b9ae78318437039481a8ed57fb/f3583/smooth-ops.png","srcSet":"/static/3e8dd3b9ae78318437039481a8ed57fb/630fb/smooth-ops.png 300w,\n/static/3e8dd3b9ae78318437039481a8ed57fb/2a4de/smooth-ops.png 600w,\n/static/3e8dd3b9ae78318437039481a8ed57fb/f3583/smooth-ops.png 1200w,\n/static/3e8dd3b9ae78318437039481a8ed57fb/bbee5/smooth-ops.png 1800w,\n/static/3e8dd3b9ae78318437039481a8ed57fb/7b560/smooth-ops.png 1931w","sizes":"(max-width: 1200px) 100vw, 1200px"}}},"excerpt":"Welcome to the fifth step of our journey towards Traefik Enterprise Edition.\nThis post focuses on the experience of operating TraefikEE...","custom_excerpt":"Welcome to the fifth step of our journey towards Traefik Enterprise Edition.\nThis post focuses on the experience of operating TraefikEE...","visibility":"public","created_at_pretty":"22 November, 2019","published_at_pretty":"March 18, 2019","updated_at_pretty":"21 May, 2020","created_at":"2019-11-22T10:39:23.000+00:00","published_at":"2019-03-18T10:39:00.000+00:00","updated_at":"2020-05-21T23:40:43.000+00:00","meta_title":"The Journey to Traefik Enterprise Edition: Smooth Operations","meta_description":"Welcome to the fifth step of our journey towards Traefik Enterprise Edition.\nThis post focuses on the experience of operating TraefikEE...","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Damien Duportal","slug":"damien","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/11/dduportal_light.jpg","twitter":null,"facebook":null,"website":null}],"primary_author":{"name":"Damien Duportal","slug":"damien","bio":null,"profile_image":"https://containous.ghost.io/content/images/2019/11/dduportal_light.jpg","twitter":null,"facebook":null,"website":null},"primary_tag":{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Blog","slug":"blog","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"},{"name":"How To","slug":"how-to","description":null,"feature_image":null,"featureImageSharp":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Welcome to the fifth step of our journey towards Traefik Enterprise Edition\n[/traefikee/].\n\nThis post focuses on the experience of operating TraefikEE using the \ntraefikeectl command line. You should already feel at ease with TraefikEE’s\none-line installation and concepts. If you are not, then you can check the\nprevious posts of the “Journey to TraefikEE:”\n\n * Join the“Early Access” Program\n   [/blog/the-journey-to-traefik-enterprise-edition-join-the-early-access-program-b73e07d62f30/]\n * Product Evaluation\n   [/blog/the-journey-to-traefik-enterprise-edition-product-evaluation-4828508cbc8/]\n * High Availability\n   [/blog/the-journey-to-traefik-enterprise-edition-high-availability-7421718be2d8/]\n * HTTPS for Everyone\n   [/blog/the-journey-to-traefik-enterprise-edition-https-for-everyone-90a36b33600/]\n\nToday, we’ll focus on traefikeectl, the command-line tool used to install,\nconfigure and operate all your TraefikEE installations, in a lean and repeatable\nway, independently of your platform.\n\nOne Command-Line to Rule Them All\n> (A voice in the background): I used Traefik because it’s really simple to use.\nI’m interested by TraefikEE for its high availability features. But distributed\nsystems are really hard. How to deal with this intrinsic complexity?\n> Containous: Let us introduce traefikeectl (also known as “TraefikEE-cuddle”),\nthe command-line tool which abstracts most of this complexity.\nTraefikEE is designed from the ground up to be platform agnostic. From\ninstallation to any operation, the workflow is the same on each platform.\n\nAll the operations are managed by the command line traefikeectl following this\nworkflow, whichever platform you are using:\n\n * Install Phase: Installs a TraefikEE cluster (with traefikeectl install or\n   manually),\n * Connect Phase: Make your local traefikeectl aware of an existing TraefikEE\n   cluster allowing multi-cluster management,\n * Deploy Phase: Deploy a “routing configuration” to this TraefikEE instance.\n\nInstall Phase\nPlatform-Specific\nDo you remember the “One Line Installation for Kubernetes”\n[/blog/the-journey-to-traefik-enterprise-edition-product-evaluation-4828508cbc8/] \nfrom previous posts (and the related documentation [https://docs.containo.us])?\n\ntraefikeectl install \\\n  --licensekey=\"$(cat /keybase/.../traefikee-license)\" \\\n  --dashboard \\\n  --kubernetes\n  # ...\n\nWhat if you want to install on a Docker Swarm cluster instead?\n\nWell, the answer is to use the flag —-swarm instead of --kubernetes , as\ndescribed on the “One Line Installation guide for Swarm”:\n\ntraefikeectl install \\\n  --licensekey=\"$(cat /keybase/.../traefikee-license)\" \\\n  --dashboard \\\n  --swarm\n  # ...\n\nEach “agnostic” feature is then provided by the commandtraefikeectl when\nrequired, as --kubernetes.namespace or --swarm.networkname .\n\nCustomize Installation\nWe’ll now dig on how to customize installation for Kubernetes.\n\n> (A voice in the background): We are not able to use traefikeectl for\ninstallation in our Kubernetes cluster, because the default configuration does\nnot fit our needs.\n> Containous: The install command of traefikeectl allows you to customize\ninstallation. With Kubernetes, you can provide a YAML file to specify custom\nvalues.\nFollowing the reference values from the documentation, let’s consider that you\nwant to specify the following elements during the installation:\n\n * A custom URL for accessing the dashboard, as \n   http(s)://private.mycompany.org/traefikee,\n * Limiting the resources used for each node to 2Gb of memory and 2 CPUs (See\n   the article “Managing Compute Resources for Containers\n   [https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/]\n   ” Kubernetes Documentation for reference).\n\nBefore installation, create the following YAML file to specify these values:\n\n## File \"traefikee-values.yaml\"\n\n# Expose dashboard at http(s)://private.mycompany.org/traefikee\ndashboard:\n  host: \"private.mycompany.org\"\n  path: \"/traefikee\"\n\n# Restrict resources usage for each TraefikEE node\nresources:\n  cpus: \"2\"\n  memory: \"2G\"\n\nYou can now proceed to the “One Line Installation”, by adding the flag \n--kubernetes.helmvaluespath to use the YAML value file:\n\ntraefikeectl install --kubernetes \\\n  --licensekey=XXXXXXX \\\n  --dashboard \\\n  --kubernetes.helmvaluespath=./traefikee-values.yaml\n\nAs no one is perfect, traefikeectl might not provide some specific settings\nrequired for your platform to work correctly. In this case, you still can “patch\n[https://kubernetes.io/docs/reference/kubectl/cheatsheet/#patching-resources]” , \n“edit”\n[https://kubernetes.io/docs/reference/kubectl/cheatsheet/#editing-resources] or\neven “annotate”\n[https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#annotate] \nthe Kubernetes resources created by traefikee install.\n\nConnect Phase\nThe next step is to ensure that your traefikeectl command has knowledge of the\ncluster you want to operate.\n\n> Please note that this step is not required if you used a “One Line Installation”\nwith traefikeectl install, as it is automatically done.\nThe scenario is the following:\n\n * A TraefikEE cluster, designated astraefikee-staging, is running on your\n   remote Kubernetes platform, in the namespace traefikee-ingress,\n * You want to set up an administration machine (your computer, a freshly\n   onboarded team member, etc.) to operate this cluster,\n * This machine is already configured to reach the Kubernetes cluster.\n\nThe connect phase is easy:\n\ntraefikeectl connect --clustername=traefikee-staging \\\n  --kubernetes \\\n  --kubernetes.namespace=traefikee-ingress\n\nThat’s all: traefikeectl is now aware of this cluster and can operate it:\n\n\ntraefikeectl list-nodes\n\ntraefikeectl logs\n\n# ...\n\nUnder the hood, traefikeectl stored the cluster connection information in a TOML\nfile named after the cluster name. These files are located in ${TRAEFIKEE_HOME},\nwhich defaults to the directory ${HOME}/.config/traefikee (XDG_CONFIG folder\n[https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html]).\n\n> Please note that if you do not provide the option --clustername , the default\nvalue traefikee is used.\nIt means that you can manage multiple TraefikEE clusters from the same \ntraefikeectl, so you are free to split per environment (staging/production, or\nevent external/internal, etc.).\n\nDeploy Phase\nThe last step of the workflow is to deploy a “routing configuration”.\n\n> (A voice in the background): We followed the previous blog post, and we were\nable to install TraefikEE on our platform. Now, we want to enable HTTPS and\nMetrics collection with Prometheus [https://prometheus.io/]. Do we have to\ninstall the cluster again to update the configuration as we did for Traefik?\n> Containous: Fortunately, you don’t have to reinstall the cluster. Unlike\nTraefik, TraefikEE lets you update the configuration at runtime.\nLet’s say that you want to set up TraefikEE with the following routing\nconfiguration:\n\n * Enable TLS termination on the port 443 (defining a new “entrypoint” named \n   https),\n * Auto-generate TLS certificates using Let’s Encrypt for this new https \n   “entrypoint” . The host names for these certificates are determined from the\n   backend applications (either Ingresses on Kubernetes or labels on Docker\n   Swarm),\n * Enable the Prometheus metric exporter,\n * Enable redirection from http to https for any incoming request.\n\nWith Traefik, you would have passed the following options (and restarted Traefik\nto apply the configuration):\n\n## Traefik Configuration References:\n# Entrypoints: https://docs.traefik.io/configuration/entrypoints/\n# Metrics: https://docs.traefik.io/configuration/metrics/\n# ACME/Let's Encrypt: https://docs.traefik.io/configuration/acme/\n\ntraefik --kubernetes \\\n  --entryPoints='Name:http Address::80 Redirect.EntryPoint:https' \\\n  --entryPoints='Name:https Address::443 TLS' \\\n  --defaultentrypoints=https,http \\\n  --acme.entryPoint=https \\\n  --acme.email=damien@containo.us \\\n  --acme.tlsChallenge \\\n  --acme.onHostRule=true \\\n  --metrics.prometheus\n\nWith TraefikEE, the same configuration is passed to the traefikeectl deploy \ncommand. It’s sent to the TraefikEE control plane through the traefikeectl API,\nstored on the TraefikEE Control Plane and then applied to all the TraefikEE Data\nNodes (which are hot-reloaded).\n\ntraefikeectl deploy --kubernetes \\\n  --entryPoints='Name:http Address::80 Redirect.EntryPoint:https' \\\n  --entryPoints='Name:https Address::443 TLS' \\\n  --defaultentrypoints=https,http \\\n  --acme.entryPoint=https \\\n  --acme.email=damien@containo.us \\\n  --acme.tlsChallenge \\\n  --acme.onHostRule=true \\\n  --metrics.prometheus\n\nIf you prefer using TOML file instead of command-line flags:\n\n# File \"traefik.toml\"\n\ndefaultEntryPoints = [\"https\",\"http\"]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \":80\"\n    [entryPoints.http.redirect]\n    entryPoint = \"https\"\n  [entryPoints.https]\n  address = \":443\"\n  [entryPoints.https.tls]\n\n[kubernetes]\n\n[acme]\nemail = \"damien@containo.us\"\nstorage = \"acme.json\"\nentryPoint = \"https\"\nonHostRule = true\n[acme.tlsChallenge]\n\ntraefikeectl deploy --configfile=./traefik.toml\n\n\n--------------------------------------------------------------------------------\n\nThat’s all for today: we installed a customized cluster, connected a remote\nmachine to operate with traefikeectl, and deployed the same configuration as the\none you could have used for Traefik, but without taking down the cluster, and\nwithout loosing any requests!\n\nYou can learn more about the traefikeectl command line on the reference\ndocumentation [https://docs.containo.us/installing/teectl-cli/].","html":"<figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2019/12/image-7.png\" class=\"kg-image\"></figure><p>Welcome to the fifth step of our journey towards <a href=\"https://containous.ghost.io/traefikee/\">Traefik Enterprise Edition</a>.</p><p>This post focuses on the experience of operating TraefikEE using the <code>traefikeectl</code> command line. You should already feel at ease with TraefikEE’s one-line installation and concepts. If you are not, then you can check the previous posts of the “Journey to TraefikEE:”</p><ul><li><em><em><a href=\"https://containous.ghost.io/blog/the-journey-to-traefik-enterprise-edition-join-the-early-access-program-b73e07d62f30/\">Join the“Early Access” Program</a></em></em></li><li><em><em><a href=\"https://containous.ghost.io/blog/the-journey-to-traefik-enterprise-edition-product-evaluation-4828508cbc8/\">Product Evaluation</a></em></em></li><li><em><em><a href=\"https://containous.ghost.io/blog/the-journey-to-traefik-enterprise-edition-high-availability-7421718be2d8/\">High Availability</a></em></em></li><li><em><em><a href=\"https://containous.ghost.io/blog/the-journey-to-traefik-enterprise-edition-https-for-everyone-90a36b33600/\">HTTPS for Everyone</a></em></em></li></ul><p>Today, we’ll focus on <code>traefikeectl</code>, the command-line tool used to install, configure and operate all your TraefikEE installations, in a lean and repeatable way, independently of your platform.</p><h2 id=\"one-command-line-to-rule-them-all\">One Command-Line to Rule Them All</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://containous.ghost.io/content/images/2019/11/image-38.png\" class=\"kg-image\"></figure><blockquote><em><em><strong><strong>(A voice in the background):</strong></strong> I used Traefik because it’s really simple to use. I’m interested by TraefikEE for its high availability features. But distributed systems are really hard. How to deal with this intrinsic complexity?</em></em></blockquote><blockquote><em><em><strong><strong>Containous:</strong></strong> Let us introduce <code><em>traefikeectl</em></code> (also known as “TraefikEE-cuddle”), the command-line tool which abstracts most of this complexity.</em></em></blockquote><p>TraefikEE is designed from the ground up to be platform agnostic. From installation to any operation, the workflow is the same on each platform.</p><p>All the operations are managed by the command line <code>traefikeectl</code> following this workflow, whichever platform you are using:</p><ul><li><strong><strong>Install Phase:</strong></strong> Installs a TraefikEE cluster (with <code>traefikeectl install</code> or manually),</li><li><strong><strong>Connect Phase: </strong></strong>Make your local <code>traefikeectl</code> aware of an existing TraefikEE cluster allowing multi-cluster management,</li><li><strong><strong>Deploy Phase:</strong></strong> Deploy a “routing configuration” to this TraefikEE instance.</li></ul><h2 id=\"install-phase\">Install Phase</h2><h3 id=\"platform-specific\">Platform-Specific</h3><p>Do you remember the <a href=\"https://containous.ghost.io/blog/the-journey-to-traefik-enterprise-edition-product-evaluation-4828508cbc8/\">“One Line Installation for Kubernetes”</a> from previous posts (and the <a href=\"https://docs.containo.us\">related documentation</a>)?</p><pre><code class=\"language-shell\">traefikeectl install \\\n  --licensekey=\"$(cat /keybase/.../traefikee-license)\" \\\n  --dashboard \\\n  --kubernetes\n  # ...</code></pre><p>What if you want to install on a Docker Swarm cluster instead?</p><p>Well, the answer is to use the flag <code>—-swarm</code> instead of <code>--kubernetes</code> , as described on the “One Line Installation guide for Swarm”:</p><pre><code class=\"language-shell\">traefikeectl install \\\n  --licensekey=\"$(cat /keybase/.../traefikee-license)\" \\\n  --dashboard \\\n  --swarm\n  # ...</code></pre><p>Each “agnostic” feature is then provided by the command<code>traefikeectl</code> when required, as <code>--kubernetes.namespace</code> or <code>--swarm.networkname</code> .</p><h3 id=\"customize-installation\">Customize Installation</h3><p>We’ll now dig on how to customize installation for Kubernetes.</p><blockquote><em><em><strong><strong>(A voice in the background):</strong></strong> We are not able to use <code><em>traefikeectl</em></code> for installation in our Kubernetes cluster, because the default configuration does not fit our needs.</em></em></blockquote><blockquote><em><em><strong><strong>Containous:</strong></strong> The <code><em>install</em></code> command of <code><em>traefikeectl</em></code> allows you to customize installation. With Kubernetes, you can provide a YAML file to specify custom values.</em></em></blockquote><p>Following the reference values from the documentation, let’s consider that you want to specify the following elements during the installation:</p><ul><li>A custom URL for accessing the dashboard, as <code>http(s)://private.mycompany.org/traefikee</code>,</li><li>Limiting the resources used for each node to <code>2Gb</code> of memory and <code>2 CPUs</code> (See the article “<a href=\"https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/\" rel=\"noopener\">Managing Compute Resources for Containers</a>” Kubernetes Documentation for reference).</li></ul><p>Before installation, create the following YAML file to specify these values:</p><pre><code class=\"language-yaml\">## File \"traefikee-values.yaml\"\n\n# Expose dashboard at http(s)://private.mycompany.org/traefikee\ndashboard:\n  host: \"private.mycompany.org\"\n  path: \"/traefikee\"\n\n# Restrict resources usage for each TraefikEE node\nresources:\n  cpus: \"2\"\n  memory: \"2G\"</code></pre><p>You can now proceed to the “One Line Installation”, by adding the flag <code>--kubernetes.helmvaluespath</code> to use the YAML value file:</p><pre><code class=\"language-shell\">traefikeectl install --kubernetes \\\n  --licensekey=XXXXXXX \\\n  --dashboard \\\n  --kubernetes.helmvaluespath=./traefikee-values.yaml</code></pre><p>As no one is perfect, <code>traefikeectl</code> might not provide some specific settings required for your platform to work correctly. In this case, you still can “<a href=\"https://kubernetes.io/docs/reference/kubectl/cheatsheet/#patching-resources\" rel=\"noopener\">patch</a>” , <a href=\"https://kubernetes.io/docs/reference/kubectl/cheatsheet/#editing-resources\" rel=\"noopener\">“edit”</a> or even <a href=\"https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#annotate\" rel=\"noopener\">“annotate”</a> the Kubernetes resources created by <code>traefikee install</code>.</p><h2 id=\"connect-phase\">Connect Phase</h2><p>The next step is to ensure that your <code>traefikeectl</code> command has knowledge of the cluster you want to operate.</p><blockquote><em><em>Please note that this step is not required if you used a “One Line Installation” with <code>traefikeectl install</code>, as it is automatically done.</em></em></blockquote><p>The scenario is the following:</p><ul><li>A TraefikEE cluster, designated as<code>traefikee-staging</code>, is running on your remote Kubernetes platform, in the namespace <code>traefikee-ingress</code>,</li><li>You want to set up an administration machine (your computer, a freshly onboarded team member, etc.) to operate this cluster,</li><li>This machine is already configured to reach the Kubernetes cluster.</li></ul><p>The connect phase is easy:</p><pre><code class=\"language-shell\">traefikeectl connect --clustername=traefikee-staging \\\n  --kubernetes \\\n  --kubernetes.namespace=traefikee-ingress</code></pre><p>That’s all: <code>traefikeectl</code> is now aware of this cluster and can operate it:</p><pre><code class=\"language-shell\">\ntraefikeectl list-nodes\n\ntraefikeectl logs\n\n# ...</code></pre><p>Under the hood, <code>traefikeectl</code> stored the cluster connection information in a TOML file named after the cluster name. These files are located in <code>${TRAEFIKEE_HOME}</code>, which defaults to the directory <code>${HOME}/.config/traefikee</code> (<a href=\"https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html\" rel=\"noopener\">XDG_CONFIG folder</a>).</p><blockquote><em><em>Please note that if you do not provide the option <code>--clustername</code> , the default value <code>traefikee</code> is used.</em></em></blockquote><p>It means that you can manage multiple TraefikEE clusters from the same <code>traefikeectl</code>, so you are free to split per environment (staging/production, or event external/internal, etc.).</p><h2 id=\"deploy-phase\">Deploy Phase</h2><p>The last step of the workflow is to deploy a “routing configuration”.</p><blockquote><em><em><strong><strong>(A voice in the background):</strong></strong> We followed the previous blog post, and we were able to install TraefikEE on our platform. Now, we want to enable HTTPS and Metrics collection with <a href=\"https://prometheus.io/\" rel=\"noopener\">Prometheus</a>. Do we have to install the cluster again to update the configuration as we did for Traefik?</em></em></blockquote><blockquote><em><em><strong><strong>Containous:</strong></strong> Fortunately, you don’t have to reinstall the cluster. Unlike Traefik, TraefikEE lets you update the configuration at runtime.</em></em></blockquote><p>Let’s say that you want to set up TraefikEE with the following routing configuration:</p><ul><li>Enable TLS termination on the port 443 (defining a new “entrypoint” named <code>https</code>),</li><li>Auto-generate TLS certificates using Let’s Encrypt for this new <code>https</code> “entrypoint” . The host names for these certificates are determined from the backend applications (either Ingresses on Kubernetes or labels on Docker Swarm),</li><li>Enable the Prometheus metric exporter,</li><li>Enable redirection from <code>http</code> to <code>https</code> for any incoming request.</li></ul><p>With Traefik, you would have passed the following options (and restarted Traefik to apply the configuration):</p><pre><code class=\"language-shell\">## Traefik Configuration References:\n# Entrypoints: https://docs.traefik.io/configuration/entrypoints/\n# Metrics: https://docs.traefik.io/configuration/metrics/\n# ACME/Let's Encrypt: https://docs.traefik.io/configuration/acme/\n\ntraefik --kubernetes \\\n  --entryPoints='Name:http Address::80 Redirect.EntryPoint:https' \\\n  --entryPoints='Name:https Address::443 TLS' \\\n  --defaultentrypoints=https,http \\\n  --acme.entryPoint=https \\\n  --acme.email=damien@containo.us \\\n  --acme.tlsChallenge \\\n  --acme.onHostRule=true \\\n  --metrics.prometheus</code></pre><p>With TraefikEE, the same configuration is passed to the <code>traefikeectl deploy</code> command. It’s sent to the TraefikEE control plane through the traefikeectl API, stored on the TraefikEE Control Plane and then applied to <strong><strong>all</strong></strong> the TraefikEE Data Nodes (which are hot-reloaded).</p><pre><code class=\"language-shell\">traefikeectl deploy --kubernetes \\\n  --entryPoints='Name:http Address::80 Redirect.EntryPoint:https' \\\n  --entryPoints='Name:https Address::443 TLS' \\\n  --defaultentrypoints=https,http \\\n  --acme.entryPoint=https \\\n  --acme.email=damien@containo.us \\\n  --acme.tlsChallenge \\\n  --acme.onHostRule=true \\\n  --metrics.prometheus</code></pre><p>If you prefer using TOML file instead of command-line flags:</p><pre><code class=\"language-toml\"># File \"traefik.toml\"\n\ndefaultEntryPoints = [\"https\",\"http\"]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \":80\"\n    [entryPoints.http.redirect]\n    entryPoint = \"https\"\n  [entryPoints.https]\n  address = \":443\"\n  [entryPoints.https.tls]\n\n[kubernetes]\n\n[acme]\nemail = \"damien@containo.us\"\nstorage = \"acme.json\"\nentryPoint = \"https\"\nonHostRule = true\n[acme.tlsChallenge]</code></pre><pre><code class=\"language-shell\">traefikeectl deploy --configfile=./traefik.toml</code></pre><hr><p>That’s all for today: we installed a customized cluster, connected a remote machine to operate with <code>traefikeectl</code>, and deployed the same configuration as the one you could have used for Traefik, but without taking down the cluster, and without loosing any requests!</p><p>You can learn more about the <code>traefikeectl</code> command line on <a href=\"https://docs.containo.us/installing/teectl-cli/\">the reference documentation</a>.</p>","url":"https://containous.ghost.io/blog/the-journey-to-traefik-enterprise-edition-smooth-operations-2591bb7ff1fe/","canonical_url":null,"uuid":"34907a2a-bbdd-4139-84dd-26a5ca4ad805","codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5dd7badbf1db6f0038c74299","reading_time":5}}]}},"pageContext":{"slug":"how-to","limit":9,"skip":0,"numberOfPages":2,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":2,"previousPagePath":null,"nextPagePath":"/tag/how-to/page/2/"}},"staticQueryHashes":["1274566015","2561578252","2731221146","394248586","4145280475","749840385"]}